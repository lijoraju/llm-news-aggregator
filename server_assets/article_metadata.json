[
  {
    "title": "AI Is Deciphering Animal Speech. Should We Try to Talk Back?",
    "content": "Chirps, trills, growls, howls, squawks. Animals converse in all kinds of ways, yet humankind has only scratched the surface of how they communicate with each other and the rest of the living world. Our species has trained some animals\u2014and if you ask cats, animals have trained us, too\u2014but we\u2019ve yet to truly crack the code on interspecies communication. Increasingly, animal researchers are deploying artificial intelligence to accelerate our investigations of animal communication\u2014both within species and between branches on the tree of life. As scientists chip away at the complex communication systems of animals, they move closer to understanding what creatures are saying\u2014and maybe even how to talk back. But as we try to bridge the linguistic gap between humans and animals, some experts are raising valid concerns about whether such capabilities are appropriate\u2014or whether we should even attempt to communicate with animals at all. Using AI to untangle animal language Towards the front of the pack\u2014or should I say pod?\u2014is Project CETI, which has used machine learning to analyze more than 8,000 sperm whale \u201ccodas\u201d\u2014structured click patterns recorded by the Dominica Sperm Whale Project. Researchers uncovered contextual and combinatorial structures in the whales\u2019 clicks, naming features like \u201crubato\u201d and \u201cornamentation\u201d to describe how whales subtly adjust their vocalizations during conversation. These patterns helped the team create a kind of phonetic alphabet for the animals\u2014an expressive, structured system that may not be language as we know it but reveals a level of complexity that researchers weren\u2019t previously aware of. Project CETI is also working on ethical guidelines for the technology, a critical goal given the risks of using AI to \u201ctalk\u201d to the animals. Meanwhile, Google and the Wild Dolphin Project recently introduced DolphinGemma, a large language model (LLM) trained on 40 years of dolphin vocalizations. Just as ChatGPT is an LLM for human inputs\u2014taking visual information like research papers and images and producing responses to relevant queries\u2014DolphinGemma intakes dolphin sound data and predicts what vocalization comes next. DolphinGemma can even generate dolphin-like audio, and the researchers\u2019 prototype two-way system, Cetacean Hearing Augmentation Telemetry (fittingly, CHAT), uses a smartphone-based interface that dolphins employ to request items like scarves or seagrass\u2014potentially laying the groundwork for future interspecies dialogue. \u201cDolphinGemma is being used in the field this season to improve our real-time sound recognition in the CHAT system,\u201d said Denise Herzing, founder and director of the Wild Dolphin Project, which spearheaded the development of DolphinGemma in collaboration with researchers at Google DeepMind, in an email to Gizmodo. \u201cThis fall we will spend time ingesting known dolphin vocalizations and let Gemma show us any repeatable patterns they find,\u201d such as vocalizations used in courtship and mother-calf discipline. In this way, Herzing added, the AI applications are two-fold: Researchers can use it both to explore dolphins\u2019 natural sounds and to better understand the animals\u2019 responses to human mimicking of dolphin sounds, which are synthetically produced by the AI CHAT system. Expanding the animal AI toolkit Outside the ocean, researchers are finding that human speech models can be repurposed to decode terrestrial animal signals, too. A University of Michigan-led team used Wav2Vec2\u2014a speech recognition model trained on human voices\u2014to identify dogs\u2019 emotions, genders, breeds, and even individual identities based on their barks. The pre-trained human model outperformed a version trained solely on dog data, suggesting that human language model architectures could be surprisingly effective in decoding animal communication. Of course, we need to consider the different levels of sophistication these AI models are targeting. Determining whether a dog\u2019s bark is aggressive or playful, or whether it\u2019s male or female\u2014these are perhaps understandably easier for a model to determine than, say, the nuanced meaning encoded in sperm whale phonetics. Nevertheless, each study inches scientists closer to understanding how AI tools, as they currently exist, can be best applied to such an expansive field\u2014and gives the AI a chance to train itself to become a more useful part of the researcher\u2019s toolkit. And even cats\u2014often seen as aloof\u2014appear to be more communicative than they let on. In a 2022 study out of Paris Nanterre University, cats showed clear signs of recognizing their owner\u2019s voice, but beyond that, the felines responded more intensely when spoken to directly in \u201ccat talk.\u201d That suggests cats not only pay attention to what we say, but also how we say it\u2014especially when it comes from someone they know. Earlier this month, a pair of cuttlefish researchers found evidence that the animals have a set of four \u201cwaves,\u201d or physical gestures, that they make to one another, as well as to human playback of cuttlefish waves. The group plans to apply an algorithm to categorize the types of waves, automatically track the creatures\u2019 movements, and understand the contexts in which the animals express themselves more rapidly. Private companies (such as Google) are also getting in on the act. Last week, China\u2019s largest search engine, Baidu, filed a patent with the country\u2019s IP administration proposing to translate animal (specifically cat) vocalizations into human language. The quick and dirty on the tech is that it would intake a trove of data from your kitty, and then use an AI model to analyze the data, determine the animal\u2019s emotional state, and output the apparent human language message your pet was trying to convey. A universal translator for animals? Together, these studies represent a major shift in how scientists are approaching animal communication. Rather than starting from scratch, research teams are building tools and models designed for humans\u2014and making advances that would have taken much longer otherwise. The end goal could (read: could) be a kind of Rosetta Stone for the animal kingdom, powered by AI. \u201cWe\u2019ve gotten really good at analyzing human language just in the last five years, and we\u2019re beginning to perfect this practice of transferring models trained on one dataset and applying them to new data,\u201d said Sara Keen, a behavioral ecologist and electrical engineer at the Earth Species Project, in a video call with Gizmodo. The Earth Species Project plans to launch its flagship audio-language model for animal sounds, NatureLM, this year, and a demo for NatureLM-audio is already live. With input data from across the tree of life\u2014as well as human speech, environmental sounds, and even music detection\u2014the model aims to become a converter of human speech into animal analogues. The model \u201cshows promising domain transfer from human speech to animal communication,\u201d the project states, \u201csupporting our hypothesis that shared representations in AI can help decode animal languages.\u201d \u201cA big part of our work really is trying to change the way people think about our place in the world,\u201d Keen added. \u201cWe\u2019re making cool discoveries about animal communication, but ultimately we\u2019re finding that other species are just as complicated and nuanced as we are. And that revelation is pretty exciting.\u201d The ethical dilemma Indeed, researchers generally agree on the promise of AI-based tools for improving the collection and interpretation of animal communication data. But some feel that there\u2019s a breakdown in communication between that scholarly familiarity and the public\u2019s perception of how these tools can be applied. \u201cI think there\u2019s currently a lot of misunderstanding in the coverage of this topic\u2014that somehow machine learning can create this contextual knowledge out of nothing. That so long as you have thousands of hours of audio recordings, somehow some magic machine learning black box can squeeze meaning out of that,\u201d said Christian Rutz, an expert in animal behavior and cognition and founding president of International Bio-Logging Society, in a video call with Gizmodo. \u201cThat\u2019s not going to happen.\u201d \u201cMeaning comes through the contextual annotation and this is where I think it\u2019s really important for this field as a whole, in this period of excitement and enthusiasm, to not forget that this annotation comes from basic behavioral ecology and natural history expertise,\u201d Rutz added. In other words, let\u2019s not put the horse before the cart, especially since the cart\u2014in this case\u2014is what\u2019s powering the horse. But with great power\u2026you know the clich\u00e9. Essentially, how can humans develop and apply these technologies in a way that is both scientifically illuminating and minimizes harm or disruption to its animal subjects? Experts have put forward ethical standards and guardrails for using the technologies that prioritize the welfare of creatures as we get closer to\u2014well, wherever the technology is going. As AI advances, conversations about animal rights will have to evolve. In the future, animals could become more active participants in those conversations\u2014a notion that legal experts are exploring as a thought exercise, but one that could someday become reality. \u201cWhat we desperately need\u2014apart from advancing the machine learning side\u2014is to forge these meaningful collaborations between the machine learning experts and the animal behavior researchers,\u201d Rutz said, \u201cbecause it\u2019s only when you put the two of us together that you stand a chance.\u201d There\u2019s no shortage of communication data to feed into data-hungry AI models, from pitch-perfect prairie dog squeaks to snails\u2019 slimy trails (yes, really). But exactly how we make use of the information we glean from these new approaches requires thorough consideration of the ethics involved in \u201cspeaking\u201d with animals. A recent paper on the ethical concerns of using AI to communicate with whales outlined six major problem areas. These include privacy rights, cultural and emotional harm to whales, anthropomorphism, technological solutionism (an overreliance on technology to fix problems), gender bias, and limited effectiveness for actual whale conservation. That last issue is especially urgent, given how many whale populations are already under serious threat. It increasingly appears that we\u2019re on the brink of learning much more about the ways animals interact with one another\u2014indeed, pulling back the curtain on their communication could also yield insights into how they learn, socialize, and act within their environments. But there are still significant challenges to overcome, such as asking ourselves how we use the powerful technologies currently in development.",
    "published_at": "2025-05-17T10:00:59Z",
    "source": "Gizmodo.com",
    "url": "https://gizmodo.com/ai-is-deciphering-animal-speech-should-we-try-to-talk-back-2000598783",
    "summary": "Humans have trained some animals, but we\u2019ve yet to crack the code on interspecies communication. Increasingly, animal researchers are deploying artificial intelligence to accelerate investigations of animal communication. Some experts are raising valid concerns about whether such capabilities are appropriate.",
    "category": "Technology"
  },
  {
    "title": "Climbing trees 1: what are decision trees?",
    "content": "Published: Jan 7, 2025 This is the first in a se\u00adries of posts about de\u00adci\u00adsion trees in the con\u00adtext of ma\u00adchine learn\u00ading. The goal here is to pro\u00advide a foun\u00adda\u00adtional un\u00adder\u00adstand\u00ading of de\u00adci\u00adsion trees and to im\u00adple\u00adment them. Climb\u00ading trees se\u00adries De\u00adci\u00adsion trees are not amaz\u00ading al\u00adgo\u00adrithms by them\u00adselves. They have lim\u00adi\u00adta\u00adtions that can re\u00adsult in sub\u00adop\u00adti\u00admal and even weird pre\u00addic\u00adtions. And yet, they have be\u00adcome ex\u00adtremely pop\u00adu\u00adlar. Some would even say they are the de facto go-to al\u00adgo\u00adrithm for many ma\u00adchine learn\u00ading do\u00admains. This is due to bag\u00adging and boost\u00ading, tech\u00adniques that turned sub\u00adpar de\u00adci\u00adsion trees into state-\u200bof-\u200bthe-\u200bart al\u00adgo\u00adrithms. We\u2019ll ex\u00adplore them in the fu\u00adture. First, we\u2019ll build an in\u00adtu\u00adition for what are de\u00adci\u00adsion trees and de\u00adfine them math\u00ade\u00admat\u00adi\u00adcally. Then, we\u2019ll ex\u00adplore how de\u00adci\u00adsion trees are built. This will allow us to grasp their main char\u00adac\u00adter\u00adis\u00adtics, ad\u00advan\u00adtages and dis\u00adad\u00advan\u00adtages. I will try to in\u00adtro\u00adduce com\u00adplex\u00adity grad\u00adu\u00adally, but I will as\u00adsume you have some knowl\u00adedge on math\u00ade\u00admat\u00adi\u00adcal no\u00adta\u00adtion, sta\u00adtis\u00adtics and basic ma\u00adchine learn\u00ading con\u00adcepts. If things be\u00adcome too com\u00adpli\u00adcated, try to read the pro\u00advided ref\u00ader\u00adences. I\u2019ve drawn upon var\u00adi\u00adous sources in\u00adstru\u00admen\u00adtal to my un\u00adder\u00adstand\u00ading of de\u00adci\u00adsion trees, in\u00adclud\u00ading books, doc\u00adu\u00admen\u00adta\u00adtion, ar\u00adti\u00adcles, blog posts and lec\u00adtures. Even if you un\u00adder\u00adstand every\u00adthing, check the ref\u00ader\u00adences: there is great con\u00adtent there. What is a de\u00adci\u00adsion tree? Imag\u00adine you\u2019re try\u00ading to de\u00adcide whether to take an um\u00adbrella when leav\u00ading home. You might ask ques\u00adtions like: \u201cAre there clouds?\u201d. If yes, you might then ask \u201cWhat\u2019s the hu\u00admid\u00adity level?\u201d. Each ques\u00adtion helps you nar\u00adrow down the de\u00adci\u00adsion. This is how a de\u00adci\u00adsion tree works. Let\u2019s sim\u00adu\u00adlate this weather ex\u00adam\u00adple: A de\u00adci\u00adsion tree can be thought of as mak\u00ading con\u00adsec\u00adu\u00adtive de\u00adci\u00adsions by ask\u00ading a se\u00adries of ques\u00adtions about our data. Each in\u00adter\u00adnal tree node uses a cer\u00adtain fea\u00adture (in our ex\u00adam\u00adple, cloud cover or hu\u00admid\u00adity) to di\u00advide its re\u00adgion into two using a split value. Each new re\u00adgion can be fur\u00adther di\u00advided into two. A node that di\u00advides its re\u00adgion into two is called an in\u00adter\u00adnal node. Leaf (or ter\u00admi\u00adnal) nodes don\u2019t ask any more ques\u00adtions, but rather pro\u00advide a pre\u00addic\u00adtion for its re\u00adgion. In our ex\u00adam\u00adple, it might say \u201cRain\u201d or \u201cNo rain\u201d. More pre\u00adcisely, it as\u00adsigns a prob\u00ada\u00adbil\u00adity for each out\u00adcome. Let\u2019s take a look at a de\u00adci\u00adsion tree fit\u00adted to our weather ex\u00adam\u00adple: This de\u00adci\u00adsion tree was kept in\u00adten\u00adtion\u00adally small. From top to bot\u00adtom, this graph rep\u00adre\u00adsents all de\u00adci\u00adsion bound\u00adaries of our sim\u00adple tree. Each in\u00adter\u00adnal node pro\u00adduces two branches, that is, two paths that can be fol\u00adlowed. These branches re\u00adcur\u00adsively par\u00adti\u00adtions the fea\u00adture space such that the sam\u00adples with the same la\u00adbels or sim\u00adi\u00adlar tar\u00adget val\u00adues are grouped to\u00adgether. For in\u00adstance, we pre\u00addict that it\u2019ll rain if hu\u00admid\u00adity is above 59% and cloud cover is above 45% (right\u00admost path in the graph) be\u00adcause most points (in\u00adstances) in this re\u00adgion are of the \u201cRain\u201d class. The class shown is only rel\u00ade\u00advant for leaf nodes, that is, those at the bot\u00adtom row. The value prop\u00aderty shows how many sam\u00adples there are for each class in each re\u00adgion. A pure node has only in\u00adstances of one class in its re\u00adgion. Since all nodes con\u00adtain at least one in\u00adstance of both classes (that is, \u201cRain\u201d and \u201cNo Rain\u201d), all nodes are im\u00adpure. The ob\u00adjec\u00adtive dur\u00ading train\u00ading is to re\u00adduce im\u00adpu\u00adrity as much as pos\u00adsi\u00adble. If all nodes are pure, then the tree has zero error on the train\u00ading data set. This is how de\u00adci\u00adsion trees learn. This vi\u00adsu\u00adal\u00adiza\u00adtion of the tree is very easy to in\u00adter\u00adpret. We can fol\u00adlow each path and clearly see why a pre\u00addic\u00adtion was made, that is, the model is eas\u00adily ex\u00adplain\u00adable (the op\u00adpo\u00adsite of a black-\u200bbox model). This is one of the rea\u00adsons why de\u00adci\u00adsion trees are pop\u00adu\u00adlar. Sim\u00adple de\u00adci\u00adsion trees can even be ap\u00adplied in some prac\u00adti\u00adcal set\u00adtings (e. g. med\u00adi\u00adcine) with\u00adout ma\u00adchine as\u00adsis\u00adtance. We can also vi\u00adsu\u00adal\u00adize the de\u00adci\u00adsion bound\u00adaries of the tree by over\u00adlay\u00ading them onto the scat\u00adter plot of our data: We can see the straight bound\u00adaries be\u00adtween re\u00adgions. More for\u00admally, a de\u00adci\u00adsion tree is a hi\u00ader\u00adar\u00adchi\u00adcal struc\u00adture that re\u00adcur\u00adsively di\u00advide our fea\u00adtures into cuboid re\u00adgions. Since we have 2 fea\u00adtures (2 di\u00admen\u00adsions) in our ex\u00adam\u00adple, the cuboid re\u00adgions are squares. Types of trees Broadly, there are two types of de\u00adci\u00adsion trees: clas\u00adsi\u00adfi\u00adca\u00adtion and re\u00adgres\u00adsion trees. While they share the same fun\u00adda\u00admen\u00adtal struc\u00adture and split\u00adting method\u00adol\u00adogy, they dif\u00adfer in their out\u00adput and how they make pre\u00addic\u00adtions. Clas\u00adsi\u00adfi\u00adca\u00adtion trees are de\u00adsigned to pre\u00addict cat\u00ade\u00adgor\u00adi\u00adcal out\u00adcomes \u2014 they as\u00adsign input data to pre\u00adde\u00adfined classes or cat\u00ade\u00adgories. At each leaf node, the tree pre\u00addicts the most com\u00admon class among the train\u00ading sam\u00adples that reached that node. Our weather ex\u00adam\u00adple in\u00advolves a clas\u00adsi\u00adfi\u00adca\u00adtion tree and the leaves pre\u00addict whether it will rain or not. The pre\u00addic\u00adtion is made by count\u00ading the pro\u00adpor\u00adtion of train\u00ading sam\u00adples of each class at the leaf node and se\u00adlect\u00ading the ma\u00adjor\u00adity class. Think of it as the tree ask\u00ading a se\u00adries of yes/no ques\u00adtions about the input fea\u00adtures until it can make an ed\u00adu\u00adcated guess about which cat\u00ade\u00adgory the input be\u00adlongs to. Re\u00adgres\u00adsion trees, on the other hand, pre\u00addict con\u00adtin\u00adu\u00adous nu\u00admer\u00adi\u00adcal val\u00adues rather than cat\u00ade\u00adgories. In\u00adstead of pre\u00addict\u00ading a class at each leaf node, re\u00adgres\u00adsion trees typ\u00adi\u00adcally out\u00adput the av\u00ader\u00adage value of all train\u00ading sam\u00adples that reached that node. For in\u00adstance, a re\u00adgres\u00adsion tree might pre\u00addict a house\u2019s price based on fea\u00adtures like square footage, num\u00adber of bed\u00adrooms, and lo\u00adca\u00adtion. Each split in the tree tries to group to\u00adgether sim\u00adi\u00adlar nu\u00admer\u00adi\u00adcal val\u00adues. When a new ex\u00adam\u00adple comes in, the tree can guide it to a leaf node con\u00adtain\u00ading train\u00ading ex\u00adam\u00adples with sim\u00adi\u00adlar tar\u00adget val\u00adues and use their av\u00ader\u00adage as the pre\u00addic\u00adtion. De\u00adci\u00adsion tree al\u00adgo\u00adrithms De\u00adci\u00adsion trees have been widely ex\u00adplored and there is a wide range of dif\u00adfer\u00adent de\u00adci\u00adsion tree al\u00adgo\u00adrithms. The most in\u00adflu\u00aden\u00adtial ones are ID3 (It\u00ader\u00ada\u00adtive Di\u00adchotomiser 3), C4.5 and CART (Clas\u00adsi\u00adfi\u00adca\u00adtion and Re\u00adgres\u00adsion Trees). ID3 is one of the ear\u00adli\u00adest de\u00adci\u00adsion tree al\u00adgo\u00adrithms and sup\u00adport only clas\u00adsi\u00adfi\u00adca\u00adtion with cat\u00ade\u00adgor\u00adi\u00adcal fea\u00adtures. Nodes can be split into more than two de\u00adpend\u00ading on the num\u00adber of cat\u00ade\u00adgor\u00adi\u00adcal lev\u00adels of each fea\u00adture. C4.5 ex\u00adtends the ID3 al\u00adgo\u00adrithm to sup\u00adport nu\u00admer\u00adi\u00adcal fea\u00adtures and miss\u00ading val\u00adues. CART is sim\u00adi\u00adlar to C4.5 but also adds sup\u00adport for re\u00adgres\u00adsion. The CART ap\u00adproach only per\u00adforms bi\u00adnary splits, re\u00adsult\u00ading in taller trees when com\u00adpared to ID3 and C4.5. Al\u00adthough the prin\u00adci\u00adples dis\u00adcussed here apply to most de\u00adci\u00adsion tree al\u00adgo\u00adrithms, I am fo\u00adcused on CART \u2014 which is also the al\u00adgo\u00adrithm we\u2019ll im\u00adple\u00adment. Math\u00ade\u00admat\u00adi\u00adcal de\u00adf\u00adi\u00adn\u00adi\u00adtion Math\u00ade\u00admat\u00adi\u00adcally, a de\u00adci\u00adsion tree can be de\u00adscribed as: f ( x ) = \u2211 m = 1 M c m I ( x \u2208 R m ) f(x) = \\sum_{m=1}^{M} c_m \\mathbb{I}(x \\in R_m) f ( x ) = m = 1 \u2211 M \u200b c m \u200b I ( x \u2208 R m \u200b ) Where x x x are the input fea\u00adtures, R m R_m Rm\u200b is the m m m\u2018th re\u00adgion and c m c_m cm\u200b is the value of this re\u00adgion. I ( x \u2208 R m ) \\mathbb{I}(x \\in R_m) I(x\u2208Rm\u200b) is 1 if x x x is con\u00adtained in the m m m\u2018th re\u00adgion, 0 oth\u00ader\u00adwise. The val\u00adues ( c c c) are typ\u00adi\u00adcally a con\u00adstant (re\u00adgres\u00adsion) or a vec\u00adtor of prob\u00ada\u00adbil\u00adi\u00adties (clas\u00adsi\u00adfi\u00adca\u00adtion). The com\u00adbi\u00adna\u00adtion of re\u00adgions and val\u00adues de\u00adfines the de\u00adci\u00adsion tree. The re\u00adgions can\u00adnot as\u00adsume ar\u00adbi\u00adtrary bound\u00adaries, though. They are al\u00adways par\u00adal\u00adlel to some axis and can only di\u00advide a pre\u00advi\u00adous re\u00adgion. This can be a lim\u00adi\u00adta\u00adtion, but it greatly re\u00adduces the com\u00adpu\u00adta\u00adtional com\u00adplex\u00adity of con\u00adstruct\u00ading a de\u00adci\u00adsion tree. In our weather ex\u00adam\u00adple, it\u2019s triv\u00adial to find the fol\u00adlow\u00ading de\u00adci\u00adsion bound\u00adary using other meth\u00adods (I have used lo\u00adgis\u00adtic re\u00adgres\u00adsion): How\u00adever, axis-\u200bparallel splits (sin\u00adgle fea\u00adture) are much eas\u00adier to com\u00adpute than oblique splits (mul\u00adti\u00adple fea\u00adtures). Find\u00ading the best split of a sin\u00adgle fea\u00adture in\u00advolves sort\u00ading the data and eval\u00adu\u00adat\u00ading splits. Since the lat\u00adter is neg\u00adli\u00adgi\u00adble com\u00adpared to sort\u00ading, this op\u00ader\u00ada\u00adtion has a time com\u00adplex\u00adity of O ( n log \u2061 n ) O(n \\log n) O(nlogn), where n n n is the num\u00adber of data points. To find the best oblique split com\u00adbin\u00ading two fea\u00adtures, how\u00adever, we must first con\u00adsider all pos\u00adsi\u00adble O ( n 2 ) O(n^2) O(n2) lines formed by pairs of points. For each line, you need to eval\u00adu\u00adate which side each point falls on: O ( n ) O(n) O(n). This amounts to a total time com\u00adplex\u00adity of O ( n 3 ) O(n^3) O(n3). More gen\u00ader\u00adally, an oblique split has a time com\u00adplex\u00adity of O ( n d + 1 ) O(n^{d+1}) O(nd+1), in which d d d is the num\u00adber of fea\u00adtures. There\u00adfore, we com\u00adpro\u00admise on using only axis-\u200bparallel splits, which de\u00adfine cuboid re\u00adgions. Each re\u00adgion R m R_m Rm\u200b is de\u00adfined by a path from the root to the m m m\u2018th leaf of the tree. For in\u00adstance, con\u00adsider the path that de\u00adfines the re\u00adgion R = { ( H u m i d i t y , C l o u d ) \u2223 H u m i d i t y > 59 and C l o u d > 45 } R = \\{(Humidity,\\ Cloud)\\ |\\ Humidity > 59\\ \\text{and}\\ Cloud > 45\\} R={(Humidity, Cloud) \u2223 Humidity>59 and Cloud>45}. This re\u00adgion can be vi\u00adsu\u00adal\u00adized on the scat\u00adter plot: Un\u00adlike lin\u00adear mod\u00adels, de\u00adci\u00adsion trees do not model the en\u00adtire data dis\u00adtri\u00adb\u00adu\u00adtion. Rather, each re\u00adgion has in\u00adde\u00adpen\u00addent pre\u00addicted val\u00adues. More for\u00admally, adding all in\u00adde\u00adpen\u00addent re\u00adgions de\u00adfines a piece\u00adwise func\u00adtion that can ap\u00adprox\u00adi\u00admate any pat\u00adtern in the data, but it may strug\u00adgle to rep\u00adre\u00adsent smooth or con\u00adtin\u00adu\u00adous func\u00adtions prop\u00aderly. Bias-\u200bvariance trade\u00adoff As all other ma\u00adchine learn\u00ading al\u00adgo\u00adrithms, trees are also haunted by the bias-\u200bvariance trade\u00adoff. If this con\u00adcept is new to you, I highly rec\u00adom\u00admend read\u00ading about it first (check the ref\u00ader\u00adences), but come back later. Bias-\u200bvariance trade\u00adoff re\u00adfresher In sum\u00admary, bias refers to the error that a model makes due to over\u00adsim\u00adpli\u00adfi\u00adca\u00adtion of re\u00adla\u00adtion\u00adships be\u00adtween fea\u00adtures (un\u00adder\u00adfit\u00adting). Vari\u00adance mea\u00adsures how sen\u00adsi\u00adtive model pre\u00addic\u00adtions are to small fluc\u00adtu\u00ada\u00adtions in the train\u00ading set. High vari\u00adance means that the model is cap\u00adtur\u00ading noise rather than true re\u00adla\u00adtion\u00adships (over\u00adfit\u00adting). Re\u00adduc\u00ading bias tends to in\u00adcrease vari\u00adance and vice-\u200bversa. Find\u00ading an op\u00adti\u00admal bias-\u200bvariance bal\u00adance is cru\u00adcial to achieve good pre\u00addic\u00adtion ac\u00adcu\u00adracy. De\u00adci\u00adsion tree vari\u00adance Due to the non-\u200blinear and non-\u200bsmooth na\u00adture of trees, they eas\u00adily cap\u00adture noise. Thus, deeper trees present more vari\u00adance. If you fully grow a tree, it will par\u00adti\u00adtion the fea\u00adture space until the error is zero1. The model will have ef\u00adfec\u00adtively mem\u00ado\u00adrized the train\u00ading set \u2014 in\u00adclud\u00ading noise \u2014 which re\u00adsults in over\u00adfit\u00adting. If we re\u00adbuild our ex\u00adam\u00adple tree until the error is 0 we get the fol\u00adlow\u00ading re\u00adgions: It has per\u00adfect ac\u00adcu\u00adracy, but it has very un\u00adusual bound\u00adaries due to noise (high vari\u00adance). This model doesn\u2019t gen\u00ader\u00adal\u00adize well, that is, it would score poorly with new data. There are dif\u00adfer\u00adent ways to limit tree vari\u00adance, namely: Lim\u00adit\u00ading depth Re\u00adquir\u00ading a min\u00adi\u00admum num\u00adber of points per node Re\u00adquir\u00ading a min\u00adi\u00admum de\u00adcrease in loss to split the node (usu\u00adally not a good idea) The num\u00adber of sam\u00adples re\u00adquired to fill a tree dou\u00adbles for each ad\u00addi\u00adtional level (depth) of the tree. These lim\u00adits en\u00adsure leaf nodes are not overly sparse. An\u00adother pos\u00adsi\u00adbil\u00adity is to fully grow the tree and later prune it to bal\u00adance com\u00adplex\u00adity and ac\u00adcu\u00adracy. Let\u2019s build de\u00adci\u00adsion trees with in\u00adcreas\u00ading depths on a toy dataset: Play Depth: 1 On the left we can see the train\u00ading set2 with two fea\u00adtures and two classes. We\u2019re build\u00ading clas\u00adsi\u00adfi\u00adca\u00adtion trees, whose de\u00adci\u00adsion bound\u00adary is over\u00adlaid onto the left plot. The plot on the right shows train\u00ading and test error, as well as the test error of a lo\u00adgis\u00adtic re\u00adgres\u00adsion model as a base\u00adline. The test set was sam\u00adpled from the same dis\u00adtri\u00adb\u00adu\u00adtion, but is dif\u00adfer\u00adent from the train\u00ading set. Use the slider to com\u00adpare depths. We can see that the best test error hap\u00adpens with a depth of 3. In\u00adcreas\u00ading the depth fur\u00adther re\u00adsults in over\u00adfit\u00adting. De\u00adci\u00adsion tree bias Even with a depth of three in the ex\u00adam\u00adple above the error is larger than the lo\u00adgis\u00adtic re\u00adgres\u00adsion base\u00adline. This is an ex\u00adam\u00adple where lin\u00adear mod\u00adels out\u00adper\u00adform de\u00adci\u00adsion trees due to the ad\u00addi\u00adtive struc\u00adture of the data. The lo\u00adgis\u00adtic re\u00adgres\u00adsion equa\u00adtion in this case is: l o g i t ( p ) = \u03b2 0 + \u03b2 1 x 1 + \u03b2 2 x 2 + \u03b5 logit(p) = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\varepsilon l o g i t ( p ) = \u03b2 0 \u200b + \u03b2 1 \u200b x 1 \u200b + \u03b2 2 \u200b x 2 \u200b + \u03b5 Where p p p is the prob\u00ada\u00adbil\u00adity of the out\u00adcome being of class 1. Ig\u00adnor\u00ading con\u00adstants and the noise ( \u03b5 \\varepsilon \u03b5), the prob\u00ada\u00adbil\u00adity is de\u00adter\u00admined by a lin\u00adear com\u00adbi\u00adna\u00adtion of both fea\u00adtures. The re\u00adla\u00adtion\u00adship be\u00adtween fea\u00adtures is not hi\u00ader\u00adar\u00adchi\u00adcal, there\u00adfore de\u00adci\u00adsion trees re\u00adquire mul\u00adti\u00adple, some\u00adtimes re\u00addun\u00addant, splits to ap\u00adprox\u00adi\u00admate this con\u00adcept, lead\u00ading to deep or overly com\u00adplex trees. There are other con\u00adcepts that fall under the same cat\u00ade\u00adgory, such as: XOR (Ex\u00adclu\u00adsive OR): the out\u00adput is of one class if ex\u00adactly one (but not both) of two in\u00adputs is true. Par\u00adity prob\u00adlem: the out\u00adput is dif\u00adfer\u00adent if the num\u00adber of true val\u00adues in a set of in\u00adputs is even or odd. Mul\u00adti\u00adplexer prob\u00adlem: a mul\u00adti\u00adplexer se\u00adlects one of sev\u00aderal input val\u00adues based on a sep\u00ada\u00adrate \u201cse\u00adlec\u00adtor\u201d input. These may seem overly spe\u00adcific, but they\u2019re used as bench\u00admarks to test the ca\u00adpa\u00adbil\u00adi\u00adties ma\u00adchine learn\u00ading al\u00adgo\u00adrithms. Ad\u00addi\u00adtive struc\u00adture, XOR and par\u00adity in\u00advolve global de\u00adpen\u00adden\u00adcies that re\u00adquire mul\u00adti\u00adple in\u00adputs to be con\u00adsid\u00adered to\u00adgether. De\u00adci\u00adsion trees split data based on one fea\u00adture at a time, there\u00adfore are in\u00adef\u00adfi\u00adcient at cap\u00adtur\u00ading these re\u00adla\u00adtion\u00adships. Mul\u00adti\u00adplexer prob\u00adlems re\u00adquire con\u00addi\u00adtional rules which are not hi\u00ader\u00adar\u00adchi\u00adcal, mak\u00ading the tree very large to ac\u00adcount for all com\u00adbi\u00adna\u00adtions of selector-\u200binput pairs. In more com\u00adplex real-\u200bworld datasets, it\u2019s quite likely that mul\u00adti\u00adple non-\u200bhierarchical con\u00adcepts are present, lead\u00ading to sub\u00adop\u00adti\u00admal bias. If they have sub\u00adpar vari\u00adance and bias, de\u00adci\u00adsion trees may look like a poor choice of al\u00adgo\u00adrithm. In\u00addeed, they rarely shine on their own, but rather as en\u00adsem\u00adbles (with bag\u00adging or boost\u00ading), which we\u2019ll cover in the fu\u00adture. The stair\u00adcase ef\u00adfect When de\u00adci\u00adsion trees at\u00adtempt to model ad\u00addi\u00adtive struc\u00adture, they face a struc\u00adtural con\u00adstraint that is com\u00admon enough for me to name it the \u201cstair\u00adcase\u201d ef\u00adfect3. This lim\u00adi\u00adta\u00adtion man\u00adi\u00adfests dif\u00adfer\u00adently in clas\u00adsi\u00adfi\u00adca\u00adtion and re\u00adgres\u00adsion tasks, but stems from axis-\u200baligned splits. In clas\u00adsi\u00adfi\u00adca\u00adtion prob\u00adlems, the stair\u00adcase ef\u00adfect be\u00adcomes ap\u00adpar\u00adent when the op\u00adti\u00admal de\u00adci\u00adsion bound\u00adary be\u00adtween classes in\u00advolves a lin\u00adear com\u00adbi\u00adna\u00adtion of fea\u00adtures (an oblique bound\u00adary). Con\u00adsider a sim\u00adple case where the op\u00adti\u00admal bound\u00adary is a di\u00adag\u00ado\u00adnal line in a two-\u200bdimensional fea\u00adture space. Be\u00adcause de\u00adci\u00adsion trees can only make splits par\u00adal\u00adlel to the fea\u00adture axes, they must ap\u00adprox\u00adi\u00admate this di\u00adag\u00ado\u00adnal bound\u00adary through a se\u00adries of rec\u00adtan\u00adgu\u00adlar re\u00adgions, cre\u00adat\u00ading a stair-\u200blike pat\u00adtern. In re\u00adgres\u00adsion set\u00adtings, the stair\u00adcase ef\u00adfect is even more promi\u00adnent be\u00adcause re\u00adgres\u00adsion trees must ap\u00adprox\u00adi\u00admate con\u00adtin\u00adu\u00adous func\u00adtions using dis\u00adcrete, constant-\u200bvalued re\u00adgions. When the un\u00adder\u00adly\u00ading re\u00adla\u00adtion\u00adship is smooth \u2014 whether lin\u00adear, poly\u00adno\u00admial, or any other con\u00adtin\u00adu\u00adous func\u00adtion \u2014 the tree\u2019s pre\u00addic\u00adtion sur\u00adface has a stair-\u200blike struc\u00adture with abrupt changes be\u00adtween ad\u00adja\u00adcent re\u00adgions. In\u00adcreas\u00ading tree depth ap\u00adprox\u00adi\u00admates the pre\u00addic\u00adtion sur\u00adface to the train\u00ading set, yet the sur\u00adface does not nec\u00ades\u00adsar\u00adily be\u00adcome smooth as it cap\u00adtures fea\u00adture noise. Re\u00adgres\u00adsion ex\u00adam\u00adple with the stair\u00adcase ef\u00adfect. There is only one fea\u00adture ( x x x) and the ver\u00adti\u00adcal axis is the out\u00adcome. Ob\u00adjec\u00adtive func\u00adtions We need to de\u00adfine ob\u00adjec\u00adtive func\u00adtions to op\u00adti\u00admize for dur\u00ading train\u00ading. Clas\u00adsi\u00adfi\u00adca\u00adtion trees use ei\u00adther Gini im\u00adpu\u00adrity or en\u00adtropy as ob\u00adjec\u00adtive func\u00adtions. Re\u00adgres\u00adsion trees usu\u00adally use the squared loss. In all ex\u00adam\u00adples, con\u00adsider the data D = { ( x 1 , y 1 ) , . . . , ( x n , y n ) } , y i \u2208 { 1 , . . . , c } \\mathcal{D} = \\{(x_1, y_1), ..., (x_n, y_n)\\}, y_i \\in \\{1, ..., c\\} D={(x1\u200b,y1\u200b),...,(xn\u200b,yn\u200b)},yi\u200b\u2208{1,...,c} where c c c is the num\u00adber of classes. Mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate M R ( D ) = \u2211 i = 1 n I ( y ^ i \u2260 y i ) n MR(\\mathcal{D}) = \\frac{\\sum_{i=1}^n \\mathbb{I}(\\hat{y}_i eq y_i)}{n} MR ( D ) = n \u2211 i = 1 n \u200b I ( y ^ \u200b i \u200b \ue020 = y i \u200b ) \u200b This is a very in\u00adtu\u00aditive ob\u00adjec\u00adtive for clas\u00adsi\u00adfi\u00adca\u00adtion. It mea\u00adsures the pro\u00adpor\u00adtion of mis\u00adclas\u00adsi\u00adfied ex\u00adam\u00adples. The pre\u00addic\u00adtion y ^ \\hat{y} y^\u200b is the ma\u00adjor\u00adity vote of the node. Our goal is to de\u00adcrease leaf node im\u00adpu\u00adrity, which is aligned with the mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate func\u00adtion. Gini im\u00adpu\u00adrity The Gini im\u00adpu\u00adrity4 over a set of class prob\u00ada\u00adbil\u00adi\u00adties p p p is de\u00adfined as: G ( D ) = \u2211 k = 1 c p k ( 1 \u2212 p k ) = 1 \u2212 \u2211 k = 1 c p k 2 G(\\mathcal{D}) = \\sum_{k=1}^{c} p_{k}(1 - p_{k}) = 1 - \\sum_{k=1}^c p_{k}^2 G ( D ) = k = 1 \u2211 c \u200b p k \u200b ( 1 \u2212 p k \u200b ) = 1 \u2212 k = 1 \u2211 c \u200b p k 2 \u200b It mea\u00adsures how often a ran\u00addomly cho\u00adsen el\u00ade\u00adment of a set would be in\u00adcor\u00adrectly la\u00adbeled if it were la\u00adbeled ran\u00addomly and in\u00adde\u00adpen\u00addently ac\u00adcord\u00ading to the dis\u00adtri\u00adb\u00adu\u00adtion of la\u00adbels in the set. When the node is pure, one class has a prob\u00ada\u00adbil\u00adity of 1 and the rest 0, so the Gini im\u00adpu\u00adrity is also 0. The worst Gini im\u00adpu\u00adrity arises when the prob\u00ada\u00adbil\u00adi\u00adties are uni\u00adform among classes, that is, a node with max\u00adi\u00admum Gini im\u00adpu\u00adrity is no bet\u00adter than a coin toss at clas\u00adsi\u00adfy\u00ading ex\u00adam\u00adples. It can be shown that the upper bound of Gini im\u00adpu\u00adrity is 1 as the num\u00adber of classes grow. To eval\u00adu\u00adate the qual\u00adity of a split ( S \\mathcal{S} S), we cal\u00adcu\u00adlate the Gini im\u00adpu\u00adrity of each child node and take the weighted av\u00ader\u00adage. G ( D \u2223 S ) = \u2223 D L \u2223 \u2223 D \u2223 G ( D L ) + \u2223 D R \u2223 \u2223 D \u2223 G ( D R ) G(\\mathcal{D}|\\mathcal{S}) = \\frac{|\\mathcal{D}_L|}{|\\mathcal{D}|} G(\\mathcal{D}_L) + \\frac{|\\mathcal{D}_R|}{|\\mathcal{D}|} G(\\mathcal{D}_R) G ( D \u2223 S ) = \u2223 D \u2223 \u2223 D L \u200b \u2223 \u200b G ( D L \u200b ) + \u2223 D \u2223 \u2223 D R \u200b \u2223 \u200b G ( D R \u200b ) Where \u2223 D L \u2223 \u2223 D \u2223 \\frac{|\\mathcal{D}_L|}{|\\mathcal{D}|} \u2223D\u2223\u2223DL\u200b\u2223\u200b is the frac\u00adtion of in\u00adputs in the left child node and \u2223 D R \u2223 \u2223 D \u2223 \\frac{|\\mathcal{D}_R|}{|\\mathcal{D}|} \u2223D\u2223\u2223DR\u200b\u2223\u200b, in the right. En\u00adtropy H ( D ) = \u2212 \u2211 k = 1 c p k l o g 2 p k H(\\mathcal{D}) = - \\sum_{k=1}^{c} p_{k}\\ log_{2} p_{k} H ( D ) = \u2212 k = 1 \u2211 c \u200b p k \u200b l o g 2 \u200b p k \u200b The en\u00adtropy cri\u00adte\u00adrion is a con\u00adcept from in\u00adfor\u00adma\u00adtion the\u00adory (Shan\u00adnon en\u00adtropy). It mea\u00adsures the av\u00ader\u00adage level of un\u00adcer\u00adtainty of a set of prob\u00ada\u00adbil\u00adi\u00adties. In other words, it\u2019s the ex\u00adpected amount of in\u00adfor\u00adma\u00adtion re\u00adquired to de\u00adscribe the po\u00adten\u00adtial out\u00adcomes. When prob\u00ada\u00adbil\u00adi\u00adties are uni\u00adformly dis\u00adtrib\u00aduted en\u00adtropy is max\u00adi\u00admum, just like Gini im\u00adpu\u00adrity. To un\u00adder\u00adstand the con\u00adnec\u00adtion be\u00adtween in\u00adfor\u00adma\u00adtion and prob\u00ada\u00adbil\u00adi\u00adties, con\u00adsider you have a set with two classes that are equally likely (let\u2019s say red and blue). If you draw a sam\u00adple, you have the least pos\u00adsi\u00adble amount of cer\u00adtainty about which color you\u2019ve drawn. On the other hand, if red has a 95% prob\u00ada\u00adbil\u00adity, you can be pretty con\u00adfi\u00addent about which color you\u2019ll draw \u2014 this has much lower un\u00adcer\u00adtainty. When prob\u00ada\u00adbil\u00adi\u00adties are uni\u00adform you need extra in\u00adfor\u00adma\u00adtion to ac\u00adcu\u00adrately con\u00advey the re\u00adsult of a se\u00adries of draws. The range of the en\u00adtropy cri\u00adte\u00adrion is from 0 to l o g 2 ( c ) log_{2}(c) log2\u200b(c). We also take the weighted av\u00ader\u00adage of child nodes to eval\u00adu\u00adate the qual\u00adity of a split: H ( D \u2223 S ) = \u2223 D L \u2223 \u2223 D \u2223 H ( D L ) + \u2223 D R \u2223 \u2223 D \u2223 H ( D R ) H(\\mathcal{D}|\\mathcal{S}) = \\frac{|\\mathcal{D}_L|}{|\\mathcal{D}|} H(\\mathcal{D}_L) + \\frac{|\\mathcal{D}_R|}{|\\mathcal{D}|} H(\\mathcal{D}_R) H ( D \u2223 S ) = \u2223 D \u2223 \u2223 D L \u200b \u2223 \u200b H ( D L \u200b ) + \u2223 D \u2223 \u2223 D R \u200b \u2223 \u200b H ( D R \u200b ) It\u2019s also com\u00admon to see the ob\u00adjec\u00adtive func\u00adtion ex\u00adpressed in terms of in\u00adfor\u00adma\u00adtion gain, which is the de\u00adcrease in en\u00adtropy yielded by a node split. I G ( D ) = H ( D ) \u2212 H ( D \u2223 S ) IG(\\mathcal{D}) = H(\\mathcal{D}) - H(\\mathcal{D}|\\mathcal{S}) I G ( D ) = H ( D ) \u2212 H ( D \u2223 S ) It rep\u00adre\u00adsents the amount of in\u00adfor\u00adma\u00adtion gained about our tar\u00adget vari\u00adable given our split. In these terms, the ob\u00adjec\u00adtive is to max\u00adi\u00admize in\u00adfor\u00adma\u00adtion gain. Com\u00adpar\u00ading clas\u00adsi\u00adfi\u00adca\u00adtion ob\u00adjec\u00adtives Al\u00adthough mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate is in\u00adtu\u00aditive and com\u00admonly used as a model met\u00adric, it\u2019s not used as an op\u00adti\u00admiza\u00adtion ob\u00adjec\u00adtive. We can come up with splits ( S \\mathcal{S} S) that have the same mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate, but one has a pure node while the other doesn\u2019t. For in\u00adstance: S = { A : 10 , B : 0 } , { A : 10 , B : 5 } \\mathcal{S} = \\{A: 10, B: 0\\},\\ \\{A: 10, B: 5\\} S = { A : 10 , B : 0 } , { A : 10 , B : 5 } S \u2032 = { A : 10 , B : 2 } , { A : 10 , B : 3 } \\mathcal{S}' = \\{A: 10, B: 2\\},\\ \\{A: 10, B: 3\\} S \u2032 = { A : 10 , B : 2 } , { A : 10 , B : 3 } Both splits mis\u00adclas\u00adsify 5 sam\u00adples of class B (same mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate), how\u00adever the first has a pure node. From an op\u00adti\u00admiza\u00adtion per\u00adspec\u00adtive, we should favor pure nodes as they re\u00adduce the num\u00adber of sub\u00adse\u00adquent splits. You can check that in\u00addeed both the en\u00adtropy and the Gini im\u00adpu\u00adrity of the sec\u00adond split are higher. Check\u00ading that the af\u00adfir\u00adma\u00adtion holds Mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate: M R ( D \u2223 S ) = 10 25 0 + 15 25 5 15 = 0.2 MR(\\mathcal{D}|\\mathcal{S}) = \\frac{10}{25} 0 + \\frac{15}{25} \\frac{5}{15} = 0.2 MR ( D \u2223 S ) = 25 10 \u200b 0 + 25 15 \u200b 15 5 \u200b = 0.2 M R ( D \u2223 S \u2032 ) = 12 25 2 12 + 13 25 3 13 = 0.2 MR(\\mathcal{D}|\\mathcal{S}') = \\frac{12}{25} \\frac{2}{12} + \\frac{13}{25} \\frac{3}{13} = 0.2 MR ( D \u2223 S \u2032 ) = 25 12 \u200b 12 2 \u200b + 25 13 \u200b 13 3 \u200b = 0.2 M R ( D \u2223 S ) = M R ( D \u2223 S \u2032 ) MR(\\mathcal{D}|\\mathcal{S}) = MR(\\mathcal{D}|\\mathcal{S}') MR ( D \u2223 S ) = MR ( D \u2223 S \u2032 ) Gini im\u00adpu\u00adrity: G ( D \u2223 S ) = 10 25 0 + 15 25 0.444 = 0.266 G(\\mathcal{D}|\\mathcal{S}) = \\frac{10}{25} 0 + \\frac{15}{25} 0.444 = 0.266 G ( D \u2223 S ) = 25 10 \u200b 0 + 25 15 \u200b 0.444 = 0.266 G ( D \u2223 S \u2032 ) = 12 25 0.277 + 13 25 0.355 = 0.318 G(\\mathcal{D}|\\mathcal{S}') = \\frac{12}{25} 0.277 + \\frac{13}{25} 0.355 = 0.318 G ( D \u2223 S \u2032 ) = 25 12 \u200b 0.277 + 25 13 \u200b 0.355 = 0.318 G ( D \u2223 S ) < G ( D \u2223 S \u2032 ) G(\\mathcal{D}|\\mathcal{S}) < G(\\mathcal{D}|\\mathcal{S}') G ( D \u2223 S ) < G ( D \u2223 S \u2032 ) For the same rea\u00adson, a tree may get \u201cstuck\u201d when there is no split that min\u00adi\u00admizes the mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate. Gini im\u00adpu\u00adrity and en\u00adtropy con\u00adsider prob\u00ada\u00adbil\u00adi\u00adties, while mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate con\u00adsid\u00aders only the ma\u00adjor\u00adity vote and there\u00adfore is not sen\u00adsi\u00adtive enough. More for\u00admally, both Gini im\u00adpu\u00adrity and en\u00adtropy are strictly con\u00adcave func\u00adtions. If you take two points on the curve of a strictly con\u00adcave func\u00adtion and draw a line be\u00adtween them, the line will be al\u00adways below the curve. Plot of en\u00adtropy H ( p ) H(p) H(p) over prob\u00ada\u00adbil\u00adi\u00adties p p p with two classes. The prob\u00ada\u00adbil\u00adity of the sec\u00adond class is ( 1 \u2212 p ) (1 - p) (1\u2212p). We know from the data pro\u00adcess\u00ading in\u00adequal\u00adity that the av\u00ader\u00adage en\u00adtropy can\u00adnot in\u00adcrease after a split. Ei\u00adther a split re\u00adduces en\u00adtropy in both child nodes \u2014 which re\u00adsults in lower av\u00ader\u00adage en\u00adtropy com\u00adpared to the par\u00adent node \u2014 or one child node has higher en\u00adtropy than the par\u00adent node and the other lower. Both child nodes can\u00adnot have higher en\u00adtropy than the par\u00adent node be\u00adcause this would mean that the split cre\u00adated new in\u00adfor\u00adma\u00adtion (un\u00adcer\u00adtainty), vi\u00ado\u00adlat\u00ading the data pro\u00adcess\u00ading in\u00adequal\u00adity. Thus, we only need to show that the av\u00ader\u00adage en\u00adtropy de\u00adcreases when one child node has higher en\u00adtropy and the other lower com\u00adpared to the par\u00adent node. The strict con\u00adcav\u00adity of the en\u00adtropy func\u00adtion is enough to en\u00adsure this. The av\u00ader\u00adage child node en\u00adtropy lies some\u00adwhere along the line be\u00adtween the points of both child nodes in the curve. The av\u00ader\u00adage prob\u00ada\u00adbil\u00adity must be the same of the par\u00adent node, so the av\u00ader\u00adage child node en\u00adtropy al\u00adways lies di\u00adrectly below the par\u00adent node en\u00adtropy. Hence, there is al\u00admost 5 al\u00adways a split which re\u00adsults in a lower child node av\u00ader\u00adage en\u00adtropy. Mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate is not strictly con\u00adcave. The av\u00ader\u00adage mis\u00adclas\u00adsi\u00adfi\u00adca\u00adtion rate of child nodes is equal to that of the par\u00adent node when both child nodes lie on the same side of the func\u00adtion, halt\u00ading the op\u00adti\u00admiza\u00adtion process. Squared loss L ( D ) = 1 N \u2211 i = 1 N ( y i \u2212 y \u02c9 ) 2 L(\\mathcal{D}) = \\frac{1}{N} \\sum_{i=1}^N (y_{i} - \\bar{y})^2 L ( D ) = N 1 \u200b i = 1 \u2211 N \u200b ( y i \u200b \u2212 y \u02c9 \u200b ) 2 The squared loss func\u00adtion is the pri\u00admary op\u00adti\u00admiza\u00adtion cri\u00adte\u00adrion for re\u00adgres\u00adsion trees. In this equa\u00adtion, y \u02c9 \\bar{y} y\u02c9\u200b rep\u00adre\u00adsents the mean value of the tar\u00adget vari\u00adable y y y within a spe\u00adcific node. This value be\u00adcomes the pre\u00addic\u00adtion ( c c c) for all ob\u00adser\u00adva\u00adtions that fall into that node, fol\u00adlow\u00ading the math\u00ade\u00admat\u00adi\u00adcal de\u00adf\u00adi\u00adn\u00adi\u00adtion of de\u00adci\u00adsion trees. While this for\u00admula re\u00adsem\u00adbles the tra\u00addi\u00adtional mean squared error (MSE) used in many sta\u00adtis\u00adti\u00adcal ap\u00adpli\u00adca\u00adtions, there is an im\u00adpor\u00adtant dis\u00adtinc\u00adtion. In stan\u00addard re\u00adgres\u00adsion mod\u00adels, MSE typ\u00adi\u00adcally mea\u00adsures the dif\u00adfer\u00adence be\u00adtween pre\u00addic\u00adtions ( y ^ \\hat{y} y^\u200b) and ac\u00adtual val\u00adues, where y ^ \\hat{y} y^\u200b can be di\u00adrectly op\u00adti\u00admized through model pa\u00adra\u00adme\u00adters. How\u00adever, in the con\u00adtext of de\u00adci\u00adsion trees, this squared loss func\u00adtion ac\u00adtu\u00adally quan\u00adti\u00adfies the within-\u200bnode vari\u00adance of the tar\u00adget vari\u00adable. This vari\u00adance in\u00adter\u00adpre\u00adta\u00adtion leads to an in\u00adtu\u00aditive un\u00adder\u00adstand\u00ading of the tree-\u200bbuilding process: the al\u00adgo\u00adrithm seeks splits that max\u00adi\u00admize the re\u00adduc\u00adtion in vari\u00adance be\u00adtween the par\u00adent node and its chil\u00addren. This ap\u00adproach, often termed vari\u00adance re\u00adduc\u00adtion, ef\u00adfec\u00adtively par\u00adti\u00adtions the data into in\u00adcreas\u00adingly ho\u00admo\u00adge\u00adneous sub\u00adgroups with re\u00adspect to the tar\u00adget vari\u00adable. The op\u00adti\u00admal split is one that cre\u00adates child nodes with min\u00adi\u00admal av\u00ader\u00adage vari\u00adance, thereby im\u00adprov\u00ading the tree\u2019s pre\u00addic\u00adtive ac\u00adcu\u00adracy. Build\u00ading a de\u00adci\u00adsion tree A suf\u00adfi\u00adciently large tree will have one train\u00ading sam\u00adple per node, ef\u00adfec\u00adtively mem\u00ado\u00adriz\u00ading the train\u00ading set. Such tree achieves 0 train\u00ading error, but it is a patho\u00adlog\u00adi\u00adcal op\u00adti\u00admiza\u00adtion case. Our goal is to build the small\u00adest pos\u00adsi\u00adble tree that achieves 0 train\u00ading error. If lim\u00adits such as max\u00adi\u00admum depth are en\u00adforced, we should find the tree that min\u00adi\u00admizes the ob\u00adjec\u00adtive while re\u00adspect\u00ading such lim\u00adits. Un\u00adfor\u00adtu\u00adnately, the com\u00adpu\u00adta\u00adtional com\u00adplex\u00adity grows com\u00adbi\u00adna\u00adto\u00adri\u00adally and find\u00ading the op\u00adti\u00admal tree is NP-\u200bcomplete. It would be nice to build trees be\u00adfore the heat death of the uni\u00adverse, so we pro\u00adceed with a greedy al\u00adgo\u00adrithm. We make a se\u00adries of lo\u00adcally op\u00adti\u00admal choices, hop\u00ading that it leads to a so\u00adlu\u00adtion some\u00adwhat close to the global op\u00adti\u00admum. Let\u2019s build a clas\u00adsi\u00adfi\u00adca\u00adtion tree using the Gini im\u00adpu\u00adrity cri\u00adte\u00adrion. Start\u00ading with all of the data and the first vari\u00adable, we test all pos\u00adsi\u00adble split points ( N \u2212 1 N - 1 N\u22121 splits) and choose the one with the low\u00adest cri\u00adte\u00adrion. Then, we re\u00adpeat this pro\u00adce\u00addure with all other fea\u00adtures. The split with the low\u00adest cri\u00adte\u00adrion over all fea\u00adtures is cho\u00adsen. Fi\u00adnally, we re\u00adpeat the pro\u00adce\u00addure for the left and right child nodes re\u00adcur\u00adsively until the cri\u00adte\u00adrion is 0 in all nodes or until a tree size limit is reached. Play Rep\u00adre\u00adsen\u00adta\u00adtion of the op\u00adti\u00admiza\u00adtion process con\u00adsid\u00ader\u00ading a sin\u00adgle fea\u00adture. We eval\u00adu\u00adate all split points to find the one that min\u00adi\u00admizes the ob\u00adjec\u00adtive func\u00adtion. The same process must be done with the other fea\u00adtures to choose the op\u00adti\u00admal split. This ap\u00adproach, while com\u00adpu\u00adta\u00adtion\u00adally ef\u00adfi\u00adcient, has sig\u00adnif\u00adi\u00adcant draw\u00adbacks. The pri\u00admary lim\u00adi\u00adta\u00adtion lies in the al\u00adgo\u00adrithm\u2019s in\u00adabil\u00adity to con\u00adsider long-\u200bterm con\u00adse\u00adquences of split de\u00adci\u00adsions. When eval\u00adu\u00adat\u00ading po\u00adten\u00adtial splits, the al\u00adgo\u00adrithm op\u00adti\u00admizes only for im\u00adme\u00addi\u00adate gain, po\u00adten\u00adtially over\u00adlook\u00ading splits that might en\u00adable bet\u00adter down\u00adstream de\u00adci\u00adsions. This my\u00adopic op\u00adti\u00admiza\u00adtion strat\u00adegy in\u00adtro\u00adduces sub\u00adstan\u00adtial model in\u00adsta\u00adbil\u00adity. The cu\u00admu\u00adla\u00adtive ef\u00adfect of these lo\u00adcally op\u00adti\u00admal but glob\u00adally sub\u00adop\u00adti\u00admal de\u00adci\u00adsions makes the re\u00adsult\u00ading tree struc\u00adture highly sen\u00adsi\u00adtive to vari\u00ada\u00adtions in the train\u00ading data (i. e. it\u2019s an\u00adother source of vari\u00adance). In ex\u00adtreme cases, the ad\u00addi\u00adtion or re\u00admoval of a sin\u00adgle train\u00ading ex\u00adam\u00adple can prop\u00ada\u00adgate through the tree struc\u00adture, lead\u00ading to dra\u00admat\u00adi\u00adcally dif\u00adfer\u00adent de\u00adci\u00adsion paths. More\u00adover, this is the main rea\u00adson why re\u00adquir\u00ading a min\u00adi\u00admum de\u00adcrease in loss to split the node is not a good idea. Splits that ap\u00adpear mar\u00adgin\u00adally ben\u00ade\u00adfi\u00adcial in iso\u00adla\u00adtion may be es\u00adsen\u00adtial for ac\u00adcess\u00ading valu\u00adable par\u00adti\u00adtion pat\u00adterns deeper in the tree struc\u00adture. There\u00adfore, the im\u00adme\u00addi\u00adate mag\u00adni\u00adtude of im\u00adprove\u00adment from a split may not re\u00adli\u00adably in\u00addi\u00adcate its ul\u00adti\u00admate con\u00adtri\u00adbu\u00adtion to model per\u00adfor\u00admance. Char\u00adac\u00adter\u00adis\u00adtics of de\u00adci\u00adsion trees As\u00adsump\u00adtions Every ma\u00adchine learn\u00ading al\u00adgo\u00adrithm makes as\u00adsump\u00adtions about the struc\u00adture of the data. Ex\u00adplor\u00ading the en\u00adtire space of pos\u00adsi\u00adble re\u00adla\u00adtion\u00adships be\u00adtween fea\u00adtures and the out\u00adcome is not fea\u00adsi\u00adble, there\u00adfore each al\u00adgo\u00adrithm cuts cor\u00adners in its way. De\u00adci\u00adsion trees as\u00adsume that we can sep\u00ada\u00adrate the data into mean\u00ading\u00adful re\u00adgions by re\u00adpeat\u00adedly split\u00adting on in\u00addi\u00advid\u00adual fea\u00adtures. In other words, they as\u00adsume that the op\u00adti\u00admal de\u00adci\u00adsion bound\u00adary in the fea\u00adture space is axis-\u200baligned, hence fea\u00adture in\u00adter\u00adac\u00adtions can only be cap\u00adtured through hi\u00ader\u00adar\u00adchi\u00adcal struc\u00adture. As with most ma\u00adchine learn\u00ading al\u00adgo\u00adrithms, these as\u00adsump\u00adtions are sel\u00addom strictly true. Nonethe\u00adless, they may be close enough to re\u00adal\u00adity to pro\u00adduce good re\u00adsults. De\u00adci\u00adsion trees, on the other hand, don\u2019t make other re\u00adstric\u00adtive as\u00adsump\u00adtions com\u00admon to many ma\u00adchine learn\u00ading al\u00adgo\u00adrithms: they do not as\u00adsume any prob\u00ada\u00adbil\u00adity dis\u00adtri\u00adb\u00adu\u00adtion nor any lin\u00adear struc\u00adture. They also do not rely on any dis\u00adtance met\u00adric, par\u00adtially evad\u00ading the curse of di\u00admen\u00adsion\u00adal\u00adity6. Fea\u00adture se\u00adlec\u00adtion is baked into the de\u00adci\u00adsion tree al\u00adgo\u00adrithm, so they can ig\u00adnore ir\u00adrel\u00ade\u00advant di\u00admen\u00adsions. Still, as di\u00admen\u00adsion\u00adal\u00adity grows and the data be\u00adcomes sparse, it be\u00adcomes harder to find mean\u00ading\u00adful splits with\u00adout cap\u00adtur\u00ading noise. Pros and cons We can sum\u00adma\u00adrize the main ad\u00advan\u00adtages of de\u00adci\u00adsion trees as: Sim\u00adple to un\u00adder\u00adstand and to in\u00adter\u00adpret Scales rea\u00adson\u00adably well with large datasets Re\u00adquires lit\u00adtle data prepa\u00adra\u00adtion 7 Able to han\u00addle both nu\u00admer\u00adi\u00adcal and cat\u00ade\u00adgor\u00adi\u00adcal data di\u00adrectly Able to ap\u00adprox\u00adi\u00admate non-\u200blinear re\u00adla\u00adtion\u00adships Do not as\u00adsume any spe\u00adcific dis\u00adtri\u00adb\u00adu\u00adtion for the data They also same major draw\u00adbacks, namely: Eas\u00adily cap\u00adture noise and over\u00adfit In\u00adsta\u00adbil\u00adity: highly sen\u00adsi\u00adtive to small changes in the train\u00ading set Lack of smooth de\u00adci\u00adsion bound\u00adary Lack of smooth and con\u00adtin\u00adu\u00adous pre\u00addic\u00adtions in re\u00adgres\u00adsion Strug\u00adgle to cap\u00adture non-\u200bhierarchical con\u00adcepts Ex\u00adtrap\u00ado\u00adla\u00adtion De\u00adci\u00adsion trees do not ex\u00adtrap\u00ado\u00adlate. I didn\u2019t place this ei\u00adther as a pro or a con be\u00adcause it might be both. The de\u00adci\u00adsion tree train\u00ading pro\u00adce\u00addure par\u00adti\u00adtions the fea\u00adture space based on ex\u00adam\u00adples. When a de\u00adci\u00adsion tree en\u00adcoun\u00adters a data point where one or more fea\u00adture fall out\u00adside the bounds of what it was trained on, it sim\u00adply as\u00adsigns the value of the near\u00adest leaf node. There\u00adfore, pre\u00addic\u00adtions re\u00admain con\u00adstant be\u00adyond the bound\u00adaries of the train\u00ading data. This be\u00adhav\u00adior makes the model ro\u00adbust to ex\u00adtreme fea\u00adture val\u00adues, hence it might be de\u00adsir\u00adable in some set\u00adtings. How\u00adever, it\u2019s also a major lim\u00adi\u00adta\u00adtion in do\u00admains where we ex\u00adpect trends to ex\u00adtend be\u00adyond our ob\u00adserved data range. Con\u00adsider the task of pre\u00addict\u00ading house based on con\u00adstructed area. If the train\u00ading data only in\u00adcludes houses up to 250 square me\u00adters, that is the upper bound of our pre\u00addic\u00adtions, even though we would rea\u00adson\u00adably ex\u00adpect larger houses to be more ex\u00adpen\u00adsive. This is an in\u00adher\u00adent in\u00adduc\u00adtive bias of de\u00adci\u00adsion trees. We\u2019ve de\u00adfined de\u00adci\u00adsion trees, their ob\u00adjec\u00adtive func\u00adtions and a gen\u00aderal al\u00adgo\u00adrithm. In the fol\u00adlowup of this se\u00adries we\u2019ll im\u00adple\u00adment clas\u00adsi\u00adfi\u00adca\u00adtion and re\u00adgres\u00adsion trees (CART) in Python. Ref\u00ader\u00adences",
    "published_at": "2025-05-18T02:56:39Z",
    "source": "Mathpn.com",
    "url": "https://mathpn.com/posts/climbing-trees-1/",
    "summary": "This is the first in a se\u00adries of posts about de\u00adci\u00adsion trees in the con\u00adtext of ma\u00adchine learn\u00ading. The goal here is to pro\u00advide a foun\u00adda\u00adtional un\u00adder\u00adstand\u00ading and to im\u00adple\u00adment them. We\u2019ll ex\u00adplore them in the fu\u00adture.",
    "category": "Technology"
  },
  {
    "title": "A guide to the Nvidia products driving the AI boom and beyond \u2014 from data center GPUs to automotive and consumer tech",
    "content": "Nvidia products, such as GPUs and software, are driving the AI boom. Nvidia products, such as GPUs and software, are driving the AI boom. Brittany Hosea-Small/REUTERS This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now. Nvidia products are at the heart of the boom in artificial intelligence. Despite starting in gaming and designing semiconductors that touch many diverse industries, the products Nvidia designs to go inside high-powered data centers are the most important to the company today, and to the future of AI. Graphics processing units, designed to be clustered together in dozens of racks inside massive temperature-controlled warehouses, made Nvidia a household name. They also got Nvidia into the Dow Jones Industrial Average, and put it in the position to control the flow of a crucial but finite resource: artificial intelligence. Nvidia's first generation of chips for the data center launched in 2017. That first generation was called Volta. Along with the Volta chips, Nvidia designed DGX (which stands for Deep GPU Xceleration) systems \u2014 the full stack of technologies and equipment necessary to bring GPUs online in a data center and make them work to the best of their ability. DGX was the first of its kind. As AI has become more mainstream, other companies such as Dell and and Supermicro have put forth designs for running GPUs at scale in a data center too. Ampere, Hopper, Blackwell, and Beyond The next GPU generation designed for the data center, Ampere, which launched in 2020, can still be found in data centers today. Though Ampere generation GPUs are slowly fading into the background in favor of more powerful models, this generation did support the first iteration of Nvidia's Omniverse, a simulation platform that the company purports as key to a future where robots work alongside humans doing physical tasks. The Hopper generation of GPUs is the one that has enabled much of the latest innovation in large language models and broader AI. Nvidia's Hopper generation of chips, which include the H100 and the H200, debuted in 2022 and remain in high demand. The H200 model in particular has added capacity that has proven increasingly important as AI models grow in size, complexity, and capability. The most powerful chip architecture Nvidia has launched to date is Blackwell. Jensen Huang announced the step change in accelerated computing in 2024 at GTC, Nvidia's developers conference, and though the rollout has been rocky, racks of Blackwells are now available from cloud providers. Nvidia unveiled its Blackwell chip at the GTC conference in 2024. Andrej Sokolow/picture alliance via Getty Images Inside the data center, Nvidia does have competitors, even though it has the vast majority of the market for AI computing. Those competitors include AMD, Intel, Huawei, custom AI chips, and a cavalcade of startups. Related stories Business Insider tells the innovative stories you want to know Business Insider tells the innovative stories you want to know The company has already teased that the next generation will be called \"Blackwell Ultra,\" followed by \"Rubin\" in 2026. Nvidia also plans to launch a new CPU, or traditional computer chip alongside Rubin, which it hasn't done since 2022. CPUs work alongside GPUs to triage tasks and direct the firepower that is parallel computing. Nvidia is a software company, too None of this high-powered computing is possible without software and Nvidia recognized this need sooner than any other company. Development for Nvidia's tentpole software stack, CUDA or Compute Unified Device Architecture, began as early as 2006. CUDA is software that allows developers to use widely known coding languages to program GPUs, since these chips require layers of code to work relatively few developers have the needed skills to program the chips directly. Still \"CUDA developer\" is a skillset and there are millions who claim this ability, according to Nvidia. When GPUs started going into data centers, CUDA was ready and that's why it's often touted as the basis for Nvidia's competitive moat. Within CUDA are dozens of libraries that help developers use GPUs in specific fields such as medical imaging, data science, or weather analytics. Nvidia began at home Just two years after Nvidia's founding, the company released its first graphics card in 1995. For more than a decade, the chips mostly resided in homes and offices \u2014 used by gamers and graphics professionals. The current generation includes the GeForce RTX 5090 and 5080, which was released in May 2025. RTX 4090, 4080, 4070, and 4060, were released in 2022 and 2023. GPUs in gaming enabled the more sophisticated shadows, texture, and light to make games hyperrealistic. In addition to the consumer work stations, Nvidia partners with device-makers like Apple and ASUS to produce laptops and personal computers. Though gaming is now a minority of the company's revenue, the business continues to grow. Nvidia has also made new efforts to enable high powered computing at home for the machine-learning obsessed. It launched Project DIGITS, which is a personal-sized supercomputer capable of working with some of the largest large language models. Nvidia in the car Nvidia is angling to be a primary player in a future where self-driving cars are the norm, but the company has also been in the automotive semiconductor game for many years. Nvidia first launched its DRIVE PX, for developing autopilot capabilities for vehicles, in 2015. Kim Kulish/Corbis via Getty Images It launched Nvidia DRIVE, a platform for autonomous vehicle development, in 2015, and over time it developed or acquired technologies for mapping, driver assist, and driver monitoring. The company designs various chips for all of functions in partnerships with Mediatek and Foxconn. Nvidia's automotive customers include Toyota, Uber, and Hyundai.",
    "published_at": "2025-05-17T10:11:01Z",
    "source": "Business Insider",
    "url": "https://www.businessinsider.com/nvidia-products",
    "summary": "Nvidia products are at the heart of the boom in artificial intelligence. Graphics processing units, designed to be clustered together in dozens of racks inside massive temperature-controlled warehouses, made Nvidia a household name.",
    "category": "Technology"
  },
  {
    "title": "Google\u2019s AlphaEvolve: The AI agent that reclaimed 0.7% of Google\u2019s compute \u2013 and how to copy it",
    "content": "Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More Google\u2019s new AlphaEvolve shows what happens when an AI agent graduates from lab demo to production work, and you\u2019ve got one of the most talented technology companies driving it. Built by Google\u2019s DeepMind, the system autonomously rewrites critical code and already pays for itself inside Google. It shattered a 56-year-old record in matrix multiplication (the core of many machine learning workloads) and clawed back 0.7% of compute capacity across the company\u2019s global data centers. Those headline feats matter, but the deeper lesson for enterprise tech leaders is how AlphaEvolve pulls them off. Its architecture \u2013 controller, fast-draft models, deep-thinking models, automated evaluators and versioned memory \u2013 illustrates the kind of production-grade plumbing that makes autonomous agents safe to deploy at scale. Google\u2019s AI technology is arguably second to none. So the trick is figuring out how to learn from it, or even using it directly. Google says an Early Access Program is coming for academic partners and that \u201cbroader availability\u201d is being explored, but details are thin. Until then, AlphaEvolve is a best-practice template: If you want agents that touch high-value workloads, you\u2019ll need comparable orchestration, testing and guardrails. Consider just the data center win. Google won\u2019t put a price tag on the reclaimed 0.7%, but its annual capex runs tens of billions of dollars. Even a rough estimate puts the savings in the hundreds of millions annually\u2014enough, as independent developer Sam Witteveen noted on our recent podcast, to pay for training one of the flagship Gemini models, estimated to cost upwards of $191 million for a version like Gemini Ultra. VentureBeat was the first to report about the AlphaEvolve news earlier this week. Now we\u2019ll go deeper: how the system works, where the engineering bar really sits and the concrete steps enterprises can take to build (or buy) something comparable. 1. Beyond simple scripts: The rise of the \u201cagent operating system\u201d AlphaEvolve runs on what is best described as an agent operating system \u2013 a distributed, asynchronous pipeline built for continuous improvement at scale. Its core pieces are a controller, a pair of large language models (Gemini Flash for breadth; Gemini Pro for depth), a versioned program-memory database and a fleet of evaluator workers, all tuned for high throughput rather than just low latency. A high-level overview of the AlphaEvolve agent structure. Source: AlphaEvolve paper. This architecture isn\u2019t conceptually new, but the execution is. \u201cIt\u2019s just an unbelievably good execution,\u201d Witteveen says. The AlphaEvolve paper describes the orchestrator as an \u201cevolutionary algorithm that gradually develops programs that improve the score on the automated evaluation metrics\u201d (p. 3); in short, an \u201cautonomous pipeline of LLMs whose task is to improve an algorithm by making direct changes to the code\u201d (p. 1). Takeaway for enterprises: If your agent plans include unsupervised runs on high-value tasks, plan for similar infrastructure: job queues, a versioned memory store, service-mesh tracing and secure sandboxing for any code the agent produces. 2. The evaluator engine: driving progress with automated, objective feedback A key element of AlphaEvolve is its rigorous evaluation framework. Every iteration proposed by the pair of LLMs is accepted or rejected based on a user-supplied \u201cevaluate\u201d function that returns machine-gradable metrics. This evaluation system begins with ultrafast unit-test checks on each proposed code change \u2013 simple, automatic tests (similar to the unit tests developers already write) that verify the snippet still compiles and produces the right answers on a handful of micro-inputs \u2013 before passing the survivors on to heavier benchmarks and LLM-generated reviews. This runs in parallel, so the search stays fast and safe. In short: Let the models suggest fixes, then verify each one against tests you trust. AlphaEvolve also supports multi-objective optimization (optimizing latency and accuracy simultaneously), evolving programs that hit several metrics at once. Counter-intuitively, balancing multiple goals can improve a single target metric by encouraging more diverse solutions. Takeaway for enterprises: Production agents need deterministic scorekeepers. Whether that\u2019s unit tests, full simulators, or canary traffic analysis. Automated evaluators are both your safety net and your growth engine. Before you launch an agentic project, ask: \u201cDo we have a metric the agent can score itself against?\u201d 3. Smart model use, iterative code refinement AlphaEvolve tackles every coding problem with a two-model rhythm. First, Gemini Flash fires off quick drafts, giving the system a broad set of ideas to explore. Then Gemini Pro studies those drafts in more depth and returns a smaller set of stronger candidates. Feeding both models is a lightweight \u201cprompt builder,\u201d a helper script that assembles the question each model sees. It blends three kinds of context: earlier code attempts saved in a project database, any guardrails or rules the engineering team has written and relevant external material such as research papers or developer notes. With that richer backdrop, Gemini Flash can roam widely while Gemini Pro zeroes in on quality. Unlike many agent demos that tweak one function at a time, AlphaEvolve edits entire repositories. It describes each change as a standard diff block \u2013 the same patch format engineers push to GitHub \u2013 so it can touch dozens of files without losing track. Afterward, automated tests decide whether the patch sticks. Over repeated cycles, the agent\u2019s memory of success and failure grows, so it proposes better patches and wastes less compute on dead ends. Takeaway for enterprises: Let cheaper, faster models handle brainstorming, then call on a more capable model to refine the best ideas. Preserve every trial in a searchable history, because that memory speeds up later work and can be reused across teams. Accordingly, vendors are rushing to provide developers with new tooling around things like memory. Products such as OpenMemory MCP, which provides a portable memory store, and the new long- and short-term memory APIs in LlamaIndex are making this kind of persistent context almost as easy to plug in as logging. OpenAI\u2019s Codex-1 software-engineering agent, also released today, underscores the same pattern. It fires off parallel tasks inside a secure sandbox, runs unit tests and returns pull-request drafts\u2014effectively a code-specific echo of AlphaEvolve\u2019s broader search-and-evaluate loop. 4. Measure to manage: targeting agentic AI for demonstrable ROI AlphaEvolve\u2019s tangible wins \u2013 reclaiming 0.7% of data center capacity, cutting Gemini training kernel runtime 23%, speeding FlashAttention 32%, and simplifying TPU design \u2013 share one trait: they target domains with airtight metrics. For data center scheduling, AlphaEvolve evolved a heuristic that was evaluated using a simulator of Google\u2019s data centers based on historical workloads. For kernel optimization, the objective was to minimize actual runtime on TPU accelerators across a dataset of realistic kernel input shapes. Takeaway for enterprises: When starting your agentic AI journey, look first at workflows where \u201cbetter\u201d is a quantifiable number your system can compute \u2013 be it latency, cost, error rate or throughput. This focus allows automated search and de-risks deployment because the agent\u2019s output (often human-readable code, as in AlphaEvolve\u2019s case) can be integrated into existing review and validation pipelines. This clarity allows the agent to self-improve and demonstrate unambiguous value. 5. Laying the groundwork: essential prerequisites for enterprise agentic success While AlphaEvolve\u2019s achievements are inspiring, Google\u2019s paper is also clear about its scope and requirements. The primary limitation is the need for an automated evaluator; problems requiring manual experimentation or \u201cwet-lab\u201d feedback are currently out of scope for this specific approach. The system can consume significant compute \u2013 \u201con the order of 100 compute-hours to evaluate any new solution\u201d (AlphaEvolve paper, page 8), necessitating parallelization and careful capacity planning. Before allocating significant budget to complex agentic systems, technical leaders must ask critical questions: Machine-gradable problem? Do we have a clear, automatable metric against which the agent can score its own performance? Compute capacity? Can we afford the potentially compute-heavy inner loop of generation, evaluation, and refinement, especially during the development and training phase? Codebase & memory readiness? Is your codebase structured for iterative, possibly diff-based, modifications? And can you implement the instrumented memory systems vital for an agent to learn from its evolutionary history? Takeaway for enterprises: The increasing focus on robust agent identity and access management, as seen with platforms like Frontegg, Auth0 and others, also points to the maturing infrastructure required to deploy agents that interact securely with multiple enterprise systems. The agentic future is engineered, not just summoned AlphaEvolve\u2019s message for enterprise teams is manifold. First, your operating system around agents is now far more important than model intelligence. Google\u2019s blueprint shows three pillars that can\u2019t be skipped: Deterministic evaluators that give the agent an unambiguous score every time it makes a change. Long-running orchestration that can juggle fast \u201cdraft\u201d models like Gemini Flash with slower, more rigorous models \u2013 whether that\u2019s Google\u2019s stack or a framework such as LangChain\u2019s LangGraph. Persistent memory so each iteration builds on the last instead of relearning from scratch. Enterprises that already have logging, test harnesses and versioned code repositories are closer than they think. The next step is to wire those assets into a self-serve evaluation loop so multiple agent-generated solutions can compete, and only the highest-scoring patch ships. As Cisco\u2019s Anurag Dhingra, SVP and GM of Enterprise Connectivity and Collaboration, told VentureBeat in an interview this week: \u201cIt\u2019s happening, it is very, very real,\u201d he said of enterprises using AI agents in manufacturing, warehouses, customer contact centers. \u201cIt is not something in the future. It is happening there today.\u201d He warned that as these agents become more pervasive, doing \u201chuman-like work,\u201d the strain on existing systems will be immense: \u201cThe network traffic is going to go through the roof,\u201d Dhingra said. Your network, budget and competitive edge will likely feel that strain before the hype cycle settles. Start proving out a contained, metric-driven use case this quarter \u2013 then scale what works. Watch the video podcast I did with developer Sam Witteveen, where we go deep on production-grade agents, and how AlphaEvolve is showing the way:",
    "published_at": "2025-05-17T00:31:12Z",
    "source": "VentureBeat",
    "url": "https://venturebeat.com/ai/googles-alphaevolve-the-ai-agent-that-reclaimed-0-7-of-googles-compute-and-how-to-copy-it/",
    "summary": "Google's new AlphaEvolve shows what happens when an AI agent graduates from lab demo to production work. Built by Google\u2019s DeepMind, the system autonomously rewrites critical code and already pays for itself inside Google.",
    "category": "Technology"
  },
  {
    "title": "Machine helping defeat West's enemies by predicting attacks before they happen...",
    "content": "A MODERN-DAY version of the Enigma machine is being rapidly created by the West to help defeat its enemies - with it already helping Ukraine. The remarkable software is the latest piece of war tech being tested on the frontlines as it aims to predict and repel Russian attacks before they even happen. 9 Ukrainians on the frontlines have already been testing out various advanced pieces of technology Credit: EPA 9 A Ukrainian soldier of an artillery unit fires towards Russian positions outside Bakhmut 9 The tech is being used on the battlefield by Ukraine in various different areas of the military Credit: Getty Estonian-based SensusQ\u2019s Winning Minds technology is able to digest and process real-time information from warzones into valuable facts and figures with ease. This has proven vital on the battlefield in Ukraine across the past three and a half years on the ground, in the air and at sea. The technology combines decades of military and intelligence experience with a top team of software engineers. The official SensusQ team describe their invention as \"the tool they wished they had\" available during their own war time experiences. Erik Markus Kannike, CSO at SensusQ, told The Sun: \"We're unique in the sense that we're focusing more on the kind of smartness behind war. \"We're not producing physical drones or weapons systems but what we do is try to bring that intelligence part of fighting into the 21st century. \"Many people usually think it's already very high tech and as you see in the Hollywood movies but in fact, it's mostly still pen and paper. \"What we see in Ukraine, for example, you have hundreds of drones, if not thousands, currently in the air, all of which are producing information. \"And you have social media and things from satellites but how do you actually manage all this information and make sense of it?\" This is where SensusQ comes in as it is able to automatically process this data and find connections between it all. Saltivka in Kharkiv is the Ukraine\u2019s most bombed housing estate. Locals are living through their very own blitz just like in war-time Britain 80 years ago This can then be presented to people in the simplest form possible so it is easily understandable. Erik also revealed that they have already been partnered with various parties in Ukraine since early on in the war. These range from military users to even law enforcement. He added: \"I can't go into direct detail on what we're doing or who it is with but the end result is the same as we're helping them to make sense of the information that they might miss otherwise.\" The main goal is always to be more effective, to use your resources more effectively and to save lives Erik Markus Kannike There is also a secure app called Verdandi used by soldiers on the ground who file real-time reports on all wartime activity. Another aspect of SensusQ's technology that sets them apart is how the data is used and shared. Whoever is in command of the system - Ukrainian officials for example - control the entire thing. They can program it as they like, deploy it when they want to and the results remain a secret to them only. 9 Bletchley Park cryptographers during WW2 working to crack the Nazi 'enigma' code Credit: Getty 9 A tank is in action during a live fire exercise of Leopard 1A5 crews as part of Ukrainian combat training 9 The main goal is to be more effective, to use resources more effectively and to save lives after many countless civilian deaths across the conflict Credit: Getty SensusQ as a company don't receive the data themselves meaning all the results can stay classified. One of the other key areas is the time it takes for the device to collect the data. On a battlefield, the situation can rapidly change day-to-day meaning that a lot of information has to be short term and quickly adjusted. This means any system must be able to kick into action fast - and the Winning Minds tech can often be set up within a few hours. We're not producing physical drones or weapons systems but what we do is try to bring that intelligence part of fighting into the 21st century Erik Markus Kannike SensusQ has now even developed a system which involves digital maps which helps with \"situational understanding\" in conflict zones. \"You're able to actually look at long-term patterns and you're able to see who's connected to what,\" Erik added. \"Then, based on this information, you're already able to start predicting. \"If you are actively fighting, the pace is such that you rarely have the time to actually do detailed analysis and craft future plans but with our system it allows them to actually have that perspective and to present it. \"The main goal is always to be more effective, to use your resources more effectively and to save lives.\" What was the enigma machine? THE Enigma machine was a secret cipher device used by Nazi Germany during World War II to encode and decode secret messages. It was an electromechanical device that utilised a series of rotors and a plugboard to create complex encryptions around what the Nazis had planned. The secrecy of the device made it extremely difficult to decipher what was being talked about without the correct settings to unlock it. The machine played a significant role in military communications for years before it was finally cracked by a clever allied team. In total, there were around a billion possible combinations which were required to use the system. The Brit often credited with solving the war-saving puzzle is Alan Turing. The cracking of the Enigma codes is widely regarded as one of the greatest achievements in cryptography and intelligence history. SensusQ has been designed to essentially eliminate mistakes in war and ensure that no information obtained ever goes to waste, Erik said. He also spoke on how valuable the Ukraine war has been to help develop the system over the past few years. Erik said: \"The lessons we've learned from Ukraine, and we are still learning are invaluable. \"They've affected a lot of how the system works as there's some things that you cannot imagine. \"The pace of innovation in Ukraine is quite incredible so we continuously take those lessons learned and integrate into our software.\" Could the UK ever use the tech? Erik says the SensusQ software is available to whichever allied nation needs it most at any given time. The tech is set to be a major player in the world of combat should a continental conflict ever break out or even a world war. The lessons learnt in Ukraine have already helped out other European states, Erik says. This is because the information collected on the battlefields of Kursk, Donetsk and beyond are already being reflected and passed on to other clients. Erik also noted that the UK in particular would be in a similar position to Ukraine should they go to war with a larger nation such as Russia or even China. The world can and SHOULD learn from Ukraine EXPERTS have said the way Ukraine has handled themselves in their gruelling conflict is something other military's can aspire towards. Kyiv has constantly come up with new plans of attack from the use of SensusQ to its ingenuous guerrilla warfare tactics to deplete Vlad's army. Colonel Hamish De Bretton Gordon told The Sun: \"They've changed the way we fight, and the use of AI to control multiple thousands of drones at a time is something all us military people are looking at and learning from. \"I know that the British army itself is looking at it, to see how they can learn. \"How can they fight as effectively as these, in effect, amateurs who have very quickly become a professional. \"The ways of fighting and technology always accelerate during warfare, and we've had over three years of it now. \"What we must do as a country is make sure we're absolutely up to speed, and are learning and copying all the really good things that Ukraine has done.\" He said: \"The key, as we're seeing both in the UK and in Europe, is we understand that numerically and maybe in terms of equipment, it's hard to compete with whoever our potential adversaries are. \"Take Russia, they have a million personnel and quite a large capacity to rejuvenate their equipment and their armoured vehicles etc. \"So what needs to happen is that we need to use what we have in a smarter way so choosing what to hit becomes more and more important. \"So you have to have what we call decision dominance where you need to understand the enemy better than the enemy understands themselves. \"And this is what we aim to provide to the entire alliance.\" 9 Personnel from the RAF and Royal Navy already conduct sophisticated training operations using advanced technology Credit: SWNS 9 A Ukrainian servicewoman uses a VR set to operate an FPV drone in Ukraine Credit: Getty",
    "published_at": "2025-05-17T13:43:37Z",
    "source": "The-sun.com",
    "url": "https://www.the-sun.com/news/14235429/ukraine-war-tech-predicts-attacks-sensusq/",
    "summary": "The software is the latest piece of war tech being tested on the frontlines. It aims to predict and repel Russian attacks before they even happen. Estonian-based SensusQ\u2019s technology is able to digest and process real-time information from warzones.",
    "category": "Technology"
  },
  {
    "title": "What Counts as Learning When AI Can Imitate It?",
    "content": "So, here\u2019s the question: What does it mean to say someone has learned something when a machine can now do the same task? Artificial intelligence can generate essays, solve problems, and simulate fluent conversation. But that\u2019s not deception. It\u2019s behavior. AI responds to prompts with outputs shaped by exposure to vast datasets and patterns reinforced during training. It behaves the way it was programmed, just like students behave based on instruction, feedback, and reinforcement. Both produce responses that resemble learning. But the resemblance ends at the surface. The difference isn\u2019t whether the response is correct, it\u2019s why it happens, and what follows. AI doesn\u2019t know when its output is meaningful, persuasive, or off base. It operates within engineered loops, with no contact with consequence, no personal stake, no history of navigating environments where behavior leads to opportunity or exclusion. Humans do. A student may revise an argument after critique, adjust after public failure, or shift direction after success. These are adaptive behaviors, shaped by feedback and personal relevance. Human behavior unfolds in environments where consequences matter. That\u2019s what makes it meaningful and that\u2019s what makes it learning. The Trouble With Internal Definitions of Learning For decades, education has defined learning in terms no one can observe. We say students \u201cunderstand,\u201d \u201cgrasp concepts,\u201d or \u201cdevelop critical thinking skills.\u201d But these phrases describe assumed internal states, not visible outcomes. They may sound rigorous, but they leave educators and students guessing. In practice, this creates confusion. One instructor may see \u201ccritical thinking\u201d as questioning assumptions. Another defines it as connecting ideas across fields. A third uses it as shorthand for writing clearly. Students are left interpreting expectations and often rely on grades, approval, or effort as stand-ins for clear goals. From a behaviorist view, most notably advanced by B. F. Skinner, this is a problem of definition. Learning must be observable: something a student can do that they couldn\u2019t reliably do before. That doesn\u2019t make it simplistic. Writing persuasively, solving problems, or facilitating a discussion are complex but observable behaviors. As long as learning is defined by what can\u2019t be seen, we\u2019ll keep mistaking performance for growth and leave the door open for machines to imitate what we never made visible. Why Behaviorism Isn\u2019t Dehumanizing, It\u2019s Clarifying Behaviorism has long been misunderstood. Critics dismiss it as cold or robotic, as if it denies the inner life of the learner. But that\u2019s a misreading. Behaviorism doesn\u2019t deny thought or complexity. It simply refuses to define learning based on what can\u2019t be seen, tested, or taught. Instead, it asks a practical question: What changed in behavior as a result of instruction? This perspective doesn\u2019t diminish humanity, it grounds it. Defining learning behaviorally gives educators and students a shared language: not about what someone \u201cgets,\u201d but about what they can do. A student doesn\u2019t just \u201cunderstand persuasion,\u201d they write a convincing letter. They don\u2019t just \u201cdevelop empathy\u201d\u2014they conduct an interview, restate the speaker\u2019s main points, ask follow-up questions about personal experiences, and modify their response based on what was shared. These are meaningful, complex, and human behaviors. And they are teachable. In this light, behaviorism isn\u2019t reductive. It\u2019s accountable. It doesn\u2019t settle for belief or intention. It demands evidence of learning, not to control students, but to support them. If learning isn\u2019t observable, we can\u2019t teach toward it. And if we can\u2019t detect or describe what changed, we can\u2019t help it grow. Relevance and Responsibility: What Machines Lack Both AI and humans can produce behavior in response to prompts. But only humans respond to relevance. That\u2019s the critical difference. AI doesn\u2019t know when its output is meaningful, harmful, persuasive, or out of place. It behaves based on statistical likelihood, not social context. It doesn\u2019t monitor consequences or shift behavior based on lived experience. Humans do. When a student adjusts a presentation after seeing classmates lose interest, rethinks a position after peer feedback, or applies a skill because they see its value, that\u2019s relevance at work. It\u2019s not a feeling. It\u2019s a functional relationship between behavior and environment. It reflects learning shaped by consequences. In behaviorist terms, this is what distinguishes adaptive human behavior: it\u2019s shaped and maintained by the interplay between action and outcome. AI may generate impressive performance, but it doesn\u2019t live with the results. Humans do. And in that lived response to relevance, social, academic, and professional learning takes root. Redefining Learning in Behavioral Terms If we want to distinguish real learning from imitation, we have to define it in observable terms not as \u201cmastery\u201d or \u201cmindset,\u201d but as action. What can the learner do now that they couldn\u2019t do before? Can they apply a skill in a new situation? Can they revise work based on feedback? Can they adapt when the environment changes? These are the markers of learning not because they\u2019re easy to measure, but because they\u2019re the only things we can reliably teach, observe, and build on. Learning is a change in behavior that results from experience, persists over time, and transfers across contexts. Writing that persuades, conversations that build trust, problem-solving that holds up beyond the classroom, these are human behaviors with human consequences. And they are the clearest proof that instruction worked. Artificial intelligence hasn\u2019t broken education. It has revealed how poorly we define learning. When machines can generate the same assignments we once used to measure growth, the issue isn\u2019t that they\u2019re too good. It\u2019s that our benchmarks have been too vague. Behaviorism doesn\u2019t reduce learning, it rescues it. It refocuses us on what matters: not what students feel, but what they can do. In a world of polished imitation, only behavior grounded in relevance and consequence can show us what was actually learned. And because learning matters, we owe it the clarity of a definition and the honesty of observation.",
    "published_at": "2025-05-17T17:16:32Z",
    "source": "Psychology Today",
    "url": "https://www.psychologytoday.com/us/blog/how-we-learn/202505/what-counts-as-learning-when-ai-can-imitate-it",
    "summary": "Artificial intelligence can generate essays, solve problems, and simulate fluent conversation. But that\u2019s not deception, it's behavior. AI doesn\u2019t know when its output is meaningful, persuasive, or off base.",
    "category": "Technology"
  },
  {
    "title": "OCaml Web Development: Essential Tools and Libraries in 2025",
    "content": "Should you use OCaml for web projects? Web development trends are a hotly debated topic in the computer programming world and the familiar faces of languages and frameworks are unlikely to change: hypertext markup language or HTML, CSS, and JavaScript are the core technologies (with server-side technologies such as PHP, Python, etc.), and React, Vue, Svelte, and Angular are proving to be as popular as ever. AI and machine learning might be the biggest foreseeable changes to the industry, driving the emergence of new tools and workflows. But there is something else gaining momentum in the world of web development: functional programming! Functional programming fits in well with the web world. The transactional nature of HTTP and the convergence towards immutable state management solutions (such as Redux and consort) make OCaml a very good candidate for web application development. In this article, we give you an overview of some of the web solutions supported by the OCaml ecosystem. It's important to note that we can't include every single one of the web development libraries available for OCaml, as there are simply too many for one post! Functional Programming, OCaml, and the Web Why do some developers use functional programming for web development? Functional programs leverage concepts like immutability, higher-order functions, and formal verification to achieve, among other beneficial outcomes, better code reusability, parallelism, and fewer bugs. These developer-friendly qualities that simplify programming and increase productivity are behind the rising interest in FP for front- and backend web development. As a functional programming language, OCaml offers great scalability for user projects by making it easy to build large systems without sacrificing maintainability. Thanks to the expressive type system, it is easy to refactor and adjust projects during development and as requirements change and evolve. The type-checker is reliable and covers 100% of the code, making it easier for developers to verify that data is used correctly in operations. With these features and the general benefits of FP, we're noticing a growing interest among software developers using OCaml to create web applications. There are several tools and libraries designed for web development in OCaml and a lot is possible with the language. Some workflows are still being developed, and many developers are building new projects and sharing them with the open-source community for feedback. Before we begin, there are three notable industry success stories, BeSport, Ahrefs, and Routine. BeSport is a popular French sports social app built using Ocsigen, a full-stack modular web framework for OCaml that empowers developers to build websites, web applications, and even mobile applications. Ahrefs, the world-leading marketing intelligence platform, uses full-stack OCaml for their web stack and has been very successful migrating to Melange. Routine, an integrated work platform that organises all your data in one place, uses Dream and wasm_of_ocaml to run their tools. With these companies showing how to leverage OCaml's potential, let's move on to the tools and libraries that make it all possible! Ocsigen: A Complete Framework Ocsigen is a collection of projects that provide a complete framework for developing web and mobile apps in OCaml. It is suitable for various uses, from simple server-side websites to client-side programs and complex client-server applications. The projects included under its umbrella are: Lwt, a general purpose concurrency library for OCaml; TyXML, for generating typed XML; Js_of_ocaml, which compiles OCamly bytecode from JavasScript and WASM; Eliom, which is a multi-tier framework for client-server web and mobile apps; Ocsigen server, a web server; Ocsigen Toolkit, a client-server widget library for Eliom and Js_of_ocaml; and Ocsigen Start, a higher level library providing user management and an application template that can be used as a basis for apps or to learn. The projects are mostly independent of each other, so users can pick and mix what they are interested in. Ocsigen's design focuses on a couple of main strengths. Firstly, it takes full advantage of OCaml's expressive type system to check multiple programs' properties at compile time. This approach drastically reduces the development time of complex apps and makes it easier to refactor an application's code to facilitate new features. Secondly, using the Eliom framework enables multi-tier (also known as universal) programming where an application's client and server side are written using the same language and as a single code, with annotations in the code to indicate which 'side' the code should be run. As a result, both the server and client parts of a web application can be implemented as one program. This method affords the developer a lot of flexibility to, for example, generate parts of pages either in the client or server code, depending on their needs. It also streamlines communication between server and client since programmers can use server-side variables in client code or call server-side OCaml functions from client code. It also makes it easy to deploy web and mobile multi-platform applications. Android and iOS apps are generated from the same exact code of the web app and run in a web view. There are loads of resources available online to learn more about Ocsigen. Check out this presentation on Watch OCaml for an overview of the framework. For an example of what a mobile app developed using Ocsigen looks like, you can download the BeSport app on Google Play or the Apple app store. Backends Backend web development creates the foundations of the web, being the server-side portion of the website you don't see that implements the functionality of what you do see in your web browser. Common languages include Python, Ruby, and Java, just to name a few. OCaml has several web frameworks that enable you to do backend development, including options for beginners (e. g. Dream) as well as more experienced software engineers (e. g. Ocsigen). Dream Dream is a backend for OCaml that is well-liked for its simplicity and minimalist approach. Developer experience is a central tenet of its design, achieved by having a simple API and relying on fundamental OCaml types like string and list , only introducing a few of its own types. For a newcomer, the web framework offers extensive documentation and plenty of examples to get them started. Further examples of its quality-of-life features include unified error handling, a simple logger, a minimalist programming model that lets the developer create web servers just using functions, and cryptography helpers and key rotations to set up security options. The Dream web framework is composed of several sub-libraries with different dependencies, which allow the user to port their projects to a variety of environments according to their needs. Furthermore, Dream is unopinionated and low-level, letting users pick and choose how they want to use it. They can swap out libraries to use other tools instead of its built-in templates (such as mlx). Essentially, the framework aims to be easy to use but highly configurable, giving the user the choice between customisation and simplicity. More concretely, Dream provides HTML templates (for OCaml or Reason); helpers for secure cookies and CSRF-safe forms; easy HTTPS, HTTP/2 and WebSockets support (meaning it supports most modern Web transport protocols); full-stack ML with clients compiled to Melange, ReScript, or Js_of_ocaml \u2013 and more! If you want to try Dream, check out the tutorials. We also recommend this blog post on the Ceramic Hacker website, part two in an OCaml web development series that covers using Dream as a backend. It has some concrete code examples and gives a nice overview of a project. Of course Dream's homepage is also an incredibly useful resource. Interop With JS, TS, and Wasm JavaScript is the reigning monarch of programming languages for the web, powering web servers and adding interactivity and dynamic elements to web pages. With a vast array of tools and features in a mature ecosystem, JavaScript cross-compatibility is a must for languages aiming to expand onto the web. Wasm, or WebAssembly, on the other hand, is a portable compilation target that enables deployment on a variety of platforms. It is popular for its security guarantees, speed, and language- and platform- neutrality. Js_of_ocaml Js_of_ocaml compiles OCaml bytecode into JavaScript. This allows you to create dynamic and interactive elements on web pages and use tools like Node. js. You can install js_of_ocaml using opam or Dune, with the latter providing native support. Some of the benefits of js_of_ocaml include its ease of use; it is simple to install and works with an existing installation of OCaml without requiring you to recompile your libraries. It also comes with existing bindings for many browser APIs and is stable and easy to maintain. Plus, performance comparisons have indicated that js_of_ocaml typically outperforms the OCaml type code interpreter. Furthermore, by generating JavaScript from OCaml bytecode, js_of_ocaml relies on a very stable interface that allows it to easily remain compatible with new compiler releases and most of the OCaml ecosystem. To try it out yourself, there's a great js_of_ocaml tutorial by Jack Strand showing you how to create an interactive animation for a website. There are also some examples of js_of_ocaml in action, like this animated 3D view of the earth and a Boulder Dash style game. Wasm_of_ocaml Wasm_of_ocaml takes OCaml bytecode and transforms it into Wasm code. Originally forked from the js_of_ocaml compiler (and now merged back) it is of a similar, lightweight design. WebAssembly provides a sandboxed environment and enforces memory safety, making it popular among users who develop mission- and security-critical applications. Wasm_of_ocaml uses the WebAssembly garbage collection extension, removing the need to implement a garbage collector through other means and enabling good interoperability with JavaScript. One of the compiler's biggest benefits is its speed, with some very impressive results from recent benchmarks driving renewed excitement. Compared to js_of_ocaml , programs compiled with wasm_of_ocaml are consistently faster. For example, Jane Street reported that they observed 2x-8x performance improvements using wasm_of_ocaml compared to js_of_ocaml . You can learn more about wasm_of_ocaml from our blog and in the repo's readme. Melange Melange is another backend for OCaml, consisting of a set of tools that makes it capable of generating and interacting with JavaScript. The tools include a compiler and compiler libraries, which can generate JavaScript code, and the runtime, which consists of a series of supporting libraries written in JS which output 100% JS. This makes interoperability and incremental adoption much easier for new users, albeit at the small cost of needing to write OCaml or Reason in a slightly different way. One of Melange's biggest strengths is that it provides support for many different tools such as the editors VSCode, Vim, and Emacs, full integration with the very popular build system Dune, and interoperability with the documentation tool odoc which can generate a diverse range of documentation from the user's files. Overall, Melange's integration with the OCaml Platform gives the user access to the great resources of the OCaml Ecosystem. Melange integrates with JavaScript through an expressive bindings language. This opens up the JavaScript ecosystem to the OCaml programmer, allowing them to use existing JavaScript packages and their own JavaScript libraries in OCaml projects and build applications that rely on features from the JavaScript ecosystem by working well with the syntax extension format ppx, Melange benefits from its performance, functionalities, and compatibilities. You can try Melange in the Melange Playground and learn more about its finer details on Melange's documentation website. For those familiar with ReactJS, there is an excellent online resource specifically aimed at React developers who want to learn Melange. It provides a hands-on introduction to Melange with several projects and examples. Melange offers excellent support for React codebases, with clear JS outputs and first-class support for many React patterns. David Sancho, one of Melange's maintainers, regularly produces very good content on his blog about the use of Melange in real-life applications, for example: Server-side rendering React in OCaml. This elegant interoperability with ReactJS demonstrates Melange's desire to interface easily with the JavaScript ecosystem, making OCaml a serious replacement for TypeScript, while continuing to benefit from the vast ecosystem of the JavaScript world! Frontend Frontend web development refers to the creation and editing of the graphical user interface of a website, including everything pertaining from HTML editing and rendering to web design, up to client-side web applications that run entirely in the browser. The underlying languages for frontend web development include HTML, cascading style sheets or CSS, JavaScript and WebAssembly. There are also popular platforms for frontend web development, such as Wordpress. OCaml-VDom The ocaml-vdom library, developed by Lexifi, implements an Elm-like architecture and VDOM for OCaml. An Elm architecture refers to a development pattern that is used to create interactive programs. The Elm architecture is a reformulation of a Moore machine, adapted to the construction of user interfaces. It enables the state of an application to be controlled using 3 ingredients: A Model: the state of the application, A View: A function which takes a model and returns the representation of the UI (in the case of Elm and OCaml-vdom , an HTML document); this document allows messages to be propagated, triggering the final ingredient, , an HTML document); this document allows messages to be propagated, triggering the final ingredient, An Update: A function that takes a Message (propagated by the View ) and the current model as arguments and computes a new model, which will be passed to the view to rebuild the UI. In practice, the Elm architecture also introduces the notion of Command and Subscription to interact with discrete effects and communicate with the outside world. This approach is very expressive for describing reactive interfaces and is the result of several iterations described by the creator of Elm in the following essay: Elm: Concurrent FRP for Functional GUIs. After much experimentation, he has drastically simplified the user experience of Functional Reactive Programming with the Elm architecture! OCaml-vdom is a very faithful implementation of the Elm architecture, giving OCaml the ease and expressiveness to describe rich web interfaces. To explore some examples and test OCaml-VDom yourself, visit the ocaml-vdom library and get hacking! Bonsai Bonsai is a client-side web framework created by Jane Street that lets users build web pages from the client (the browser) by creating components. For those familiar with other web development frameworks, Bonsai fills the same role as, for example, Angular and Vue, but it is written entirely in OCaml. The structure of Bonsai is as a group of components, each representing one part of the final page, available in the bonsai_web_components repo. One of the benefits of the framework's design is that, instead of structuring its components like a tree, it does so in a \"structured acyclic graph\". This lets programmers create components that can 'communicate' with each other much more easily than with frameworks that use the tree structure. To learn more about the framework, we definitely recommend the same article series mentioned above from the 'Ceramic Hacker' blog, especially starting from the Setting up Bonsai post. In it, Alexander Skvortsov illustrates why he found Bonsai excellent for building \"safe, massively scalable, performant UIs\". \u2026 And Many More There are plenty more libraries available for web development in OCaml, and we have not been able to include them all in this post. For example, Brr provides a toolkit for programming browsers in OCaml using Js_of_ocaml; the Lwd library enables reactive programming in the browser through a simple form of incremental computation; Vif is an experimental program that runs an OCaml script and launches a web server from it; React is a functional reactive programming library for OCaml; ReScript is a typed language that grew out of OCaml, now used to write fast and human-readable JavaScript for the web; and Wasocaml is another WebAssembly compiler developed by OCamlPro which works differently than Wasm_of_ocaml. Furthermore, several big OCaml projects were developed in connection with extensive research done at universities, including projects like Ocsigen and MirageOS (check out Unipi for a great example of a static web server built with MirageOS). For example, 'Rethinking Traditional Web Interaction' is an interesting paper exploring the future of web development far ahead of its time, research which directly impacted Ocsigen's design! While this post has focussed on application development frameworks, MirageOS offers a robust, mature, and efficient deployment solution similarly grown out of a rich academic history. When deploying a traditional application, it is common to separate it into multiple execution units (i. e., microservices). However, each of these services requires an OS (and ideally containerisation). MirageOS is a framework that allows developers to define an operating system (executed by the CPU's hypervisor) that only runs a limited set of tasks: a unikernel. This enables the creation of very lightweight operating systems designed to perform only a restricted set of tasks, significantly reducing the attack surface and boot time. As a result, MirageOS provides an advanced set of tools for development using microservices. Since OCaml is an excellent choice for building compilers and build systems, there are many advanced static web site generators to choose from! Without going into too much detail, we'd like to mention Soupault, a highly flexible HTML processor that offers a great deal of freedom when it comes to building static pages; Stog, a mature tool with a huge number of plugins; and YOCaml, a very generic framework for composing your own static site generator. There are many others, and since a static site generator is a specialised version of a build system, Dune can even be used as one! In any case, OCaml is a useful (and fun) choice for creating a static site, which also works well alongside MirageOS for deploying very small static servers or using Git as a static file system (directly conceivable with Yocaml_git). These are just a few examples of the things we didn't cover here, and there are many more great projects out there to discover. If you think we've missed one, please let us know! Until Next Time Thank you for checking out this article on web development in OCaml. We have tried to capture as much information as possible in one place (as you can probably guess from the length of this post!) and we look forward to hearing your feedback. Have you developed any web applications using OCaml? What was your experience? Connect with us on Bluesky, Mastodon, Threads, and LinkedIn. We look forward to hearing from you!",
    "published_at": "2025-05-17T19:13:07Z",
    "source": "Tarides.com",
    "url": "https://tarides.com/blog/2025-05-15-ocaml-web-development-essential-tools-and-libraries-in-2025/",
    "summary": " functional programming fits in well with the web world. The transactional nature of HTTP and the convergence towards immutable state management solutions (such as Redux and consort) make OCaml a good candidate.",
    "category": "Technology"
  },
  {
    "title": "Behind Silicon Valley and the GOP's campaign to ban state AI laws",
    "content": "Greetings all, Today, we dive deep into the GOP\u2019s radical campaign to ban US states from passing any laws that govern AI. Even in a political moment as fraught as ours, this one stands out. We\u2019ll get into: How a proposal to ban AI lawmaking wound up in the budget reconciliation bill the same week that AI execs took a trip with Trump to Saudi Arabia How the GOP plans to try to sell its state AI ban, according to the GOP A look at what the implications are for AI in general An interview at the end with California Assemblyman Isaac Bryan, author and co-sponsor of some of the AI bills Silicon Valley wants dead I\u2019m not going to lie, this was a dark week, and a tough one to report through\u2014I meant to publish this on Tuesday, then Wednesday, and the new twists and revelations in how this campaign came together just kept piling up. It took many hours to research, investigate, and write this story. To that end, Blood in the Machine is 100% reader supported, and made possible by paid subscribers. If you find value in this work, and if you can, your support would be immensely appreciated. On Sunday, May 11th, Republicans added a sweeping amendment to the 2025 budget reconciliation bill that would ban all US states from enacting any laws regulating AI for ten years. Reconciliation is a common way for a party to try to push through controversial or unpopular legislation that might not survive a regular Senate vote (budgets can\u2019t be filibustered, and need just a simple majority to pass). Even so, this amendment, put forward by the Kentucky congressman and energy and commerce committee chair Brett Guthrie, managed to shock. The amendment drew admonitory headlines, consternation in Democrats, and anger and disbelief on social media. The outcry is well deserved. The bill\u2019s language is not ambiguous. It says that \u201cno State or political subdivision thereof may enforce any law or regulation regulating artificial intelligence models, artificial intelligence systems, or automated decision systems during the 10-year period beginning on the date of the enactment of this Act.\u201d Take a minute to absorb what\u2019s being proposed here: No state may enforce any law or regulation of AI. A total ban of state lawmaking on what is routinely touted as the most transformative commercial technology of our generation. And because we can safely assume there will be no serious efforts to regulate AI by the GOP-controlled Congress or by a Trump administration intent on helping the US AI industry dominate, this is, in effect, an effort to ban any lawmaking around AI whatsoever, for the next two to four years, while Republicans have a stranglehold on power. All of this is, needless to say, profoundly undemocratic. Both in approach\u2014the act of sliding a bill with such severe repercussions into the reconciliation process, where it won\u2019t receive a proper public hearing\u2014and intent: to prevent the public from having a vote on how pervasive Silicon Valley technologies are impacting their lives. Worse still, Gutherie\u2019s amendment is the culmination of a multi-pronged lobbying effort from the major AI companies. That effort\u2019s aim, as reported by Politico, was to shut down state laws that might constrain AI firms\u2019 and investors\u2019 ability to profit off of AI products\u2014especially California\u2019s. AI industry pitchmen are fond of saying that AI is a powerful tool for \u201cdemocratization.\u201d It has instead become a force for the opposite. On Tuesday, at about the same time that the proposed language seeking to ban state AI regulation was officially being introduced in Congress, a bevy of tech billionaires including Sam Altman, Elon Musk, Nvidia CEO Jensen Huang and Amazon CEO Andrew Jassy were at lunch with president Trump in Saudi Arabia. There, the tech titans cut billion dollar deals with Gulf State royalty and the Trump Administration. Trump announced a $142 billion defense and AI services sale to Saudi Arabia. DataVolt, a Saudi Arabian company will spend $20 billion on data centers in the US. Amazon is investing $5 billion in Humain, Mohammed bin Salman\u2019s AI startup. Nvidia is selling billions of dollars worth of chips to Humain. Meanwhile, OpenAI is mulling a StarGate project in the United Arab Emirates; MGX, the Emirati investment firm, is already a backer of its fledgling Texas data megacenter. And on and on it goes. I hope this fact escapes no one: While the executives of AI firms are abroad in Saudi Arabia, cutting billion dollar deals to expand their operations with nations boasting some of the worst human rights records in the world, their lobbyists and partners back home are trying to make it impossible to pass any laws governing their AI products at all. With states\u2019 rights to legislate AI under assault, I reached out to lawmakers to see how the move in DC was reverberating back home. \u201cThe tech industry was incubated, cultivated, and continues to grow and innovate here in California,\u201d says Isaac Bryan, a California assemblyman who has authored a state bill that limits the ways AI can be used for surveillance in the workplace\u2014one of the bills that the GOP amendment would ban. (Bryan also happens to represent my district in the CA assembly.) \u201cCalifornia deserves the right, and has the expertise, to lead. We\u2019ve been establishing meaningful guardrails and regulations around these advancements so that we center people as we continue to innovate.\u201d But now there\u2019s a gulf between who gets a say in AI policy, Bryan says, and who doesn\u2019t. \u201cThere's the needs that everyday folks have,\u201d he says, \u201cand there's the needs that our tech billionaire class has\u2014and those are the only ones being addressed.\u201d Samantha Gordon, a program director at TechEquity, a nonprofit group of tech workers that advocates for housing and labor issues, and that has backed a number of California AI bills, tells me that widening gulf is by design. \u201cThis amendment is the direct result of a campaign by Google, Meta, OpenAI, and venture capitalists like Andreessen Horowitz\u2014and their dozens of trade associations\u2014to bulldoze through the public's safety in order to continue to make risky bets on a precarious and potentially hazardous technology,\u201d Gordon says. Public polling shows bipartisan support for more regulation of AI, after all, not less. And yet, as Gordon puts it, \u201cif this amendment passes, not a single state in America could protect people from AI systems that unfairly deny their medical care, keep their nursing homes understaffed, revoke their unemployment benefits, or inflate their rent.\u201d It\u2019s part of what she says is a \u201ccynical campaign\u201d the tech industry is waging \u201cto override the will of the public.\u201d Now, there\u2019s a good possibility that this aggressive language won\u2019t survive the Byrd Rule\u2014a law that restricts what can be included in the reconciliation process to measures that affect spending levels and revenue\u2014but it might. And GOP leadership, which now counts Silicon Valley insiders and AI bulls like Musk, Andreessen, and David Sacks among its inner circle, may deem it worth the legal challenges. And even if the language does gets stripped we cannot afford to ignore what it tells us: Top Republicans and top players in the AI industry can now move as a united front. The time of AI industry leaders paying lip service to AI as a technology that \u201cbenefits all of humanity,\u201d a line that has been withering on the vine for a while now, is gone. In its place is a cold calculus bent on using the technology and its logic to accumulate as much power as possible. So let\u2019s run down why it is the AI companies are so intent on stopping these state-level bills, why the GOP is so interested in helping them, and how this changes the very way we should think about AI as a technology. You may have noticed in the above language in the bill goes beyond \u201cAI\u201d and also includes \u201cautomated decision systems.\u201d That\u2019s likely because there are two California bills currently under consideration in the state legislature that use the term; AB 1018, the Automated Decisions Safety Act and SB7, the No Robo Bosses Act, which would seek to prevent employers from relying on \u201cautomated decision-making systems, to make hiring, promotion, discipline, or termination decisions without human oversight.\u201d The GOP\u2019s new amendments would ban both outright, along with the other 30 proposed bills that address AI in California. Three of the proposed bills are backed by the California Federation of Labor Unions, including AB 1018, which aims to eliminate algorithmic discrimination and to ensure companies are transparent about how they use AI in workplaces. It requires workers to be told if AI is used in the hiring process, allows them to opt out of AI systems, and to appeal decisions made by AI. The Labor Fed also backs Bryan\u2019s bill, AB 1221, which seeks to prohibit discriminatory surveillance systems like facial recognition, establish worker data protections, and compels employers to notify workers when they introduce new AI surveillance tools. It should be getting clearer why Silicon Valley is intent on halting these bills: One of the key markets\u2014if not the key market\u2014for AI is as enterprise and workplace software. A top promise is that companies can automate jobs and labor; restricting surveillance capabilities or carving out worker protections promise to put a dent in the AI companies\u2019 bottom lines. Furthermore, AI products and automation software promise a way for managers to evade accountability\u2014laws that force them to stay accountable defeat the purpose. OpenAI already won a major victory in beating back state level policy earlier this year, after Assemblywoman Diane Papan, who had proposed a bill aimed at preventing nonprofits from restructuring as for-profit companies\u2014which OpenAI was in the process of trying to do\u2014gutted the language of her own bill and replaced it with essentially an entirely new one. The strange move came after pushback from OpenAI, and just three days after OpenAI closed its deal with SoftBank for $40 billion, a large portion of which is contingent on the removal of that nonprofit structure. It\u2019s almost quaint to think back to 2023, when Sam Altman made a performative show of asking Congress to regulate his company\u2014he\u2019s spent the two years since fighting tooth and nail against every meaningful regulation that would affect his business. The Trump administration, meanwhile, has adopted the industry\u2019s zeal for deregulation; in part, of course, because there\u2019s significant overlap between the industry and the administration. One of Trump\u2019s first actions was to dissolve Biden\u2019s framework for governing AI, and to institute a new set of priorities aimed not at safe, equitable AI but at helping the US AI industry achieve dominance. Vice president, and former venture capitalist, JD Vance used his first speech abroad to call for an end to international AI regulations. Marc Andreessen, who\u2019s advising the administration on tech policy, and who wields nearly as much influence as Musk, has long advocated for less regulation\u2014his fingerprints are all over the Guthrie amendment. In an effort to try to better understand the GOP\u2019s aims here, I called up Guthrie\u2019s office, and spoke on background with a rep on the energy and commerce committee. Evidently, their plan is to argue that because the Trump administration is modernizing agencies like the Department of Commerce and the Federal Trade Commission with AI, banning states\u2019 ability to regulate AI is a spending-related matter. If, for instance, California passes a law that, say, requires an AI company to comply with transparency laws, and it becomes more expensive as a result, then the federal government will have to spend more on AI services. This strikes me as an enormous stretch, as such logic could be deployed to ban state lawmaking around just about anything. You could, say, ban states from making laws that seek to regulate the housing market, on the grounds that they might effect the price of maintaining federal buildings, or ban statewide labor laws because they impact the cost of paying federal employees, and so on. It seems that the talking points around promoting this amendment will roughly be: -It will encourage innovation and efficiency, preventing AI companies from having to deal with a patchwork of state laws -States like Colorado and California that have passed or are preparing to pass AI regulations are not truly prepared to do so -This effort is actually intended to benefit little tech, not big tech, because any regulations would harm little tech more -A \u201clight touch\u201d is imperative so we can beat China in the AI race A lot of these ideas can be traced back to Congressional committee hearings held by Gutherie and Ted Cruz in recent months, which were attended by Altman, former Google chief Eric Schmidt, Scale AI CEO Alexandr Wang and others. The notion that the US must \u201cbeat\u201d China in the AI race at any cost was a frequent theme, and this was where Schmidt\u2019s now-infamous declaration that AI needs to be given as much energy as possible (and not to worry, AI will solve the climate crisis) was made. It left an impression. \u201cEric Schmidt said we need to use energy [to develop AI] because it\u2019s going to produce the solutions to climate change,\u201d Brett Gutherie told the Washington Post, weeks before he introduced his amendment banning state lawmaking on AI. In the interview, Guthrie argues that \u201cthe most existential threat to America\u201d is \u201closing the battle for AI\u201d to China. That, Guthrie says, is why we can\u2019t \u201cgo down the path some other continents have,\u201d as Europe has, and adopt even modest regulations on AI or the tech sector. It\u2019s unclear whether Guthrie and the GOP\u2014or Sam Altman and Eric Schmidt, for that matter\u2014believe there\u2019s an AI race with China of existential proportions, or if it\u2019s simply a useful line to justify calling for limitless investment, and placing AI outside the democratic process. Ultimately it doesn\u2019t matter. It\u2019s serving GOP and Silicon Valley interests in providing the imperative for unfettered AI development, even halfheartedly. What\u2019s clear is that the GOP, AI executives, and Gulf State princes all have a common belief in AI\u2014as a means of accumulating capital, undercutting labor, and concentrating power. And the terms of AI development and deployment are on the cusp of being set entirely by oligarchs, billionaires, and their allies in the ruling party. And those parties are intent removing any impediments\u2014like the democratic process\u2014from their pursuit of power and profit. \u201cPoliticians are letting billionaires call the shots and all of us will be the ones who pay the price,\u201d as TechEquity\u2019s Samantha Gordon put it. Bryan says it might come to people taking to the streets; there\u2019s so much at stake. \u201cAs goes California, as goes the country. And so they're trying to get ahead of us,\u201d he says. \u201cBut I don't think they've got the expertise, and they certainly don't have the American people behind them in an effort like this.\u201d Over in the Senate, Ted Cruz has announced that he will introduce an amendment like Guthrie\u2019s, where he\u2019ll make the push for the ban on states making their own AI rules to become law. This story was edited by Mike Pearl. Eliza McCullough contributed research. Interview with Assemblyman Isaac Bryan In reporting the above piece, I spoke at length with California state assemblyman Isaac Bryan, the author of the state bill AB 1221: Workplace surveillance tools, the co-sponsor of a number of other AI-focused bills, and who also happens to represent my district in Los Angeles. I thought the full conversation worth sharing, so I\u2019m sharing a lightly edited and abridged version of it below. BLOOD IN THE MACHINE: Thanks for taking the time to talk \u2014 so, you\u2019ve sponsored some of the bills that are being considered in the California state legislature, to prevent employers from using AI unethically in the workplace, for one. How are you thinking about these bills now, as the GOP is taking aim at your capacity to even pass such laws? The reality is we still have a preservation of states' rights and the ability for states to set policy guidelines and regulations, particularly on issues that impact residents of their state disproportionately. The tech industry was incubated, cultivated, and continues to grow and innovate here in California. And I think many of us, all of us, most of us, believe in that innovation, believe in that creativity, believe in that advancement. It's also why California deserves the right, and has the expertise, to lead. We\u2019ve been establishing meaningful guardrails and regulations around these advancements so that we center people as we continue to innovate. The challenges of this administration in Washington\u2014they often shoot from the hip and misfire as they have rapidly on several different occasions with several different policy fronts and especially on things related to the economy. I can't think of how many executive orders and how many tariff ideas and how many other things have come from this administration only to be kind of rolled back or changed when they ran into the pragmatism of reality. The budget reconciliation process certainly isn't done yet and I know we continue all to an ever-encroaching minority in the House. And so I expect for California's voices to be heard. But I think all states should be deeply concerned about new levels of preemption. That should be a bipartisan kind of conversation about where the federal government can step in, should step in, and where it absolutely should not. What we're going to do in California is continue to lead in the ways that we have. Balancing the needs of everyday people, the needs of the emerging industries, the desires of those of us in the state house, along with the goals of the governor, and strike those balances where we can. And if the federal government continues to encroach on that, we'll continue to file lawsuits as we have and have done successfully, both in the past Trump administration and currently. There are two levels of audacity here. First, that they would even attempt such a thing \u2014 this is a party that has, in the past, quite loudly expressed their belief in states' rights; as recently as last summer. And now to try to do away with them on such a key issue altogether. But then, secondly, to do this in the budget reconciliation bill, to have such a far-reaching and potentially impactful measure put through in reconciliation. That really, to me, without giving this bill a proper hearing, it really underscores how undemocratic this maneuver is, around such an important topic. I couldn't agree further. I mean, if there's one thing that the GOP has been consistent about, it has been their hypocrisy. They are for any type of legislative maneuvers, any type of distribution of checks and balances and powers that favor them in any given moment. There's very limited consistency, and we've seen some strict constitutionalists in the GOP absolutely flipped the script to justify the actions of the current administration and leaders in Congress. This is no exception. But, you know, this is a moment for those in the federal government who value the preservation of our civic institutions over the preservation of self and self-interest to rise and stand up. And I think you're seeing that kind of consistency from the left. You're seeing that kind of measured and steady hand from the last two Democratic presidents, and hopefully that kind of longer term view of balancing powers and making sure that the American people are heard, the people who are most impacted by these kinds of changes. And in this particular space, on AI, that is Californians. Whether the Trump administration likes it or not, I recognize that he took a far-reaching group of billionaire CEOs and particular tech CEOs to Saudi Arabia just the other day to meet with the prince. And I think all of that has important diplomatic motivations, but it's a very strange thing to have people struggling to keep a roof over their head and watching the exorbitant wealth being generated by tech billionaires, and the preservation of that wealth by this administration, supersede the needs of everyday people. The richest man in the world, a tech billionaire himself, was serving as a surrogate president for the last several months. I think it's a scary time for folks. I could not ignore that irony either. The same day that the amendment to try to effectively wipe out AI regulation in the United States, the CEOs of these companies are in Saudi Arabia inking billion dollar deals. It's interesting, too. It seems like the only bridges that Trump can build are between tech billionaire CEOs who don't like each other, right? It's not a well-kept secret that Musk and Altman don't like each other. Their views around OpenAI have spilled out into the public, and yet they both seem to find comfort, security, and safety in this current president. It's a shame that the everyday folks across this country who are struggling right now and deeply afraid of how these kind of economic decisions will impact or limit their choices as they try to provide food for their kids and keep a roof over their heads and buy new school clothes and backpacks. There's the needs that everyday folks have, and there's the needs that our tech billionaire class has\u2014and those are the only ones being addressed. I know it's always a tricky line in California, because the tech sector is largely based here. And it's a key constituency. Does it concern you at all that these tech companies, that this is essentially what they have been lobbying for? That Sam Altman and Google and IBM have been pushing for an exemption to state lawmaking, specifically because I think that they worry about having to comply with rules that might be put forward in places like California? Yeah, it's deeply concerning because I think there's no place better positioned to understand the tremendous positive things, both for society, for social living, but also for wealth generation in an industry that pays taxes to the state. Nobody understands that better than California. But we also deal with the harsh and very real realities that as these kinds of innovations take place in a way that displaces workers, with an intentionality of increasing productivity through the laying off of everyday people trying to earn a living, that there's a balance that's got to be struck there. And even as we generate new forms of state revenue, and are able to increase the state's wealth through this new industry, we will also have a disproportionate growth in liabilities, as people will need unemployment and health care and other social safety nets because their ability to earn a living has drastically changed during this spike of innovation. So we've got to be mindful of that balance\u2014we also want to make sure that tools don't become predatory, or increase the opportunity for data and information to be leaked. It's unconscionable to me the way that the current federal administration has treated people's private and sensitive federal data like some sort of play thing for Elon Musk and Big Balls\u2014only because I can't remember the guy's actual name. On the DOGE team. Exactly. To me, how much we've allowed for our lives to be captured through these algorithmic systems, and through these innovations, and then to have that data decisively unprotected in this present moment\u2014and so we've got to do almost all of the above in California. And I think when we lead in this sector the kind of decisions we'll make will strike the appropriate balances that allow for others to follow. And that's the real fear: As goes California, as goes the country. And so they're trying to get ahead of us. But I don't think they've got the expertise, and they certainly don't have the American people behind them in an effort like this. Yeah. These are proposals aimed at limiting some of the harms of AI, making sure that workers don't get steamrolled and can't be surveilled at will, and giving some power back to workers when these tools are used in their workplaces. Now, I think that when a tech company sees that, they see something that\u2019s going to be inconvenient and costly. But can you talk a little bit about why it's important to have things like SB7 or AB 1221, which, I would describe them as hardly radical, but more like common sense proposals in the era of AI, as the technology that stands to affect more workers. They're absolutely common sense proposals, and they're working through the legislative process, taking amendments through the process, learning, bringing stakeholders to the table. It's interesting too, if I was some of these tech CEOs, I actually wouldn't want this power to, the ability to regulate and make thoughtful decisions in the hands of somebody [Trump] who's decided that thoughtfulness is not a characteristic that they want to exhibit through their leadership. I mean, he has haphazardly taken a sledgehammer and swung from left to right on a range of issues. And even in these issues, I think he's going to wake up one day and realize that the Teamsters, the only labor union that backed him at the federal level, have a deep interest in not being pushed out by automated trucks, which is a conversation that's been going on here in California, and there's been some back and forth between legislators and the governor on how to land this correctly, even here. But that's another base of a constituency that he will eventually hear from. They probably don't get in through the door as quickly as the billionaire tech CEOs. So I think this is California's responsibility. These are the kinds of state rights that we can and should have. We are allowed to govern in the interests that protect our economy and the people who rely on us. To have that preempted or suggested to be preempted in this way surely has got to be unconstitutional and we should do what we can to find out. Let\u2019s talk for a second about why you co-sponsored these bills in the first place, and what stands to be lost. Our bill, AB 1221, we offered this bill because we don't want to lose the humanity in the workplace. There are some AI tools now that, register your emotional feeling for the day, your gait, movement and the way that you walk. They make corrective decisions, recommendations, disciplinary recommendations, all without human intervention. This has gone far beyond cameras in the store to make sure theft doesn't occur. It is very invasive. It has increasing ability to show biased attitudes, biased behaviors that can be harmful to both protected classes and workers more broadly. We just want to make sure that these tools are being used responsibly, that workers know which ones are being used on them and that any kind of disciplinary activity or things that impact somebody's ability to keep their job that those decisions are ultimately made by a person\u2014which doesn't sound unreasonable to me. Like I said, it's about preserving the humanity in the workplace. You mentioned legal challenges. Hopefully it gets struck down and doesn't pass the Byrd Rule in the Senate, and hopefully. But now we've also seen their colors, their intent, through this maneuver. That they're willing to even attempt this route; something that even just a couple years ago would have been considered audacious and extreme. How do you push back on this? We stand up. We make sure our elected officials hear from us. We, hold rallies, hold town halls, hold people accountable, take to the streets when necessary, and defend states that are willing to step up and buck this administration for the good of the American people. You know, this is not a partisan issue. It's about putting people first. And that used to be a shared value. But it's not everyday people who met with Saudi oligarchs a week ago, right? You needed a certain net worth to be invited on that trip. And you can't imagine that any kind of conversations that take place in that setting are good for everyday workers trying to keep a roof over their head and food on their tables. But there are more everyday people trying to earn an honest living in this moment than there are tech billionaires, and it's time for those folks to be heard. Well, I think that's a great place to leave it. Thanks for your time. Absolutely. Thank you. OTHER BLOODY STUFF Columbia Journalism Review asked me to participate in a roundup of how journalists are using AI\u2014Spoiler: I am not. The whole thing is worth a read, with smart takes from fellow travelers like Jason Koebler, Khari Johnson, Susie Cagle, and others. I was on the Majority Report with Emma Vigeland to talk about my piece on the AI jobs crisis: Friend of the blog Steve Rhodes sent over this poem, which is worth a read: ssyjuco A post shared by @ssyjuco Tune into System Crash this week, where we discuss the above, as well as the new Luddite pope, and a lot more. Tune into a live chat on Friday, May 16th, at 10 AM EST / 1 PM PST with Karen Hao, where we\u2019ll talk about her fantastic new book, Empire of AI. That\u2019s it for this week. Until next time, thanks for reading \u2014 and hammers up. Way up.",
    "published_at": "2025-05-17T02:46:33Z",
    "source": "Bloodinthemachine.com",
    "url": "https://www.bloodinthemachine.com/p/de-democratizing-ai",
    "summary": "The GOP wants to ban US states from passing any laws that govern AI. This week, AI execs took a trip with Trump to Saudi Arabia. It took many hours to research, investigate and write this story.",
    "category": "Politics"
  },
  {
    "title": "No scanner? No problem \u2014 your Android phone can now do it all",
    "content": "The scanner feature on Android devices has received a major upgrade, transforming how users digitize documents. Google's latest enhancement automatically improves document quality without manual adjustments. This smart scanner delivers professional-looking results with just a tap, eliminating the need for third-party scanning apps. Android smartphones have evolved into versatile tools that replace multiple devices we once carried. The ability to scan documents directly from your phone has been available for years, but Google has now significantly improved this experience with an automatic enhancement feature. This innovation streamlines the document scanning process, making it more efficient for business professionals, students, and anyone who regularly needs to digitize paperwork. Revolutionary automatic enhancement for Android document scanning Google has rolled out a major update to Android's document scanning capabilities that represents a significant improvement over previous versions. Until recently, users needed to manually apply enhancement filters after scanning a document, requiring extra steps and technical knowledge. With the latest update, Android now automatically enhances scanned documents by default. The enhancement system intelligently adjusts brightness, contrast, and sharpness to create clear, professional-looking scans. This technology mimics the output quality of dedicated scanning hardware while using just your smartphone camera. This feature saves valuable time for business professionals who frequently scan receipts, contracts, or other important papers. Users can find this feature in multiple Android applications, including: Google Drive Files app Pixel's built-in camera app Select other Google applications The system analyzes the document content and applies the appropriate enhancements without user intervention. If you prefer the unenhanced version, a simple tap on the \u201cEnhance\u201d button in the top-right corner reverts to the original scan. Integration across Google's ecosystem The automatic document scanner enhancement feature represents part of Google's broader strategy to integrate intelligent features across its ecosystem. This improvement lives within Google Play Services version 25.17.30 or newer, meaning it's distributed automatically to compatible Android devices. Android Authority first spotted this update, noting how it significantly improves productivity. Unlike previous iterations where enhancement options were buried in menus, the new implementation makes professional-quality scanning the default experience. The feature integrates seamlessly with Google Drive and other productivity tools for business users. Scanned documents can be immediately shared, edited, or stored in the cloud with minimal friction. This integration creates a streamlined workflow from paper to digital format, enhancing productivity. The automatic updates through Google Play Services ensure that most compatible devices already have this feature, with no manual installation required. This distribution method highlights how Google can enhance core functionality without requiring full system updates. Technical improvements behind the enhancement The enhanced scanning feature leverages advanced image processing algorithms to deliver superior results. These improvements focus on several key areas: Enhancement Area Technical Approach User Benefit Contrast Optimization Adaptive contrast enhancement Improved text readability Edge Detection Precision boundary recognition Automatic document cropping Light Balancing Exposure compensation algorithms Consistent results in various lighting Text Sharpening Targeted text clarity processing Professional document appearance While these technical improvements work impressively in most scenarios, they may occasionally produce suboptimal results in unusual lighting conditions or with non-standard document formats. Google has wisely included the option to disable enhancement when needed, offering flexibility while maintaining simplicity. The technology works particularly well with text documents, forms, and receipts \u2013 the most commonly scanned items. The processing happens almost instantaneously, with no noticeable delay compared to standard scanning. Practical applications and user benefits The automatic enhancement feature transforms how different user groups can leverage their Android devices. For business professionals, the improved scanner creates presentation-ready documents without additional editing. Students can quickly digitize notes, handouts, and textbook pages with professional quality. Home users benefit when organizing receipts, warranties, and essential paperwork. The enhanced scan quality approaches what dedicated scanning hardware produces, making this a compelling alternative to purchasing separate equipment. Users report significantly improved readability for: Handwritten notes and signatures Small print on receipts and forms Documents with mixed text and graphics Papers with varying background colors Materials with light pencil marks By making enhancement the default option, Google has effectively eliminated a common pain point. Previously, users often needed to learn about enhancement features and manually apply them. The best scanning result is now delivered immediately, with customization options if desired. This scanner enhancement continues Google's pattern of integrating intelligent features that anticipate user needs rather than requiring manual configuration. The technology showcases how machine learning can simplify everyday tasks while delivering superior results. The future of mobile document handling Google's enhanced document scanning feature represents just the beginning of more sophisticated document handling capabilities on mobile devices. The automatic enhancements demonstrate how artificial intelligence continues reshaping everyday smartphone tasks into more efficient processes. Industry analysts expect future updates may include improved text recognition for immediate editing, advanced categorization of scanned documents, and possibly integration with Google's search capabilities to make content discoverable. As these technologies mature, the line between physical and digital documents continues to blur. For users, these improvements transform smartphones into increasingly capable productivity tools that require less technical knowledge to operate effectively. The simplified scanning process exemplifies how technology can eliminate friction points in everyday tasks. This feature update highlights Google's commitment to refining core Android functionality through iterative improvements. Rather than flashy new features, these quality-of-life enhancements often deliver the most tangible benefits to users' daily experience.",
    "published_at": "2025-05-18T06:30:00Z",
    "source": "TalkAndroid",
    "url": "https://www.talkandroid.com/507096-no-scanner-no-problem-your-android-phone-can-now-do-it-all/",
    "summary": "Google has rolled out a major update to Android's document scanning capabilities. The new feature automatically improves document quality without manual adjustments. This innovation streamlines the document scanning process, making it more efficient.",
    "category": "Technology"
  },
  {
    "title": "Boffins devise technique that lets users prove location without giving it away",
    "content": "Computer scientists from universities in Germany, Hong Kong, and the United Kingdom have proposed a way to provide verifiable claims about location data without surrendering privacy. The technique, referred to as Zero-Knowledge Location Privacy (ZKLP), aims to provide access to unverified location data in a way that preserves privacy without sacrificing accuracy and utility for applications that might rely on such data. It's described in a paper [PDF] presented this week at the 2025 IEEE Symposium on Security and Privacy. Location data, obtained from mobile phones and apps among other sources, has become highly sought after by data brokers. But it's particularly sensitive. As the Electronic Frontier Foundation observes, it \"can reveal where we live and work, who we associate with, and where we worship, protest, and seek medical care.\" In their paper, authors Jens Ernstberger (Technical University of Munich), Chengru Zhang (University of Hong Kong), Luca Ciprian (Technical University of Munich), Philipp Jovanovic (University College London), and Sebastian Steinhorst (Technical University of Munich) note that various attempts have been made to mitigate the privacy risk of location data. These include communication protocols that rely on obfuscation, to make location data less precise, and cryptographic techniques, to make location data less available. Examples include Geo-Indistinguishability and VPriv [PDF], among others. The authors argue that these approaches have shortcomings, like reliance on third-party data anonymization. \"With ZKLP, users can prove to any third party that they are within a specific geographical region while obfuscating their exact location for utility and privacy,\" the authors claim. \"To the best of our knowledge, ZKLP provides the first paradigm for non-interactive, publicly verifiable, and privacy-preserving proofs of geolocation.\" ZKLP does not address the issue of an individual misrepresenting location data (spoofing) \u2013 it proves only the location data's value, not its provenance. The authors observe that additional overhead would be required to prove that location data is authentic. The potential solutions they suggest involve network communication with a third party, such as Apple's \"Find My\" network or GNSS (Global Navigation Satellite System) signals. So data provenance assurance \u2013 you are where you say you are \u2013 would no longer be non-interactive. The authors' technique relies on zero-knowledge proofs known as Succinct Non-Interactive Argument of Knowledge (zk-SNARK), a cryptographic mechanism that allows one party to prove knowledge of a secret without actually revealing the secret. Zero-knowledge proofs often use fixed-point arithmetic because it's more computationally efficient. But ZKLP has been designed to work with the Discrete Global Grid System (DGGS), a geospatial referencing framework that divides the world into hexagonal grids. It allows users to specify the granularity of their location on the hex grid map \u2013 they could choose to be in a city or in a more specific location like a park and their claim would be computationally verifiable. But DGGS is better suited to floating-point math. Hexagons, geodata, and associated computations require square roots and trigonometric functions. These are data types and operations best handled with floating-point calculations. So the academics had to come up with optimizations for computing floating-point SNARKs, in conjunction with optimizations to eliminate trigonometric operations, that together make ZKLP computationally more practical. They say it was challenging to implement SNARKs using floating-point arithmetic that complies with the IEEE 754 standard. But the result is a system that's less error-prone and more secure than something based on fixed-point calculations. \"In comparison to an unoptimized fixed point baseline, our implementation has 15.9\u00d7 less constraints for FP32 values, and 12.2\u00d7 less constraints for FP64 values,\" the researchers explain in their paper. \"We apply ZKLP and show that it can realize privacy-preserving peer-to-peer proximity testing, through which a user can evaluate its proximity to 470 peers per second.\" Beyond privacy-preserving proximity testing, the authors see their scheme being useful for scenarios where location data has already been authenticated. \"For example, in the workflow of C2PA (Coalition for Content Provenance and Authenticity), the location where a photo is taken is signed by a C2PA-compatible camera, and thus we can seamlessly integrate ZKLP with C2PA to provide photo authenticity while obfuscating the accurate location, thereby preserving the privacy of the photo\u2019s author,\" they state. They also suggest their methods could be useful for machine learning applications, because parameters are often represented as floating-point numbers, and as a building block for Proof-of-Personhood mechanisms that are being explored. \u00ae",
    "published_at": "2025-05-17T15:31:08Z",
    "source": "Theregister.com",
    "url": "https://www.theregister.com/2025/05/17/privacy_preserving_location_sharing/",
    "summary": "Computer scientists propose a way to provide verifiable claims about location data without surrendering privacy. The technique, referred to as Zero-Knowledge Location Privacy (ZKLP), aims to provide access to unverified location data in a way that preserves privacy.",
    "category": "Technology"
  },
  {
    "title": "Greywolfe CEO Ron Earley to Headline Oxford Keynote on the Future of AI and E-Commerce",
    "content": "How Machine Learning Is Reshaping Operational Strategy and Financial Freedom for the Next Generation of Entrepreneurs OXFORD, United Kingdom, May 17, 2025 (GLOBE NEWSWIRE) -- Ron Earley , Founder and CEO of Greywolfe Investing , will deliver a featured keynote at the EMBA Inspires event hosted by Sa\u00efd Business School at the University of Oxford on May 19, 2025. This year\u2019s program focuses on Machine Learning Fundamentals, uniting global executives and Oxford\u2019s Executive MBA alumni to explore how artificial intelligence is transforming modern leadership and business strategy. Earley\u2019s keynote, titled \u201cScaling Smarter \u2013 AI, Strategy & the Amazon Wholesale Ecosystem,\u201d will explore how artificial intelligence is transforming the Amazon FBA landscape. By drawing on real-world experience and case studies, he\u2019ll show how wholesale sellers are using machine learning tools to overcome operational blind spots, optimize performance, and scale more strategically. From predictive analytics to dynamic pricing, the session will highlight how business leaders can unlock efficiency and growth by integrating AI at key points across their organizations. Earley will also challenge attendees to rethink how they structure teams, make decisions, and protect data as a strategic asset. His approach blends tactical insight with a long-term vision for responsible AI adoption, offering participants a rare look at how automation, culture, and clarity can combine to drive resilience in a volatile business environment. \u201cAI isn\u2019t just a tool, it\u2019s a multiplier of talent, speed, and insight,\u201d said Earley. \u201cThis keynote is about showing leaders how to move from reactive management to proactive strategy using real-world applications of machine learning.\u201d Ron Earley brings a unique entrepreneurial journey to Oxford\u2019s stage. From starting with just $36,000 in capital to building one of the fastest-growing Amazon FBA firms in the country, he has led Greywolfe Investing with a focus on transparency, automation, and operational excellence. His firm is headquartered next to Florida\u2019s largest Amazon facility, employs over 100 professionals, and is a member of Amazon\u2019s exclusive Service Provider Network. Through the keynote, Earley will share insights on overcoming human limitations in managing complex e-commerce data, identifying and integrating automation opportunities, and transitioning organizations from instinct-driven cultures to AI-literate, structured environments. The session will also touch on emerging technologies shaping the future of commerce, including voice interfaces, generative content, and ethical AI systems. Ron Earley\u2019s participation in EMBA Inspires reflects a growing recognition of the role entrepreneurs play in shaping how advanced technologies are applied in the real world. His keynote will not only highlight the technical possibilities of machine learning, but also ground them in the lived experience of building a business from the ground up. As leaders across industries look to integrate AI more thoughtfully, Earley\u2019s story offers a compelling reminder that innovation is most powerful when paired with clarity, strategy, and purpose. About Greywolfe Investing: Greywolfe Investing is a Sarasota-based e-commerce investment firm redefining how wholesale sellers succeed on Amazon. Specializing in Fulfilled by Amazon (FBA) operations, Greywolfe offers a fully integrated approach that combines proprietary AI tools, strategic warehousing near Amazon\u2019s largest Florida hub, and partnerships with some of the largest manufacturers in the world. As an official Amazon Service Provider Network (SPN) partner, the company is committed to building resilient, transparent, and scalable operations for investors and entrepreneurs alike. Greywolfe\u2019s mission is to create legitimate investment opportunities that prioritize both performance and long-term stability in the rapidly evolving e-commerce ecosystem. Contact: Ron Earley support@greywolfeinvesting. com Media contact: Chloe Smart cs@omnipublic. global Disclaimer: This is a paid post and is provided by Greywolfe Investing. The statements, views, and opinions expressed in this content are solely those of the content provider and do not necessarily reflect the views of this media platform or its publisher. We do not endorse, verify, or guarantee the accuracy, completeness, or reliability of any information presented. This content is for informational purposes only and should not be considered financial, investment, or business advice. All investments carry inherent risks, including the potential loss of capital. Readers are strongly encouraged to conduct their own due diligence and consult with a qualified financial advisor before making any investment decisions. Neither the media platform nor the publisher shall be held responsible for any inaccuracies, misrepresentations, or financial losses resulting from the use or reliance on the information in this press release. Speculate only with funds you can afford to lose. In the event of any legal claims or concerns regarding this article, we accept no liability or responsibility. Legal Disclaimer: This media platform provides the content of this article on an \"as-is\" basis, without warranties or representations of any kind, express or implied. We assume no responsibility or liability for the accuracy, content, images, videos, licenses, completeness, legality, or reliability of the information contained herein. Any complaints, copyright issues, or inquiries regarding this article should be directed to the content provider listed above. A photo accompanying this announcement is available at https://www. globenewswire. com/NewsRoom/AttachmentNg/4d4d7e91-7583-4964-8a8e-72f35829dbb2",
    "published_at": "2025-05-17T21:31:00Z",
    "source": "GlobeNewswire",
    "url": "https://www.globenewswire.com/news-release/2025/05/17/3083527/0/en/Greywolfe-CEO-Ron-Earley-to-Headline-Oxford-Keynote-on-the-Future-of-AI-and-E-Commerce.html",
    "summary": "Ron Earley will deliver a featured keynote at the EMBA Inspires event hosted by Sa\u00efd Business School at the University of Oxford on May 19, 2025. Earley\u2019s keynote, titled \u201cScaling Smarter \u2013 AI, Strategy & the Amazon Wholesale Ecosystem,\u201d will explore how artificial intelligence is transforming the Amazon FBA landscape.",
    "category": "Business"
  },
  {
    "title": "Short Bursts, Big Gains: Microlearning In Action",
    "content": "How Small Lessons Can Drive Big Impact Attention spans are shrinking; research famously pegged the average human attention span at around 8 seconds (shorter than a goldfish). Modern learners also expect information on demand and in bite-sized formats, much like they consume social media or YouTube tutorials. For HR managers, L&D professionals, and corporate trainers, this raises a pressing challenge: How can we deliver effective training when learners can barely spare a few minutes and struggle to stay focused? The reality is that most employees have very limited time for formal learning\u2014one study found just 1% of the work week (about 24 minutes) is available for training. Traditional training approaches, day-long workshops, lengthy slide decks, and thick manuals are ill-suited to this new landscape of limited attention and time. The good news? Microlearning offers a solution. In this article, we'll explore how short, focused learning modules can boost engagement and retention, fit into busy schedules, and transform corporate training. We'll also cover implementation strategies, the science behind microlearning, and the role of gamification. Why Traditional Training Falls Short Conventional training methods have long struggled with engagement and knowledge retention, and these issues are magnified in today's fast-paced workplace. Some key problems with traditional training include: 1. Time And Attention Demands Long seminars or multi-hour eLearning courses demand uninterrupted focus that modern employees simply can't give. With only minutes a week to spare for learning, lengthy training sessions often get skipped or rushed. Even when completed, learners are mentally exhausted and less receptive by the end. 2. Information Overload And Forgetting Dumping a large volume of information in one go overwhelms learners. Cognitive science shows that without reinforcement, people forget roughly 50% of new information within an hour, 70% within a day, and 90% within a week. No wonder employees often retain only fragments of an all-day training. A passive lecture or slide presentation might yield as low as 10% knowledge retention after a week, meaning most of that training effort is lost. 3. Low Engagement Traditional training is often passive; think one-way lectures or page after page of text. Learners disengage easily, leading to poor completion rates and minimal behavior change. Boredom in training is a real issue. If trainees are tuning out or checking their phones, the training loses its impact. 4. One-Size-Fits-All Content In many traditional programs, every employee gets the same material in the same format, regardless of their prior knowledge or immediate needs. This lack of personalization and real-world context makes it harder for learners to connect the training to their jobs, and they may quickly revert to old habits. 5. Siloed, Infrequent Learning Old-school training might happen in big yearly workshops or onboarding bootcamps, separated from daily work. This gap means new skills aren't reinforced in the flow of work. Without follow-up, any gains from the training diminish over time (the classic \"learning\u2013doing gap\"). In short, lengthy and infrequent training approaches are often inefficient and ineffective for the modern workforce. They consume a lot of time for very little return in terms of learning outcomes. This is where microlearning comes in as a game-changer. Training With Microlearning: Big Benefits In Small Packages Microlearning refers to delivering training in small, focused chunks; think short learning modules that take only a few minutes to complete. Instead of a one-hour course on a broad topic, you might have a series of 5-minute lessons, each targeting a specific skill or concept. By aligning training with how people actually pay attention and learn today, microlearning offers several powerful benefits: Higher Learner Engagement Bite-sized content is inherently more digestible and often more engaging. Learners are more willing to start a 5-minute module than a 50-minute one, and they're less likely to zone out. Many organizations report significantly higher engagement with microlearning. In fact, companies using microlearning see about 50% higher learner engagement compared to traditional training. The interactive, multimedia nature of microlearning (videos, quizzes, gamified elements) also keeps learners interested. Engaged learners learn better. Better Knowledge Retention Microlearning is designed to combat the forgetting curve. By focusing on one topic at a time and reinforcing key points through repetition, it helps knowledge stick. Studies have found that switching to microlearning can boost retention rates by 20% or more. Another study showed microlearning can improve knowledge retention by up to 60% versus traditional methods. The result is learners not only complete the training, but actually remember and apply what they learned. Flexibility And Just-In-Time Learning Because modules are so short and typically mobile-friendly, employees can learn anytime, anywhere during a coffee break, on the commute, or right before a relevant task. This flexibility means training no longer requires blocking off large chunks of work time. Microlearning fits into busy schedules and meets learners at their point of need. For example, a salesperson could quickly pull up a 3-minute refresher on product features minutes before a client call. This just-in-time accessibility makes training feel more relevant and immediately useful. Microlearning seamlessly integrates into the flow of work, fostering a culture of continuous learning rather than one-and-done training events. In essence, microlearning enables \"learning in the flow of work.\" Employees can continuously upskill without stepping away from their jobs for long. It's a win-win: learners get what they need in a convenient way, and organizations see more effective training outcomes (often with lower development costs and time). Now, how can you implement microlearning successfully? Let's look at key strategies. Key Strategies For Implementing Microlearning In Your Training Rolling out microlearning in a corporate training program involves more than just chopping content into smaller pieces. To truly harness microlearning in corporate training, consider these best practices: 1. Short, Focused Modules Design each module around a single learning objective or topic. Keep lessons brief; usually, 3 to 7 minutes is ideal. This focus prevents cognitive overload and caters to short attention spans. For instance, instead of a 30-minute compliance video covering ten policies, create six five-minute microlessons, each on one policy or procedure. Learners find it much easier to digest and remember targeted nuggets of information. 2. Just-In-Time And On-Demand Access Make microlearning available exactly when and where employees need it. Host content in an easily accessible library or learning portal so staff can pull up training on the fly. You can also push out timely microlessons (for example, a quick safety tip the morning a new machine is introduced). The key is to integrate learning into daily workflows. When training is on-demand, it becomes a resource rather than a chore\u2014like quickly googling an answer, but with vetted internal content. 3. Mobile Optimization Ensure all microlearning content is mobile-friendly (or even mobile-first in design). Modern learners often prefer smartphones for quick learning bursts. Responsive design is crucial; a module should work just as well on a phone as on a laptop. By optimizing for mobile, you empower employees to learn during commutes, travel, or remote work. Microlearning apps or an LMS with a good mobile interface can facilitate this. The more accessible the training, the more likely employees will engage with it regularly. 4. Interactive And Multimedia Content Make microlearning modules interactive to maximize engagement. Use a mix of media, short videos, animations, infographics, and especially quizzes or scenario-based questions. Interactive elements turn learners from passive observers into active participants. Even simple quiz questions or branching scenarios within a 5-minute lesson can reinforce understanding and keep attention high. Incorporating game elements (points, badges, challenges), which we'll discuss more later, can further motivate learners. Remember, the goal is to make learning active, fun, and memorable. 5. Foster A Learning Culture Encourage a company culture that supports continuous, bite-sized learning. Managers should allow and even encourage employees to take microlearning breaks during work. Normalize the idea that spending 10 minutes on a training module is a productive use of time, not an interruption. Some organizations schedule a \"learning hour\" each week or send out a weekly microlearning challenge to all staff. By embedding microlearning into routines and recognizing those who regularly upskill, you create an environment where learning is valued. A supportive learning culture ensures your microlearning initiative sustains momentum rather than fizzling out after the initial excitement. By following these strategies, keeping content short and goal-focused, delivering it when and where it's needed, making it engaging, and cultivating organizational support, you'll set up your microlearning program for success. But why exactly does microlearning work so well? For that, we turn to some cognitive science insights. Backed By Brain Science: Spaced Repetition Microlearning isn't just a trendy idea; it aligns with how our brains learn and remember. A proven principle from cognitive science underpins the effectiveness of microlearning in boosting retention: spaced repetition. Rather than a one-off dumping of information, microlearning allows you to spread learning over time. Research on memory dating back to Ebbinghaus in the 19th century shows that information is retained much better when study sessions are spaced out. In practice, this means revisiting key concepts periodically (for example, a short refresher module next week, and a follow-up quiz a month later). Spaced repetition combats the forgetting curve by reinforcing knowledge at intervals. One study found that using spaced repetition techniques improved long-term knowledge retention by 200% compared to a single crammed session. In a corporate context, employees who used spaced microlearning platforms retained about 80% of critical information after 30 days, versus just 20% with traditional one-and-done training. These are dramatic differences. Microlearning makes it easy to implement spaced reinforcement; you can schedule brief review lessons or quizzes to reactivate memories just as they're about to fade, locking in learning for the long haul. Gamification: Making Microlearning Fun And Rewarding Another secret sauce for boosting learner engagement is gamification, incorporating game-like elements (points, badges, leaderboards, challenges) into the learning experience. Microlearning and gamification are a match made in heaven. Those short modules can feel even more motivating when they're part of a game-inspired progression. Here's how gamified microlearning drives results: 1. Increased Engagement And Motivation Games are addictive for a reason. Adding friendly competition, scores, or rewards taps into employees' natural desires for achievement and status. Learners are more likely to come back for daily micro-quizzes if they earn points or badges for each one. Participation rates shoot up when training feels like playing a game rather than a mandatory chore. The fun elements keep learners curious about what's next. 2. Instant Feedback And Gratification Gamification provides immediate feedback; quizzes tell you right away if you're right, and you gain points or progress bars in real time. This instant feedback loop in microlearning satisfies learners with quick wins. It also helps identify knowledge gaps on the spot. Instead of waiting for a final exam, learners get continuous insight into how they're doing, which guides them on what to review. 3. Higher Knowledge Retention It turns out that making learning fun also makes it more sticky. The interactivity and repetition inherent in gamified learning (e. g., retrying a quiz to earn a better score, or revisiting modules to unlock achievements) reinforce the material. Gamification encourages repeat engagement with content, which naturally leads to better retention of that content. By revisiting key concepts through game challenges, learners essentially practice spaced repetition without it feeling like \"review.\" The result is they remember the training far better than after a once-and-done session. Conclusion In an era of 8-second attention spans and constant busyness, microlearning has emerged as the bridge between limited attention and strong learning outcomes. By delivering training in short bursts, microlearning meets learners where they are busy, distracted, and hungry for information that's relevant and timely. We've seen how it tackles the shortcomings of traditional training by keeping learners engaged, leveraging science-backed techniques to improve retention, and fitting seamlessly into the workday. Importantly, microlearning isn't about dumbing down training or oversimplifying content; it's about making learning more efficient and impactful, given the realities of modern work life. Originally published on May 17, 2025",
    "published_at": "2025-05-17T15:00:57Z",
    "source": "Elearningindustry.com",
    "url": "https://elearningindustry.com/short-bursts-big-gains-microlearning-in-action",
    "summary": "One study found just 1% of the work week (about 24 minutes) is available for training. Traditional training approaches, day-long workshops, lengthy slide decks, and thick manuals are ill-suited to this new landscape of limited attention and time.",
    "category": "Business"
  },
  {
    "title": "AirPods Pro 3: Get Ready for a Massive Upgrade This Year!",
    "content": "Apple is preparing to unveil the AirPods Pro 3, a highly anticipated update to its popular wireless earbuds. This new iteration is expected to introduce a range of enhancements, including improved performance, advanced health-tracking capabilities, and subtle design updates. These changes aim to not only refine the user experience but also solidify Apple\u2019s position as a leader in the competitive wireless audio market. With a focus on innovation and practicality, the AirPods Pro 3 promises to cater to a wide range of users, from casual listeners to tech enthusiasts. The video below from SaranByte gives us more details on what Apple has planned for the new AirPods Pro. Refined Design and Modern Aesthetics The AirPods Pro 3 will retain the signature glossy white finish that has become synonymous with Apple\u2019s earbuds, but it will also feature several subtle design refinements. Reports suggest that the earbuds will incorporate smaller sensors, resulting in a sleeker and more compact profile. This streamlined design could enhance comfort during extended use while maintaining the iconic Apple aesthetic. The charging case is also expected to undergo a redesign. A slimmer profile, combined with a concealed LED indicator and a capacitive button, may replace the current layout. These updates aim to modernize the overall look and feel of the product while making sure it remains instantly recognizable. By balancing innovation with familiarity, Apple continues to prioritize both functionality and style in its design philosophy. Performance Upgrades Powered by the H3 Chip At the core of the AirPods Pro 3 lies the new H3 chip, which is set to deliver significant performance improvements. This advanced processor will enable a host of upgrades designed to enhance the listening experience. Key enhancements include: Enhanced Active Noise Cancellation (ANC): The H3 chip is expected to provide superior noise isolation, allowing users to fully immerse themselves in their audio without external distractions. The H3 chip is expected to provide superior noise isolation, allowing users to fully immerse themselves in their audio without external distractions. Improved Audio Quality: Upgraded drivers may deliver richer soundscapes, deeper bass, and greater clarity, appealing to both casual listeners and audiophiles. Upgraded drivers may deliver richer soundscapes, deeper bass, and greater clarity, appealing to both casual listeners and audiophiles. Extended Battery Life: Optimizations in power efficiency could result in longer listening sessions, addressing a common concern among users. These performance upgrades highlight Apple\u2019s commitment to delivering a premium audio experience, making sure the AirPods Pro 3 remains a top choice in the wireless earbud market. Advanced Health-Tracking Features Health and wellness are becoming increasingly central to Apple\u2019s product ecosystem, and the AirPods Pro 3 is no exception. The new model is expected to integrate advanced health-tracking features that could rival dedicated fitness devices. Anticipated upgrades include: In-Ear Heart Rate Monitoring: This feature could provide accurate heart rate data, making the earbuds a valuable tool for fitness enthusiasts and health-conscious users. This feature could provide accurate heart rate data, making the earbuds a valuable tool for fitness enthusiasts and health-conscious users. Temperature Sensing: By measuring body temperature via the ear canal, users may gain a convenient way to monitor their health on the go. These additions align with Apple\u2019s broader strategy of embedding health-focused technologies across its product lineup, offering users practical tools to support their well-being. Innovative Functionalities and Future Potential One of the most exciting rumored features of the AirPods Pro 3 is on-device live translation. This functionality could enable real-time multilingual conversations, making the earbuds an invaluable tool for travelers, professionals, and anyone navigating language barriers. By using artificial intelligence and machine learning, Apple is pushing the boundaries of what wireless earbuds can achieve. Looking further ahead, Apple is reportedly exploring additional innovations for future AirPods models. Potential advancements include: Infrared Cameras for Spatial Audio: These cameras could enhance the immersive audio experience by tracking head movements with greater precision. These cameras could enhance the immersive audio experience by tracking head movements with greater precision. In-Ear Gesture Controls: This technology may allow users to interact with their earbuds through subtle movements, offering a more intuitive and seamless interface. While these features are not expected to debut with the AirPods Pro 3, they underscore Apple\u2019s commitment to staying at the forefront of wireless audio technology. Release Timeline and Pricing Expectations The AirPods Pro 3 is anticipated to launch in September, likely alongside the iPhone 17. Pricing is expected to range between $249 and $299, reflecting the inclusion of new features and potential inflationary factors. While this represents a slight increase compared to previous models, the enhanced capabilities and innovative technology are likely to justify the cost for many users. Apple\u2019s focus on delivering value through innovation ensures that the AirPods Pro 3 will appeal to a broad audience. A Promising Step Forward The AirPods Pro 3 represent a thoughtful evolution of Apple\u2019s wireless earbud lineup. With features like the H3 chip, advanced health tracking, and live translation, the new model is designed to meet the diverse needs of modern users. By combining performance, innovation, and practicality, the AirPods Pro 3 is poised to set a new standard in the wireless audio market. As the release date approaches, anticipation continues to build for what promises to be one of Apple\u2019s most compelling product launches in recent years. Uncover more insights about AirPods Pro 3 in the previous articles we have written. Source & Image Credit: SaranByte Latest Geeky Gadgets Deals Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",
    "published_at": "2025-05-17T07:00:52Z",
    "source": "Geeky Gadgets",
    "url": "https://www.geeky-gadgets.com/airpods-pro-3-massive-upgrade/",
    "summary": "Apple is preparing to unveil the AirPods Pro 3, a highly anticipated update to its popular wireless earbuds. This new iteration is expected to introduce a range of enhancements, including improved performance, advanced health-tracking capabilities, and subtle design updates. These changes aim to not only refine the user experience but also solidify Apple's position as a leader in the competitive wireless audio market.",
    "category": "Health"
  },
  {
    "title": "Contrasting Alphabet (NASDAQ:GOOGL) and DigitalOcean (NYSE:DOCN)",
    "content": "DigitalOcean (NYSE:DOCN \u2013 Get Free Report) and Alphabet (NASDAQ:GOOGL \u2013 Get Free Report) are both computer and technology companies, but which is the better stock? We will contrast the two businesses based on the strength of their profitability, valuation, risk, dividends, analyst recommendations, institutional ownership and earnings. Analyst Recommendations This is a breakdown of current ratings and target prices for DigitalOcean and Alphabet, as reported by MarketBeat. com. Get DigitalOcean alerts: Sell Ratings Hold Ratings Buy Ratings Strong Buy Ratings Rating Score DigitalOcean 1 6 6 0 2.38 Alphabet 0 10 26 4 2.85 DigitalOcean presently has a consensus target price of $39.83, suggesting a potential upside of 28.28%. Alphabet has a consensus target price of $199.75, suggesting a potential upside of 20.19%. Given DigitalOcean\u2019s higher probable upside, equities research analysts plainly believe DigitalOcean is more favorable than Alphabet. Earnings and Valuation Gross Revenue Price/Sales Ratio Net Income Earnings Per Share Price/Earnings Ratio DigitalOcean $806.59 million 3.50 $19.41 million $1.11 27.97 Alphabet $359.71 billion 5.61 $100.12 billion $8.97 18.53 This table compares DigitalOcean and Alphabet\u201ds revenue, earnings per share and valuation. Alphabet has higher revenue and earnings than DigitalOcean. Alphabet is trading at a lower price-to-earnings ratio than DigitalOcean, indicating that it is currently the more affordable of the two stocks. Profitability This table compares DigitalOcean and Alphabet\u2019s net margins, return on equity and return on assets. Net Margins Return on Equity Return on Assets DigitalOcean 10.86% -43.11% 7.64% Alphabet 28.60% 32.49% 23.52% Volatility and Risk DigitalOcean has a beta of 1.88, suggesting that its stock price is 88% more volatile than the S&P 500. Comparatively, Alphabet has a beta of 1.01, suggesting that its stock price is 1% more volatile than the S&P 500. Insider & Institutional Ownership 49.8% of DigitalOcean shares are held by institutional investors. Comparatively, 40.0% of Alphabet shares are held by institutional investors. 1.0% of DigitalOcean shares are held by insiders. Comparatively, 11.6% of Alphabet shares are held by insiders. Strong institutional ownership is an indication that hedge funds, endowments and large money managers believe a stock will outperform the market over the long term. Summary Alphabet beats DigitalOcean on 11 of the 15 factors compared between the two stocks. About DigitalOcean (Get Free Report) DigitalOcean Holdings, Inc., through its subsidiaries, operates a cloud computing platform in North America, Europe, Asia, and internationally. The company\u2019s platform provides on-demand infrastructure and platform tools for developers, start-ups, and small and growing digital businesses. It also offers infrastructure-as-a-service (IaaS) solutions comprising compute and storage services, as well as networking projects, including Cloud Firewalls software, Managed Load Balancers software, and Virtual Private Cloud (VPC). The company also provides platform-as-a-service (PaaS) solutions, such as managed databases; managed Kubernetes and container registry; application platform to build, deploy, and scale applications; Functions, a serverless compute solution; and Uptime for real-time uptime and latency alerts, as well as software-as-a-service (SaaS), including managed hosting and DigitalOcean Marketplace, a platform where developers can find pre-configured applications and solutions. In addition, it offers artificial intelligence (AI)/machine learning (ML) applications comprising GPU virtual machines for scaling AI applications; Notebooks, a simple cloud workspace that runs on GPUs that provides a managed interactive development environment for exploring data, and training and building machine learning models; and Deployments for deploying their machine learning model as an API endpoint. The company\u2019s customers include software engineers, researchers, data scientists, system administrators, students, and hobbyists. Its customers use its platform in various industry verticals and for a range of use cases, such as web and mobile applications, website hosting, e-commerce, media and gaming, personal web projects, managed services, and AI/ML applications. DigitalOcean Holdings, Inc. was incorporated in 2012 and is headquartered in New York, New York. About Alphabet (Get Free Report) Alphabet Inc. offers various products and platforms in the United States, Europe, the Middle East, Africa, the Asia-Pacific, Canada, and Latin America. It operates through Google Services, Google Cloud, and Other Bets segments. The Google Services segment provides products and services, including ads, Android, Chrome, devices, Gmail, Google Drive, Google Maps, Google Photos, Google Play, Search, and YouTube. It is also involved in the sale of apps and in-app purchases and digital content in the Google Play and YouTube; and devices, as well as in the provision of YouTube consumer subscription services. The Google Cloud segment offers infrastructure, cybersecurity, databases, analytics, AI, and other services; Google Workspace that include cloud-based communication and collaboration tools for enterprises, such as Gmail, Docs, Drive, Calendar, and Meet; and other services for enterprise customers. The Other Bets segment sells healthcare-related and internet services. The company was incorporated in 1998 and is headquartered in Mountain View, California. Receive News & Ratings for DigitalOcean Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for DigitalOcean and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:27:00Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/contrasting-alphabet-nasdaqgoogl-and-digitalocean-nysedocn/",
    "summary": "DigitalOcean and Alphabet are both computer and technology companies, but which is the better stock? We will contrast the two businesses based on the strength of their profitability, valuation, risk, dividends, analyst recommendations, institutional ownership and earnings.",
    "category": "Technology"
  },
  {
    "title": "Hobby Thread - May 17, 2025 [TRex]",
    "content": "Hobby Thread - May 17, 2025 [TRex] Welcome hobbyists! Pull up a chair and sit a spell with the Horde in this little corner of the interweb. This is the mighty, mighty officially sanctioned Ace of Spades Hobby Thread. We gave the Ace of Spades Wheel of Hobbies(TM) a spin and it came up with drones! [Top photo: Landwasserviadukt in Switzerland Photo Credit] *** Consumer drones have transformed what was previously the province of commercial services with helicopters and airplanes. Technology has progressed and costs have plummeted. Like digital cameras, it does not require a lot of money to buy a reasonably capable personal drone. Consumer drones have transformed what was previously the province of commercial services with helicopters and airplanes. Technology has progressed and costs have plummeted. Like digital cameras, it does not require a lot of money to buy a reasonably capable personal drone. If this was a politics thread, we could talk about the regulatory framework in the US and the FAA's drone license restrictions and requirements. If this was a military thread, we could talk about drones usage in warfare and what has happened in Ukraine and what personal drones or drone swarms might mean for the future of military strategy. The Hobby Thread is neither. We're more interested in flying drones for giggles. If this was a politics thread, we could talk about the regulatory framework in the US and the FAA's drone license restrictions and requirements. If this was a military thread, we could talk about drones usage in warfare and what has happened in Ukraine and what personal drones or drone swarms might mean for the future of military strategy. The Hobby Thread is neither. We're more interested in flying drones for giggles. The Horde has many varied interests and has inclinations towards toys. Some amongst the Horde must be drone owners or operators. Some must have success stories of great shots in great locations or above great events. Some must also have horror stories of drones getting lost in trees or flying over the horizon with destinations unknown. The Horde has many varied interests and has inclinations towards toys. Some amongst the Horde must be drone owners or operators. Some must have success stories of great shots in great locations or above great events. Some must also have horror stories of drones getting lost in trees or flying over the horizon with destinations unknown. Share your stories. What do you fly? How did your learn? Has it been easy or difficult? Have you used it as you thought you would when you obtained your drone? Have surprised uses popped up where your drone came in handy? Has any among the Horde used a drone for their commercial purposes? Share your stories. What do you fly? How did your learn? Has it been easy or difficult? Have you used it as you thought you would when you obtained your drone? Have surprised uses popped up where your drone came in handy? Has any among the Horde used a drone for their commercial purposes? TRex has a small brain and short arms, so going to need Horde help for this one. TRex has a small brain and short arms, so going to need Horde help for this one. *** Some landscapes seem like they were meant to be viewed from the sky: Some landscapes seem like they were meant to be viewed from the sky: *** Buyer's guide: Buyer's guide: *** Legal knowledge: Legal knowledge: *** Market statistics: Market statistics: A growing number of drones are being used for videography, aerial photography, and recreational purposes, making the US one of the biggest markets for consumer drones. As of 2023, the Federal Aviation Administration (FAA) has estimated more than 1.47 million drones registered, through December 2022. One primary driver is the surge in demand from consumers of high-quality aerial photography for personal purposes and the manufacturing of social media content. The growth of the Drone Racing League (DRL) and other drone racing leagues fuels further demand from hobbyists. The growing use of artificial intelligence (AI) and machine learning (ML) with consumer drones is fueling the market. AI and ML algorithms give drones the ability to process data, make autonomous decisions, and adapt to any scenario, which makes them a more effective tool. The use of AI-enabled object recognition enables drones to identify and track objects, making them a valuable tool in surveillance, search and rescue operations, and wildlife monitoring. ML algorithms analyze sensor data to improve flight stability and obstacle avoidance, ensuring safer and more efficient operations. Furthermore, AI-driven data analysis provides actionable insights for agriculture, mapping, and infrastructure inspection. Drones equipped with AI can identify crop diseases, assess construction progress, and create detailed 3D models with unprecedented accuracy. Source *** What Are the Best Settings for Drone Photography? 10 Tips to Improve Your Drone Photography How to take high quality low light photos with your drone *** A photo only possible with a drone (or a very low helicopter): A photo only possible with a drone (or a very low helicopter): *** Most drone photography is for big outdoor scenes or vistas. This video goes the other direction. A microscope gives a similar perspective but at a much, much smaller scale. The video also shows 3-D printing artwork on cardboard so that you can both see and feel works by the masters. Most drone photography is for big outdoor scenes or vistas. This video goes the other direction. A microscope gives a similar perspective but at a much, much smaller scale. The video also shows 3-D printing artwork on cardboard so that you can both see and feel works by the masters. Horde hat tip. *** How to obtain a commercial drone license: How to obtain a commercial drone license: *** Carrying over the golf theme from last week: Carrying over the golf theme from last week: *** Horde Hobbying update from the Hobby Thread's resident landscape painter. This work from polynikes honors the golf theme from last week. It is called \"An Eagle on #9.\" Horde Hobbying update from the Hobby Thread's resident landscape painter. This work from polynikes honors the golf theme from last week. It is called \"An Eagle on #9.\" Good stuff as always. Thank you! Good stuff as always. Thank you! *** What are you hobbying these days? What are you hobbying these days? As per usual Hobby Thread etiquette, keep this thread limited to hobbying. Your participation does not need to limited to the theme. All hobbying is welcome. However, politics, current events and religious debates can live in threads elsewhere. Play nice. Do not be a troll and do not feed the trolls. Pants, as always, are optional. As per usual Hobby Thread etiquette, keep this thread limited to hobbying. Your participation does not need to limited to the theme. All hobbying is welcome. However, politics, current events and religious debates can live in threads elsewhere. Play nice. Do not be a troll and do not feed the trolls. Pants, as always, are optional. *** Did you miss the Hobby Thread last week? We talked Did you miss the Hobby Thread last week? We talked golf. The comments may be closed, but you can re-live the content. *** Notable comments from last week: Notable comments from last week: *** Words of wisdom: \"Because despite all our troubles, when things are grim out in that wide round world of ours, that's when it's really important to have a good hobby.\" Posted by: tankascribe at June 22, 2024 07:41 PM (HWxAD). *** If you have trouble finding something in the content or comments that resonates with you, hijack the thread for your hobbying as you see fit. We will feature a different theme next time. What are you hobbying? We love showing off Horde hobbying. Send thoughts, suggestions and photos of your hobbying to moronhobbies at protonmail dot com. Do mighty things. Posted by: Open Blogger at 05:30 PM MuNuvians MeeNuvians",
    "published_at": "2025-05-17T21:30:15Z",
    "source": "Acecomments.mu.nu",
    "url": "https://acecomments.mu.nu/?post=414868",
    "summary": "Ace of Spades Wheel of Hobbies(TM) came up with drones. Consumer drones have transformed what was previously the province of commercial services with helicopters and airplanes. Like digital cameras, it does not require a lot of money to buy a reasonably capable personal drone.",
    "category": "Technology"
  },
  {
    "title": "What is Noble Financial\u2019s Forecast for GoHealth Q2 Earnings?",
    "content": "GoHealth, Inc. (NASDAQ:GOCO \u2013 Free Report) \u2013 Stock analysts at Noble Financial dropped their Q2 2025 earnings estimates for shares of GoHealth in a research report issued on Wednesday, May 14th. Noble Financial analyst P. Mccann now anticipates that the company will earn ($2.48) per share for the quarter, down from their previous forecast of ($1.39). The consensus estimate for GoHealth\u2019s current full-year earnings is ($5.50) per share. Noble Financial also issued estimates for GoHealth\u2019s Q3 2025 earnings at ($2.15) EPS, FY2025 earnings at ($2.34) EPS and FY2026 earnings at ($1.30) EPS. Get GoHealth alerts: GoHealth (NASDAQ:GOCO \u2013 Get Free Report) last released its quarterly earnings results on Tuesday, May 13th. The company reported ($0.47) EPS for the quarter, missing the consensus estimate of ($0.26) by ($0.21). The business had revenue of $220.97 million for the quarter, compared to analysts\u2019 expectations of $225.91 million. GoHealth had a negative net margin of 4.32% and a negative return on equity of 17.17%. GoHealth Trading Down 1.7% Institutional Investors Weigh In On GoHealth GoHealth stock opened at $7.13 on Friday. The firm has a 50 day moving average of $10.70 and a 200 day moving average of $12.92. The firm has a market capitalization of $164.05 million, a price-to-earnings ratio of -2.04 and a beta of 1.71. GoHealth has a 12-month low of $6.86 and a 12-month high of $21.00. The company has a current ratio of 1.18, a quick ratio of 1.18 and a debt-to-equity ratio of 1.72. Several hedge funds and other institutional investors have recently added to or reduced their stakes in the company. FNY Investment Advisers LLC purchased a new stake in GoHealth during the 1st quarter valued at approximately $31,000. Cubist Systematic Strategies LLC purchased a new stake in GoHealth during the 4th quarter valued at approximately $37,000. Wells Fargo & Company MN grew its holdings in GoHealth by 28.2% during the 4th quarter. Wells Fargo & Company MN now owns 2,760 shares of the company\u2019s stock valued at $37,000 after buying an additional 607 shares in the last quarter. N. E. W. Advisory Services LLC purchased a new stake in GoHealth during the 1st quarter valued at approximately $45,000. Finally, Bank of America Corp DE grew its holdings in GoHealth by 22.8% during the 4th quarter. Bank of America Corp DE now owns 7,831 shares of the company\u2019s stock valued at $105,000 after buying an additional 1,452 shares in the last quarter. 24.21% of the stock is owned by hedge funds and other institutional investors. GoHealth Company Profile (Get Free Report) GoHealth, Inc operates as a health insurance marketplace and Medicare-focused digital health company in the United States. The company operates a technology platform that leverages machine-learning algorithms of insurance behavioral data to optimize the process for helping individuals find the health insurance plan for their specific needs. Further Reading Receive News & Ratings for GoHealth Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for GoHealth and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T05:56:52Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/what-is-noble-financials-forecast-for-gohealth-q2-earnings/",
    "summary": "GoHealth, Inc. (NASDAQ:GOCO \u2013 Get Free Report) \u2013 Stock analysts at Noble Financial dropped their Q2 2025 earnings estimates for shares of GoHealth in a research report issued on Wednesday, May 14th. Noble Financial now anticipates that the company will earn ($2.48) per share for the quarter, down from their previous forecast of ($1.39) GoHealth last released its quarterly earnings results on Tuesday, May 13th. The company reported ($0.47) EPS for the Quarter, missing the consensus estimate of $0.26. GoHealth had a negative net margin of 4.",
    "category": "Health"
  },
  {
    "title": "Sidoti Csr Forecasts GoHealth\u2019s Q2 Earnings (NASDAQ:GOCO)",
    "content": "GoHealth, Inc. (NASDAQ:GOCO \u2013 Free Report) \u2013 Equities researchers at Sidoti Csr decreased their Q2 2025 EPS estimates for GoHealth in a research report issued to clients and investors on Tuesday, May 13th. Sidoti Csr analyst J. Sidoti now anticipates that the company will post earnings per share of ($3.32) for the quarter, down from their prior estimate of ($2.60). The consensus estimate for GoHealth\u2019s current full-year earnings is ($5.50) per share. Sidoti Csr also issued estimates for GoHealth\u2019s Q3 2025 earnings at ($3.37) EPS, Q4 2025 earnings at $3.29 EPS and FY2025 earnings at ($3.73) EPS. Get GoHealth alerts: GoHealth (NASDAQ:GOCO \u2013 Get Free Report) last released its quarterly earnings data on Tuesday, May 13th. The company reported ($0.47) EPS for the quarter, missing analysts\u2019 consensus estimates of ($0.26) by ($0.21). GoHealth had a negative net margin of 4.32% and a negative return on equity of 17.17%. The firm had revenue of $220.97 million during the quarter, compared to the consensus estimate of $225.91 million. GoHealth Price Performance Institutional Investors Weigh In On GoHealth GOCO stock opened at $7.13 on Friday. The firm has a 50 day moving average of $10.70 and a 200-day moving average of $12.92. The company has a current ratio of 1.18, a quick ratio of 1.18 and a debt-to-equity ratio of 1.72. GoHealth has a 12 month low of $6.86 and a 12 month high of $21.00. The firm has a market capitalization of $164.05 million, a P/E ratio of -2.04 and a beta of 1.71. Hedge funds have recently bought and sold shares of the stock. FNY Investment Advisers LLC bought a new stake in GoHealth during the first quarter valued at approximately $31,000. Cubist Systematic Strategies LLC bought a new stake in GoHealth during the fourth quarter valued at approximately $37,000. Wells Fargo & Company MN raised its stake in shares of GoHealth by 28.2% during the fourth quarter. Wells Fargo & Company MN now owns 2,760 shares of the company\u2019s stock worth $37,000 after acquiring an additional 607 shares in the last quarter. N. E. W. Advisory Services LLC purchased a new position in shares of GoHealth during the first quarter worth approximately $45,000. Finally, Bank of America Corp DE raised its stake in shares of GoHealth by 22.8% during the fourth quarter. Bank of America Corp DE now owns 7,831 shares of the company\u2019s stock worth $105,000 after acquiring an additional 1,452 shares in the last quarter. 24.21% of the stock is currently owned by institutional investors. GoHealth Company Profile (Get Free Report) GoHealth, Inc operates as a health insurance marketplace and Medicare-focused digital health company in the United States. The company operates a technology platform that leverages machine-learning algorithms of insurance behavioral data to optimize the process for helping individuals find the health insurance plan for their specific needs. Further Reading Receive News & Ratings for GoHealth Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for GoHealth and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T05:56:51Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/sidoti-csr-forecasts-gohealths-q2-earnings-nasdaqgoco/",
    "summary": "GoHealth, Inc. (NASDAQ:GOCO \u2013 Get Free Report) last released its quarterly earnings data on Tuesday, May 13th. The company reported ($0.47) EPS for the quarter, missing analysts\u2019 consensus estimates of $0.26. GoHealth had a negative net margin of 4.32% and a negative return on equity of 17.17%.",
    "category": "Health"
  },
  {
    "title": "QuickLogic (NASDAQ:QUIK) Price Target Lowered to $11.00 at Oppenheimer",
    "content": "QuickLogic (NASDAQ:QUIK \u2013 Free Report) had its price objective cut by Oppenheimer from $13.00 to $11.00 in a research report released on Wednesday morning,Benzinga reports. They currently have an outperform rating on the semiconductor company\u2019s stock. Separately, StockNews. com upgraded shares of QuickLogic to a \u201csell\u201d rating in a research report on Tuesday, April 22nd. One investment analyst has rated the stock with a sell rating, three have issued a buy rating and one has given a strong buy rating to the company\u2019s stock. According to data from MarketBeat. com, QuickLogic currently has a consensus rating of \u201cModerate Buy\u201d and a consensus target price of $10.87. Get QuickLogic alerts: Get Our Latest Stock Report on QUIK QuickLogic Stock Down 4.0% Institutional Inflows and Outflows Shares of QUIK opened at $5.76 on Wednesday. QuickLogic has a one year low of $4.26 and a one year high of $13.74. The company has a market cap of $91.00 million, a P/E ratio of -57.60 and a beta of 0.71. The company has a debt-to-equity ratio of 0.06, a current ratio of 1.12 and a quick ratio of 1.05. The firm has a 50 day simple moving average of $5.40 and a two-hundred day simple moving average of $7.17. Several institutional investors have recently modified their holdings of the stock. Perkins Capital Management Inc. increased its holdings in shares of QuickLogic by 0.9% during the fourth quarter. Perkins Capital Management Inc. now owns 202,956 shares of the semiconductor company\u2019s stock worth $2,293,000 after buying an additional 1,850 shares in the last quarter. Barclays PLC increased its holdings in shares of QuickLogic by 11.0% during the fourth quarter. Barclays PLC now owns 21,834 shares of the semiconductor company\u2019s stock worth $247,000 after buying an additional 2,158 shares in the last quarter. Wells Fargo & Company MN increased its holdings in shares of QuickLogic by 49.4% during the fourth quarter. Wells Fargo & Company MN now owns 6,645 shares of the semiconductor company\u2019s stock worth $75,000 after buying an additional 2,197 shares in the last quarter. Crews Bank & Trust acquired a new position in shares of QuickLogic during the fourth quarter worth $28,000. Finally, Bank of America Corp DE increased its holdings in shares of QuickLogic by 40.5% during the fourth quarter. Bank of America Corp DE now owns 13,091 shares of the semiconductor company\u2019s stock worth $148,000 after buying an additional 3,773 shares in the last quarter. 31.54% of the stock is currently owned by institutional investors and hedge funds. QuickLogic Company Profile (Get Free Report) QuickLogic Corporation operates as a fabless semiconductor company in the United States. The company offers embedded FPGA intellectual property, low power, multicore semiconductor system-on-chips, discrete FPGAs, and AI software; and end-to-end artificial intelligence/machine learning solution with accurate sensor algorithms using AI technology. Featured Articles Receive News & Ratings for QuickLogic Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for QuickLogic and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:10:56Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/quicklogic-nasdaqquik-price-target-lowered-to-11-00-at-oppenheimer/",
    "summary": "QuickLogic (NASDAQ:QUIK) had its price objective cut by Oppenheimer from $13.00 to $11.00 in a research report released on Wednesday. They currently have an outperform rating on the semiconductor company\u2019s stock.",
    "category": "Technology"
  },
  {
    "title": "What is William Blair\u2019s Forecast for GoHealth Q2 Earnings?",
    "content": "GoHealth, Inc. (NASDAQ:GOCO \u2013 Free Report) \u2013 William Blair issued their Q2 2025 EPS estimates for GoHealth in a report issued on Tuesday, May 13th. William Blair analyst A. Klauber expects that the company will post earnings of ($1.76) per share for the quarter. The consensus estimate for GoHealth\u2019s current full-year earnings is ($5.50) per share. William Blair also issued estimates for GoHealth\u2019s Q3 2025 earnings at ($2.27) EPS. Get GoHealth alerts: GoHealth Trading Down 1.7% NASDAQ:GOCO opened at $7.13 on Thursday. GoHealth has a 12 month low of $6.86 and a 12 month high of $21.00. The company has a 50-day moving average price of $10.70 and a 200-day moving average price of $12.91. The company has a current ratio of 1.18, a quick ratio of 1.18 and a debt-to-equity ratio of 1.72. The stock has a market cap of $164.05 million, a price-to-earnings ratio of -2.04 and a beta of 1.71. Institutional Inflows and Outflows GoHealth ( NASDAQ:GOCO Get Free Report ) last released its quarterly earnings data on Tuesday, May 13th. The company reported ($0.47) earnings per share (EPS) for the quarter, missing analysts\u2019 consensus estimates of ($0.26) by ($0.21). The firm had revenue of $220.97 million during the quarter, compared to analysts\u2019 expectations of $225.91 million. GoHealth had a negative net margin of 4.32% and a negative return on equity of 17.17%. Several large investors have recently bought and sold shares of the company. JPMorgan Chase & Co. raised its holdings in GoHealth by 103.8% in the 4th quarter. JPMorgan Chase & Co. now owns 17,195 shares of the company\u2019s stock worth $230,000 after purchasing an additional 8,758 shares during the period. Barclays PLC increased its position in GoHealth by 83.9% in the third quarter. Barclays PLC now owns 9,580 shares of the company\u2019s stock worth $89,000 after buying an additional 4,372 shares in the last quarter. Russell Investments Group Ltd. raised its stake in shares of GoHealth by 41,225.5% in the fourth quarter. Russell Investments Group Ltd. now owns 21,076 shares of the company\u2019s stock worth $282,000 after buying an additional 21,025 shares during the period. Empowered Funds LLC lifted its position in shares of GoHealth by 5.3% during the 4th quarter. Empowered Funds LLC now owns 23,218 shares of the company\u2019s stock valued at $311,000 after buying an additional 1,170 shares in the last quarter. Finally, Geode Capital Management LLC lifted its position in shares of GoHealth by 1.7% during the 4th quarter. Geode Capital Management LLC now owns 105,514 shares of the company\u2019s stock valued at $1,413,000 after buying an additional 1,779 shares in the last quarter. 24.21% of the stock is owned by hedge funds and other institutional investors. About GoHealth (Get Free Report) GoHealth, Inc operates as a health insurance marketplace and Medicare-focused digital health company in the United States. The company operates a technology platform that leverages machine-learning algorithms of insurance behavioral data to optimize the process for helping individuals find the health insurance plan for their specific needs. Recommended Stories Receive News & Ratings for GoHealth Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for GoHealth and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:59:01Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/what-is-william-blairs-forecast-for-gohealth-q2-earnings/",
    "summary": "William Blair issued their Q2 2025 EPS estimates for GoHealth in a report issued on Tuesday, May 13th. William Blair analyst A. Klauber expects that the company will post earnings of ($1.76) per share for the quarter. GoHealth ( NASDAQ:GOCO Get Free Report ) last released its quarterly earnings data on Tuesday,. GoHealth has a 12 month low of $6.86 and a 12 year high of $21.00.",
    "category": "Health"
  },
  {
    "title": "Riskified (NYSE:RSKD) Price Target Raised to $8.00",
    "content": "Riskified (NYSE:RSKD \u2013 Free Report) had its target price lifted by Truist Financial from $7.00 to $8.00 in a report issued on Thursday,Benzinga reports. They currently have a buy rating on the stock. RSKD has been the topic of a number of other research reports. JPMorgan Chase & Co. lowered their price objective on Riskified from $7.00 to $6.00 and set a \u201cneutral\u201d rating on the stock in a research note on Monday, March 10th. DA Davidson lowered their price objective on Riskified from $7.00 to $6.00 and set a \u201cbuy\u201d rating on the stock in a research note on Monday, April 14th. Keefe, Bruyette & Woods boosted their price objective on Riskified from $5.25 to $5.50 and gave the stock a \u201cmarket perform\u201d rating in a research note on Thursday. Piper Sandler reissued an \u201coverweight\u201d rating and set a $7.00 price objective on shares of Riskified in a research note on Monday, March 17th. Finally, The Goldman Sachs Group upped their price target on Riskified from $4.00 to $4.50 and gave the company a \u201csell\u201d rating in a research note on Thursday, March 6th. One analyst has rated the stock with a sell rating, four have issued a hold rating and three have issued a buy rating to the stock. Based on data from MarketBeat. com, Riskified currently has a consensus rating of \u201cHold\u201d and a consensus target price of $6.03. Get Riskified alerts: Check Out Our Latest Analysis on RSKD Riskified Stock Performance Hedge Funds Weigh In On Riskified NYSE RSKD opened at $4.96 on Thursday. The stock\u2019s fifty day moving average is $4.60 and its two-hundred day moving average is $4.82. The firm has a market capitalization of $798.79 million, a P/E ratio of -24.77 and a beta of 1.36. Riskified has a fifty-two week low of $3.94 and a fifty-two week high of $6.65. Several large investors have recently modified their holdings of RSKD. TFJ Management LLC acquired a new position in shares of Riskified in the 1st quarter valued at $3,615,000. Alta Fox Capital Management LLC acquired a new position in Riskified during the 1st quarter worth about $3,498,000. Monimus Capital Management LP acquired a new position in Riskified during the 4th quarter worth about $3,428,000. Clearline Capital LP lifted its stake in Riskified by 37.3% during the 1st quarter. Clearline Capital LP now owns 2,453,506 shares of the company\u2019s stock worth $11,335,000 after acquiring an additional 666,175 shares in the last quarter. Finally, Millennium Management LLC lifted its stake in Riskified by 171.0% during the 4th quarter. Millennium Management LLC now owns 766,977 shares of the company\u2019s stock worth $3,628,000 after acquiring an additional 483,975 shares in the last quarter. Institutional investors and hedge funds own 58.98% of the company\u2019s stock. Riskified Company Profile (Get Free Report) Riskified Ltd., together with its subsidiaries, develops and offers an e-commerce risk management platform that allows online merchants to create trusted relationships with consumers in the United States, Europe, the Middle East, Africa, the Asia-Pacific, and the Americas. It offers Chargeback Guarantee that ensures the legitimacy of merchants' online orders; Policy Protect, a machine learning solution designed to detect and prevent refund and returns policy abuse in real-time; Account Secure, a solution that cross-checks every login attempt; Dispute Resolve, which is used to compile submissions for fraud and non-fraud related chargeback issues; and PSD2 Optimize that helps merchants avoid bank authorization failures and abandoned shopping carts. Read More Receive News & Ratings for Riskified Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Riskified and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T06:16:49Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/riskified-nyserskd-price-target-raised-to-8-00/",
    "summary": "Riskified (NYSE:RSKD) had its target price lifted by Truist Financial from $7.00 to $8.00 in a report issued on Thursday. They currently have a buy rating on the stock. RSKD has been the topic of a number of other reports.",
    "category": "Business"
  },
  {
    "title": "DA Davidson Issues Positive Forecast for Riskified (NYSE:RSKD) Stock Price",
    "content": "Riskified (NYSE:RSKD \u2013 Free Report) had its price target boosted by DA Davidson from $6.00 to $6.50 in a report released on Thursday morning,Benzinga reports. The brokerage currently has a buy rating on the stock. DA Davidson also issued estimates for Riskified\u2019s Q2 2025 earnings at ($0.06) EPS. A number of other equities analysts have also recently issued reports on RSKD. UBS Group increased their price objective on shares of Riskified from $5.50 to $5.75 and gave the stock a \u201cneutral\u201d rating in a research report on Thursday. Keefe, Bruyette & Woods increased their price objective on shares of Riskified from $5.25 to $5.50 and gave the stock a \u201cmarket perform\u201d rating in a research report on Thursday. Piper Sandler reissued an \u201coverweight\u201d rating and set a $7.00 price objective on shares of Riskified in a research report on Monday, March 17th. JPMorgan Chase & Co. lowered their target price on shares of Riskified from $7.00 to $6.00 and set a \u201cneutral\u201d rating on the stock in a report on Monday, March 10th. Finally, Truist Financial upped their target price on shares of Riskified from $7.00 to $8.00 and gave the stock a \u201cbuy\u201d rating in a report on Thursday. One analyst has rated the stock with a sell rating, four have given a hold rating and three have issued a buy rating to the company. According to MarketBeat. com, the company presently has an average rating of \u201cHold\u201d and a consensus price target of $6.03. Get Riskified alerts: View Our Latest Report on RSKD Riskified Price Performance Institutional Investors Weigh In On Riskified RSKD stock opened at $4.96 on Thursday. The stock has a market capitalization of $798.79 million, a PE ratio of -24.77 and a beta of 1.36. The company\u2019s 50-day moving average is $4.60 and its 200-day moving average is $4.82. Riskified has a 1 year low of $3.94 and a 1 year high of $6.65. Institutional investors and hedge funds have recently made changes to their positions in the business. Lazard Asset Management LLC acquired a new stake in shares of Riskified in the 4th quarter worth about $38,000. Group One Trading LLC grew its position in Riskified by 4,503.5% in the 4th quarter. Group One Trading LLC now owns 8,719 shares of the company\u2019s stock worth $41,000 after purchasing an additional 8,917 shares in the last quarter. Invesco Ltd. bought a new stake in Riskified in the 1st quarter worth about $51,000. Bayesian Capital Management LP bought a new stake in Riskified in the 4th quarter worth about $56,000. Finally, Cubist Systematic Strategies LLC bought a new stake in Riskified in the 4th quarter worth about $74,000. Institutional investors and hedge funds own 58.98% of the company\u2019s stock. About Riskified (Get Free Report) Riskified Ltd., together with its subsidiaries, develops and offers an e-commerce risk management platform that allows online merchants to create trusted relationships with consumers in the United States, Europe, the Middle East, Africa, the Asia-Pacific, and the Americas. It offers Chargeback Guarantee that ensures the legitimacy of merchants' online orders; Policy Protect, a machine learning solution designed to detect and prevent refund and returns policy abuse in real-time; Account Secure, a solution that cross-checks every login attempt; Dispute Resolve, which is used to compile submissions for fraud and non-fraud related chargeback issues; and PSD2 Optimize that helps merchants avoid bank authorization failures and abandoned shopping carts. Featured Stories Receive News & Ratings for Riskified Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Riskified and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T06:16:50Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/da-davidson-issues-positive-forecast-for-riskified-nyserskd-stock-price/",
    "summary": "Riskified (NYSE:RSKD) had its price target boosted by DA Davidson to $6.50. The brokerage currently has a buy rating on the stock. DA Davidson also issued estimates for Riskified\u2019s Q2 2025 earnings at ($0.06) EPS.",
    "category": "Business"
  },
  {
    "title": "Q2 Earnings Estimate for Riskified Issued By DA Davidson",
    "content": "Riskified Ltd. (NYSE:RSKD \u2013 Free Report) \u2013 Analysts at DA Davidson issued their Q2 2025 earnings per share estimates for Riskified in a research report issued on Thursday, May 15th. DA Davidson analyst C. Wright expects that the company will post earnings of ($0.06) per share for the quarter. DA Davidson currently has a \u201cBuy\u201d rating and a $6.50 target price on the stock. The consensus estimate for Riskified\u2019s current full-year earnings is ($0.15) per share. Get Riskified alerts: Other equities analysts also recently issued reports about the company. Keefe, Bruyette & Woods boosted their price objective on Riskified from $5.25 to $5.50 and gave the company a \u201cmarket perform\u201d rating in a research report on Thursday. The Goldman Sachs Group lifted their target price on Riskified from $4.00 to $4.50 and gave the stock a \u201csell\u201d rating in a report on Thursday, March 6th. Truist Financial lifted their target price on Riskified from $7.00 to $8.00 and gave the stock a \u201cbuy\u201d rating in a report on Thursday. Piper Sandler reaffirmed an \u201coverweight\u201d rating and issued a $7.00 target price on shares of Riskified in a report on Monday, March 17th. Finally, JPMorgan Chase & Co. reduced their target price on Riskified from $7.00 to $6.00 and set a \u201cneutral\u201d rating on the stock in a report on Monday, March 10th. One research analyst has rated the stock with a sell rating, four have given a hold rating and three have given a buy rating to the company\u2019s stock. According to MarketBeat, the stock has an average rating of \u201cHold\u201d and a consensus price target of $6.03. Riskified Stock Down 1.3% Shares of Riskified stock opened at $4.96 on Friday. The stock\u2019s 50-day simple moving average is $4.60 and its 200-day simple moving average is $4.82. Riskified has a 52 week low of $3.94 and a 52 week high of $6.65. The company has a market capitalization of $798.79 million, a price-to-earnings ratio of -24.77 and a beta of 1.36. Institutional Investors Weigh In On Riskified Several large investors have recently added to or reduced their stakes in RSKD. TFJ Management LLC bought a new stake in Riskified during the first quarter worth approximately $3,615,000. Alta Fox Capital Management LLC bought a new stake in Riskified during the first quarter worth approximately $3,498,000. Monimus Capital Management LP bought a new stake in Riskified during the fourth quarter worth approximately $3,428,000. Clearline Capital LP increased its stake in Riskified by 37.3% during the first quarter. Clearline Capital LP now owns 2,453,506 shares of the company\u2019s stock worth $11,335,000 after acquiring an additional 666,175 shares during the last quarter. Finally, Millennium Management LLC increased its stake in Riskified by 171.0% during the fourth quarter. Millennium Management LLC now owns 766,977 shares of the company\u2019s stock worth $3,628,000 after acquiring an additional 483,975 shares during the last quarter. 58.98% of the stock is owned by institutional investors. Riskified Company Profile (Get Free Report) Riskified Ltd., together with its subsidiaries, develops and offers an e-commerce risk management platform that allows online merchants to create trusted relationships with consumers in the United States, Europe, the Middle East, Africa, the Asia-Pacific, and the Americas. It offers Chargeback Guarantee that ensures the legitimacy of merchants' online orders; Policy Protect, a machine learning solution designed to detect and prevent refund and returns policy abuse in real-time; Account Secure, a solution that cross-checks every login attempt; Dispute Resolve, which is used to compile submissions for fraud and non-fraud related chargeback issues; and PSD2 Optimize that helps merchants avoid bank authorization failures and abandoned shopping carts. Featured Articles Receive News & Ratings for Riskified Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Riskified and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T05:34:57Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/q2-earnings-estimate-for-riskified-issued-by-da-davidson/",
    "summary": "DA Davidson expects that the company will post earnings of ($0.06) per share for the quarter. Riskified currently has a \u201cBuy\u201d rating and a $6.50 target price on the stock. Other equities analysts also recently issued reports about the company.",
    "category": "Business"
  },
  {
    "title": "Grail (NASDAQ:GRAL) Price Target Raised to $43.00",
    "content": "Grail (NASDAQ:GRAL \u2013 Free Report) had its price objective boosted by Canaccord Genuity Group from $32.00 to $43.00 in a report released on Wednesday morning,Benzinga reports. The brokerage currently has a buy rating on the stock. Separately, Morgan Stanley increased their target price on Grail from $16.00 to $20.00 and gave the company an \u201cequal weight\u201d rating in a report on Tuesday, March 18th. Get Grail alerts: Check Out Our Latest Analysis on Grail Grail Trading Up 2.4% Grail stock opened at $39.91 on Wednesday. Grail has a twelve month low of $12.33 and a twelve month high of $63.99. The stock\u2019s fifty day simple moving average is $30.01 and its 200-day simple moving average is $26.56. The firm has a market capitalization of $1.41 billion and a P/E ratio of -0.65. Grail (NASDAQ:GRAL \u2013 Get Free Report) last posted its quarterly earnings data on Tuesday, May 13th. The company reported ($3.10) earnings per share for the quarter, topping analysts\u2019 consensus estimates of ($4.03) by $0.93. The company had revenue of $31.84 million for the quarter, compared to analysts\u2019 expectations of $35.80 million. Sell-side analysts predict that Grail will post -15.15 earnings per share for the current year. Insider Buying and Selling at Grail In other news, President Joshua J. Ofman sold 2,109 shares of the stock in a transaction dated Friday, March 7th. The shares were sold at an average price of $31.20, for a total transaction of $65,800.80. Following the completion of the sale, the president now owns 559,673 shares in the company, valued at approximately $17,461,797.60. This represents a 0.38% decrease in their ownership of the stock. The sale was disclosed in a filing with the Securities & Exchange Commission, which is accessible through this link. Also, CFO Aaron Freidin sold 1,816 shares of the stock in a transaction dated Friday, March 7th. The stock was sold at an average price of $31.20, for a total transaction of $56,659.20. Following the sale, the chief financial officer now owns 335,170 shares of the company\u2019s stock, valued at $10,457,304. This trade represents a 0.54% decrease in their position. The disclosure for this sale can be found here. Insiders sold 194,948 shares of company stock worth $6,583,130 over the last 90 days. Corporate insiders own 1.85% of the company\u2019s stock. Institutional Inflows and Outflows Several large investors have recently added to or reduced their stakes in GRAL. Crcm LP purchased a new position in Grail during the fourth quarter worth about $65,061,000. Sessa Capital IM L. P. acquired a new stake in shares of Grail in the 4th quarter worth approximately $53,550,000. Primecap Management Co. CA purchased a new position in Grail in the 4th quarter valued at approximately $37,118,000. Baker BROS. Advisors LP purchased a new position in Grail in the 4th quarter valued at approximately $29,098,000. Finally, Vanguard Group Inc. purchased a new position in Grail in the 4th quarter valued at approximately $25,902,000. Grail Company Profile (Get Free Report) GRAIL, Inc operates as a commercial-stage healthcare company, which engages in the development of a technology for early detection of cancer. It utilizes machine learning, software, and automation to detect and identify multiple deadly cancer types in earlier stages. The company was founded by Jeffrey T. Featured Articles Receive News & Ratings for Grail Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Grail and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T07:35:03Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/grail-nasdaqgral-price-target-raised-to-43-00/",
    "summary": "Canaccord Genuity Group boosted Grail\u2019s price objective from $32.00 to $43.00 in a report released on Wednesday morning. The brokerage currently has a buy rating on the stock. Grail (NASDAQ:GRAL \u2013 Get Free Report) last posted its quarterly earnings data on Tuesday, May 13th.",
    "category": "Business"
  },
  {
    "title": "Autonomous AI agents create new job opportunities",
    "content": "The following is a guest post and opinion of Zac Cheah, Co-Founder of Pundi AI. The brouhaha over autonomous artificial intelligence (AI) agents taking up jobs and radically transforming industries like healthcare and finance requires close inspection. Autonomy is a spectrum, where even the most autonomous AI agents need some form of human intervention to work appropriately. Fully autonomous AI agents are impossible. And rather than eating up jobs, autonomous AI agents create new work opportunities where humans assist AI agents\u2019 functions throughout their lifecycle. Diversifying Job Options Within the AI Industry All autonomous AI agents in production or deployment stages require human action because they cannot operate independently, thereby creating job openings. Although AI agents operating at scale are beyond a single person\u2019s cognitive capacities, each agent has multiple human-led teams in the development pipeline. These agents need human developers to build the underlying infrastructure, code the algorithm, prepare human-labeled datasets for training, and oversee auditing procedures. For example, an autonomous AI agent\u2019s accuracy depends on high-quality data training and performing repeated analytical tests. No wonder 67% of data engineers spend hours preparing datasets for AI model training. Since fragmented datasets lead to operational problems for autonomous agents, project teams have to clean data before training. Moreover, as data gaps can generate wrong output, developers must ensure an AI agent\u2019s integrity and market positioning through rigorous evaluation. Each AI company thus requires human data cleaners, labelers, and evaluators to run its models. Further, human-supervised audits provide necessary checks to prevent harm from autonomous AI agents acting rogue after deployment. Such defense mechanisms consist of elaborately tiered teams including company management, policy workers, auditors, and other skilled technicians. It takes a village to build and maintain an AI agent during its lifecycle. Thus, fully autonomous AI agents generate multiple job opportunities as human expertise is required to create, deploy, and evaluate these agents. Autonomous AI Agents Create New Human-Led Job Opportunities Humans\u2019 experiences help them develop nuanced societal understandings, which in turn help them make logical inferences and rational decisions. However, autonomous AI agents cannot \u2018experience\u2019 their surroundings and will always fail to make sound judgments without human assistance. So humans must meticulously prepare datasets, assess model accuracy, and interpret output generation to ensure functional consistency and reliability. Human evaluation is critical to identifying prejudices, mitigating bias, and ensuring that AI agents align with humanitarian values and ethical standards. A collaborative approach between human and machine intelligence is necessary to prevent ambiguous output generation events, grasp nuances, and solve complicated problems. With humans\u2019 contextual knowledge base, common-sense reasoning, and coherent deduction, AI agents will function better in real-life situations. Therefore, autonomous AI agents create new job roles and work opportunities within the AI industry rather than taking up jobs. To this end, Pundi AI drives AI innovation by empowering humans to contribute directly to the industry\u2019s growth narrative. Besides computational power, AI models need high-quality data accessibility for model training and domain specialists to fine-tune data for efficient model performance. But megacorporations have monopolized control over human-generated data for building AI-ML models. Pundi AI offers a decentralized data solution, providing equitable opportunities for everyone so that large companies don\u2019t exploit data producers. Thus, humans can maintain control over their data and directly benefit from using it for AI model training, creating new AI-related job options. According to a Gartner survey, companies will abandon over 60% of AI projects by 2026 due to the unavailability of AI-ready data. Solutions like Pundi AI\u2019s AIFX empower developers and users to create AI-ready data assets and trade them on-chain, offering financial incentives for curating robust datasets. Beyond pre-processing datasets, AI agents also require human assistance during the in-processing (inference) and post-processing (deployment) stages. Several methods, like Reinforcement Learning with Human Feedback (RLHF) and Human-in-the-Loop (HITL), are necessary to evaluate AI agents during training or real-time operations for effective output generation and model optimization. Similarly, interactive debugging helps human auditors to scrutinize AI agents\u2019 responses and evaluate them against societal benchmarks of fair decision-making. Sometimes, sensitive agent applications require a hybrid method combining expert human-level validation with machine-generated answers to remove uncertainties and build trust. Human intuition and creativity are key to developing new AI agents that can autonomously function in society without causing any harm. Besides enhancing autonomous AI agents\u2019 general intelligence, human supervision ensures optimal performance for high-performing agents in independent settings. Thus, a decentralized approach to building and deploying AI agents democratizes the AI industry by redistributing data and model training among people from diverse backgrounds, reducing structural bias, and creating new jobs.",
    "published_at": "2025-05-17T18:00:28Z",
    "source": "CryptoSlate",
    "url": "https://cryptoslate.com/autonomous-ai-agents-create-new-job-opportunities/",
    "summary": "Zac Cheah, Co-Founder of Pundi AI, says fully autonomous AI agents are impossible. Instead, he says, humans assist AI agents\u2019 functions throughout their lifecycle. Each agent has multiple human-led teams in the development pipeline.",
    "category": "Technology"
  },
  {
    "title": "Cryptocurrency in wealth management, a passing trend or here to stay",
    "content": "Live Events (You can now subscribe to our (You can now subscribe to our ETMarkets WhatsApp channel Should you use cryptocurrency in your cash management? Is it just a trend or will it last? There are many similar questions that come to our mind when we think of \u201cCrypto\u201d as an investment avenue. Cryptocurrency is a kind of digital or virtual money that has made big changes to how money and banks work. Cryptocurrencies are not controlled by a single entity like traditional currencies are. Instead, they are built on blockchain technology and are decentralized. They let people do business without going through brokers in a safe and clear way. Bitcoin was the first digital money. When it came out in 2009, it showed the way for thousands of other digital applications. A lot of people, including investors and tech experts, are interested in digital assets. This has led to debates about their reality and how they might affect financial systems. The way money is treated and grown has changed a lot in the last few years since wealth management became digital. Things are now quicker, easier to get to, and more personalized than ever, thanks to technology. Digital platforms and robo-advisors are new ways to handle investments, get personalized financial help, and access data analytics. Most of the time, they are cheaper than traditional services as well. As technology is used more and more in wealth management, combining AI, machine learning, and big data analytics keeps making risk management and decision-making better. Traders can now see and change their portfolios in real time. This lets them respond quickly to changes in the market and seize new opportunities. Digital tools also make things more transparent, so clients can help themselves achieve their financial goals. To stay competitive, wealth management companies need to keep making changes as the move to digital continues. It's important for them to follow the rules and come up with new ideas at the same time. Bitcoin came out more than ten years ago. Since then, a lot has changed on the internet of money. Every day, new cryptocurrencies and blockchain technologies evolve. Each is useful and helpful in its own way. A lot of people believed that cryptocurrencies were just a trend at first, but now they're seen as real tools. A growing community of decentralized apps and financial goods has made this possible. More institutions are starting to use them. Some of the positives about cryptocurrencies are that they are easy to buy and sell, they can help one achieve big gains while spreading the risk. The fact that they are not linked to regular banking systems makes them appealing during times of economic or political unrest. Also, buyers who want safe and reliable financial tools prefer the safety of blockchain technology. Wealth managers today are looking for smart ways to add digital currencies to their clients' financial accounts. Bit coins can help spread risk in portfolios. They give you a chance to get better risk-adjusted returns. Digital currencies are more volatile than other investments, hence investors need to be aware of the market. Decentralized Finance , (DeFi) and other new ideas like it show that cryptocurrencies are still useful and have a lot of potential. DeFi applications take traditional banking services away from one central location. This gives buyers more power over their money, which could mean bigger returns. If you want to add cryptocurrencies to your stock, you will face some issues, such as unclear rules, security risks, and the need for specific knowledge. To get the most out of cryptocurrencies while reducing their risks, these things need to be carefully thought through by people who know a lot about money. Most financial experts still don't agree on whether or not bitcoins can be used to make money. Some people say that the fast growth and new technologies in the area make it possible to make a lot of money. Others say that these digital assets are risky and can add more volatility to the portfolio than generate returns. People who believe in cryptocurrencies think of them as the digital gold of our time. People have always said that Bitcoin is like gold because of their scarcity, and they can be used to keep their value. Bitcoin has generated large returns since its inception. This has made early investors very wealthy and attracted new buyers looking for big gains. The same is true for Ethereum , the platform for decentralized apps and smart contracts. To make money, there are more than just individual coins. The area of decentralized finance (DeFi) is growing. People can trade assets, give and borrow money, and earn interest on DeFi platforms without going through banks or other middlemen. Most of the time, these sites offer better returns than regular investments. When investors use cryptocurrencies as part of their portfolio, they can expect mixed outcomes. It's still tough to tell when prices will change, which is why fluctuation is a big problem. Also, since digital currencies are still fairly new, the rules that govern them are always changing. This could lead to issues with the law and following the rules. Safety is another important issue. A lot of money has been lost because of hacks and scams. Even though they are aware of these risks, some investors and wealth managers say that mixing cryptocurrency with standard assets is the best way to make their portfolios do better. People who want to diversify their portfolios without taking too many risks might want to put a small amount of their money into cryptocurrency. That's why you need to study a lot, know what you want to achieve with your investments, and have good risk management skills. In the end, whether cryptocurrencies can regularly work as a way to build wealth depends on how well the market continues to grow, how widely they are used, and how well regulations are put in place to support them. To keep track of money, cryptocurrencies might become more important as these things change. Wealth management has a lot of problems that need to be fixed before they can use cryptocurrencies correctly as they keep changing. A big problem is that people don't know what the rules are. All over the world, countries are trying to figure out how to handle cryptocurrencies. Because of this, there are now a lot of different rules that can be hard to follow and put investors and experts at greater legal risk. Concerns about safety are also high, as digital assets can be lost, stolen, or hacked and used illegally. Rich people managers need to use strong security to keep their clients' information and money safe. They will have to pay a lot of money for cutting-edge tech and safety experts. To keep their clients' money safe from market changes they can't see, wealth managers have to come up with complicated risk management plans. Another issue is that cryptocurrencies are very unstable. To protect your customers, you should teach them about these risks and be honest with them about the returns they can expect and how cryptocurrencies fit into a diversified portfolio. Last but not least, the bitcoin market changes quickly, which means that people who work in wealth management need to keep learning and changing with it. Wealth managers need to keep up with new technologies and market trends so they can give their clients good help. Wealth management companies can better understand and use cryptocurrency by taking care of these issues ahead of time. This way, they can get the most out of it while reducing its risks.(The author is Director - Master of Applied Finance & Wealth Management at SP Jain School of Global Management.): Recommendations, suggestions, views and opinions given by the experts are their own. These do not represent the views of the Economic Times",
    "published_at": "2025-05-17T04:28:23Z",
    "source": "The Times of India",
    "url": "https://economictimes.indiatimes.com/markets/cryptocurrency/cryptocurrency-in-wealth-management-a-passing-trend-or-here-to-stay/articleshow/121227547.cms",
    "summary": "Crypto is a kind of digital or virtual money that has made big changes to how money and banks work. Cryptocurrencies are not controlled by a single entity like traditional currencies are. Instead, they are built on blockchain technology and are decentralized.",
    "category": "Technology"
  },
  {
    "title": "Create a Reversible Skirt for Twice the Style: A Simple Sewing Tutorial You\u2019ll Love",
    "content": "If you\u2019re looking for a sewing project that offers double the fun and twice the fashion, the reversible skirt tutorial from The Seaman Mom is a must-try! This tutorial teaches you how to make a stylish skirt that\u2019s as versatile as it is beautiful\u2014two looks in one skirt. How amazing is that? Whether you\u2019re short on closet space or just love a great deal, a reversible skirt is the perfect way to get the most out of your fabrics. With this easy-to-follow guide, you\u2019ll learn how to make a skirt that\u2019s comfortable, flattering, and fully reversible, meaning you can change your look in seconds. Whether you\u2019re at a brunch, a beach day, or out running errands, you can switch sides depending on the vibe you want. This tutorial is great for beginner to intermediate sewers who are looking to create something fun and functional. The best part? The skills you learn here can be applied to other reversible projects down the line, so you\u2019ll definitely get your money\u2019s worth in sewing knowledge. So why not try your hand at making this practical and chic reversible skirt? Head on over to The Seaman Mom\u2019s Reversible Skirt Tutorial and start sewing up your new favorite wardrobe piece today!",
    "published_at": "2025-05-17T06:07:02Z",
    "source": "Craftgossip.com",
    "url": "https://sewing.craftgossip.com/create-a-reversible-skirt-for-twice-the-style-a-simple-sewing-tutorial-youll-love/2025/05/16/",
    "summary": "This reversible skirt tutorial teaches you how to make a stylish skirt that\u2019s as versatile as it is beautiful. The skills you learn can be applied to other reversible projects down the line.",
    "category": "Technology"
  },
  {
    "title": "Don Marti: why privacy-enhancing advertising technologies failed",
    "content": "Previously: PET projects or real privacy? From recent news: Google is reportedly wrapping up work on in-browser privacy-enhancing advertising features. Instead, they\u2019re keeping third-party cookies and even encouraging going back to older user tracking methods like fingerprinting. Google\u2019s Privacy Sandbox projects were their own special case, and it certainly looks possible that their continued struggles were mostly because of trying to replicate a bunch of anticompetitive tricks from Google\u2019s old ad stack inside the browser. Privacy-enhancing technologies are hard enough without adding in all the anticompetitive stuff too. But by now it looks more and more clearn that it wasn\u2019t just a problem with Privacy Sandbox trying to do too much. Most of the hard problems of PETs for advertising are more general. Although in-browser advertising features persist, for practical purposes they\u2019re already dead code. Right now we\u2019re in a period of adjustment, and some of the interesting protocols and code will probably end up being adaptable to other areas, just not advertising. While PETs for advertising were a bad idea for a lot of reasons, all I\u2019m going to list here are the big problems they couldn\u2019t get over. PETs without consent didn\u2019t work. The original plan in the early days of Privacy Sandbox was to deploy to users with a simple Got it! dialog. That didn\u2019t work. Regulators in the UK wrote (PDF), We believe that further user research and testing of the dialogue box, using robust methodologies and a representative sample of users, is critical to resolve these concerns. Also, it is not clear if users will be prompted to revisit their choices, and the frequency of this. In the real world, PETs will be required to get the same kind of consent that other adtech is. Buried in a clickwrap agreement isn\u2019t going to pass inspection. PETs are catching the same kinds of complaints over lack of consent as any other adtech. And getting consent will be hard, because\u2026 Users are about as creeped out by PETs as by other kinds of tracking. Jereth et al. find that perceived privacy violations for a browser-based system that does not target people individually are similar to the perceived violations for conventional third-party cookies. Co-author Klaus M. Miller presented the research at FTC PrivacyCon (PDF): So keeping your data safer on your device seems to help in terms of consumer perceptions, but it doesn\u2019t make any difference whether the firm is targeting the consumer at the individual or group level in the perceived privacy perceptions. Martin et al. find substantial differences between the privacy that users expect and the privacy (ish) features of PETs. In fact, users might actually feel better about old-fashioned web tracking than about the PET kind. In sum, the use of inferences rather than raw data collected by a primary site is not a privacy solution for users. In most instances, respondents judged the use of raw data such as browsing history, location, search terms, and engagement data to be statistically the same as using inferences based on that same data. Further, for improving services across contexts, consumers judged the use of raw data as more appropriate compared to using inferences based on that same raw data. PET developers tried to come up with solutions that would work as a default for all web users, but that\u2019s just not realistic considering that the research consistently shows that people are different. About 30% of people prefer cross-context personalized advertising, 30% really don\u2019t want it, and for 40% it depends how you ask. PETs are too lossy for people who want cross-context personalized ads and too creepy for people who don\u2019t. (In addition to this published research, there is also in-house research at a variety of companies, including at some of the companies that had been most enthusiastically promoting PETs.) PETs never had a credible anti-fraud story. One of the immutable laws of adtech is that you can take any adtech term and put fraud after it, and it\u2019s a thing. PETs are no exception. Anti-fraud lesson of the 1990s: never trust the client Anti-fraud lesson of the 2000s: use machine learning on lots of data to spot patterns of fraud PETs: trust the client to obfuscate the data that your ML would have needed to spot fraud. (how was this even supposed to work?) If PET developers could count on an overwhelming percentage of users to participate in PETs honestly, then there might not be a problem. A few people would try fraud but they would get lost in the noise created by PET math. But active spoofing of PETs, if they ever caught on, would have the same triad of user motivations that open-source software does: it feels like the right thing to do (since the PETs come from the same big evil companies that people are already protesting), you would have been able to make money doing it, and it\u2019s fun. Any actual data collected by PETs would have been drowned out by fake data generated either on principle, for money, or for lulz. PETs didn\u2019t change the market. The original, optimistic pitch for PETs was that they would displace other surveillance advertising technologies in marketing budgets and VC portfolios. That didn\u2019t happen. The five-year publicity frenzy around Google\u2019s Privacy Sandbox might actually have had the opposite effect. The project\u2019s limitations, well understood by adtech developers and later summarized in an IAB Tech Lab report, encouraged more investment in the kinds of non-cookie, non-PET tracking methods that Mozilla calls unintended identification techniques. Just as we didn\u2019t see articles written for end users recommending PETs as a privacy tip\u2014because the privacy they provide isn\u2019t the privacy that users want\u2014we also didn\u2019t see anyone in the advertising business saying they were cutting back on other tracking to do PETs instead. Even Google, which was the biggest proponent of PETs for a while, lifted its 2019 ban on fingerprinting as Privacy Sandbox failed to take off. PETs would create hard-to-predict antitrust issues. If users are still creeped out by PETs, and advertisers find PET features too limiting, then the designers of PETs must be splitting the difference and doing something right, right? Well, no. PETs aren\u2019t just about users vs. advertisers, they\u2019re about large-scale platforms vs. smaller companies. PETs introduce noise and obfuscation, to make data interpretation only practical above a certain data set size\u2014for a few large companies, or one. Designers of PETs can tune the level of obfuscation introduced to make their systems practical for any desired minimum size of company. The math is complicated enough, and competition regulators have enough on their to-do lists, to make it hard to tell when PET competition issues will come up. But they will eventually. PETs would have made privacy enforcement harder. This year\u2019s most promising development in privacy news in the USA is the Honda case. Companies that had been getting by with non-compliant opt outs and Right to Know forms are finally fixing their stuff. CCPA+CPRA are progressing to their (intended?) true form, as a kind of RCRA for PII. Back in the 1980s, companies that had a bunch of random hazardous materials around decided that it was easier to safely get rid of them than to deal with RCRA paperwork, and something similar is happening for surveillance marketing today. PETs would have interfered with this trend by making it harder for researchers to spot problematic data usage practices, and helping algorithmic discrimination to persist. Conclusion: learning from the rise and fall of PETs. In most cases, there should be little or no shame in chasing a software fad. At their best, hyped-up technologies can open up a stale industry to new people by way of hiring frenzies, and create change that would have been harder to do otherwise. all right, the cryptocurrency and AI bubbles might be an exception because of the environmental impact, but the PET fad wasn\u2019t that big. Having been into last year\u2019s trendy thing can feel a little embarrassing, but really, a trend-driven industry has two advantages. A trend can give you a face-saving way to dig up and re-try a previous good project idea that didn\u2019t get funded at the time. (this could still happen with prediction markets) Investing in a trend can be an excuse to fix your dependencies (I once got to work on fixing software builds, making RPMs, and automating a GPL corresponding source release, because Docker containers were a big thing at the time) and produce software that\u2019s useful later (PDF-to-structured-text tools, so hot right now) In the case of PETs there probably should have been more user research earlier, to understand that the default PETs without consent idea wouldn\u2019t have worked and save development time, but that\u2019s a deeper problem with the relative influence of people who write code and people who do user research within companies, and not just a PET thing. The development work that went into PETs wasn\u2019t wasted, because PETs are still really promising in other areas, just not advertising. For example, energy markets could benefit from being able to predict demand without revealing when individual utility customers are at home or away. PETs are already valuable for software telemetry\u2014for example, revealing that a certain web page crashed the browser without telling the browser maintainer which users visited which pages\u2014and could end up being more widely used for other products, where the manufacturer and user have a shared interest in facilitating maintenance and improving quality. But advertising is different, mostly because it\u2019s unavoidably adversarial. Every market has honest and dishonest advertisers, and advertising\u2019s main job is to build reputation by doing something that\u2019s practical for a legit advertiser to do and as difficult as possible for a dishonest advertiser. As the shift to a low-trust economy continues, and more software companies see their reputations continue to slide, real ad reform solutions will need to come from somewhere else. More: Sunday Internet optimism #",
    "published_at": "2025-05-17T00:00:00Z",
    "source": "Zgp.org",
    "url": "https://blog.zgp.org/why-pets-failed/",
    "summary": "Google is reportedly wrapping up work on in-browser privacy-enhancing advertising features. They\u2019re keeping third-party cookies and even encouraging going back to older user tracking methods like fingerprinting.",
    "category": "Technology"
  },
  {
    "title": "Why We Think | Lil'Log",
    "content": "Test time compute (Graves et al. 2016, Ling, et al. 2017, Cobbe et al. 2021) and Chain-of-thought (CoT) (Wei et al. 2022, Nye et al. 2021), have led to significant improvements in model performance, while raising many research questions. This post aims to review recent developments in how to effectively use test-time compute (i. e. \u201cthinking time\u201d) and why it helps. Enabling models to think for longer can be motivated in a few different ways. Analogy to Psychology# The core idea is deeply connected to how humans think. We humans cannot immediately provide the answer for \"What's 12345 times 56789?\" . Rather, it is natural to spend time pondering and analyzing before getting to the result, especially for complex problems. In Thinking, Fast and Slow (Kahneman, 2013), Daniel Kahneman characterizes human thinking into two modes, through the lens of the dual process theory : Fast thinking (System 1) operates quickly and automatically, driven by intuition and emotion while requiring little to no effort. Slow thinking (System 2) demands deliberate, logical thought and significant cognitive efforts. This mode of thinking consumes more mental energy and requires intentional engagement. Because System 1 thinking is fast and easy, it often ends up being the main decision driver, at the cost of accuracy and logic. It naturally relies on our brain\u2019s mental shortcuts (i. e., heuristics) and can lead to errors and biases. By consciously slowing down and taking more time to reflect, improve and analyze, we can engage in System 2 thinking to challenge our instincts and make more rational choices. Computation as a Resource# One view of deep learning, is that neural networks can be characterized by the amount of computation and storage they can access in a forward pass, and if we optimize them to solve problems using gradient descent, the optimization process will figure out how to use these resources\u2013they\u2019ll figure out how to organize these resources into circuits for calculation and information storage. From this view, if we design an architecture or system that can do more computation at test time, and we train it to effectively use this resource, it\u2019ll work better. In Transformer models, the amount of computation (flops) that the model does for each generated token is roughly 2 times the number of parameters. For sparse models like mixture of experts (MoE), only a fraction of the parameters are used in each forward pass, so computation = 2 * parameters / sparsity, where sparsity is the fraction of experts active. On the other hand, CoT enables the model to perform far more flops of computation for each token of the answer that it is trying to compute. In fact, CoT has a nice property that it allows the model to use a variable amount of compute depending on the hardness of the problem. Latent Variable Modeling# A classic idea in machine learning is to define a probabilistic model with a latent (hidden) variable $z$ and a visible variable $y$, where $y$ is given to our learning algorithm. Marginalizing (summing) over the possible values of the latent variable allows us to express a rich distribution over the visible variables, $P(y) = \\sum_{z \\sim P(z)} P(y \\mid z)$. For example, we can model the distribution over math problems and solutions by letting $x$ denote a problem statement, $y$ be ground truth answer or proof, and $z$ as a free-form thought process that leads to the proof. The marginal probability distribution to optimize would be $P(y \\mid x) = \\sum_{z \\sim p(z\\mid x)} P(y \\mid x, z)$ The latent variable perspective is particularly useful for understanding methods that involve collecting multiple parallel CoTs or searching over the CoT\u2013these algorithms can be seen as sampling from the posterior $P(z \\mid x, y)$. This view also suggests the benefits of using the log loss $\\log P(y \\mid x)$ as the target objective to optimize, as the log loss objective has been so effective in pretraining. Thinking in Tokens# The strategy of generating intermediate steps before generating short answers, particularly for math problems, was explored by Ling, et al. 2017, who introduced the AQUA-RAT dataset, and then expanded by Cobbe et al. 2021, who introduced the Grade School Math (GSM) dataset. Cobbe et al. train a generator with supervised learning on human-written solutions and verifiers that predict the correctness of a candidate solution; they can then search over these solutions. Nye et al. (2021) experimented with intermediate thinking tokens as \u201cscratchpads\u201d and Wei et al. (2022) coined the now-standard term chain-of-thought (CoT). Early work on improving CoT reasoning involved doing supervised learning on human-written reasoning traces or model-written traces filtered for answer correctness, where the latter can be seen as a rudimentary form of reinforcement learning (RL). Some other work found that one could significantly boost math performance of instruction tuned models by prompting them appropriately, with \"think step by step\" (Kojima et al. 2022) or more complex prompting to encourage the model to reflect on related knowledge first (Yasunaga et al. 2023). Later work found that the CoT reasoning capabilities can be significantly improved by doing reinforcement learning on a dataset of problems with automatically checkable solutions, such as STEM problems with short answers, or coding tasks that can be checked with unit tests (Zelikman et al. 2022, Wang et al., 2023, Liu et al., 2023). This approach rose to prominence with the announcement of o1-preview, o3, and the R1 tech report (DeepSeek-AI, 2025), which showed that a simple recipe where a policy gradient algorithm could lead to strong performance. Chain-of-thought prompting leads to higher success rate of solving math problems. Larger models benefit more from thinking time. (Image source: Wei et al. 2022) Branching and Editing# The fundamental intent of test-time compute is to adaptively modify the model\u2019s output distribution at test time. There are various ways of utilizing test time resources for decoding to select better samples and thus alter the model\u2019s predictions towards a more desired distribution. Two main approaches for improving the decoding process are parallel sampling and sequential revision. Parallel sampling generates multiple outputs simultaneously, meanwhile providing guidance per step with process reward signals or using verifiers to judge the quality at the end. It is the most widely adopted decoding method to improve test time performance, such as best-of-$N$ or beam search. Self-consistency (Wang et al. 2023) is commonly used to select the answer with majority vote among multiple CoT rollouts when the ground truth is not available. generates multiple outputs simultaneously, meanwhile providing guidance per step with process reward signals or using verifiers to judge the quality at the end. It is the most widely adopted decoding method to improve test time performance, such as best-of-$N$ or beam search. Self-consistency (Wang et al. 2023) is commonly used to select the answer with majority vote among multiple CoT rollouts when the ground truth is not available. Sequential revision adapts the model\u2019s responses iteratively based on the output in the previous step, asking the model to intentionally reflect its existing response and correct mistakes. The revision process may have to rely on a fine-tuned model, as naively relying on the model\u2019s intrinsic capability of self-correction without external feedback may not lead to improvement (Kamoi et al. 2024, Huang et al. 2024). Parallel sampling is simple, intuitive and easier to implement, but bounded by the model capability of whether it can achieve the correct solution in one-go. Sequential explicitly asks the model to reflect on mistakes but it is slower and requires extra care during implementation as it does run the risk of correct predictions being modified to be incorrect or introducing other types of hallucinations. These two methods can be used together. Snell et al. (2024) showed that easier questions benefit from purely sequential test-time compute, whereas harder questions often perform best with an optimal ratio of sequential to parallel compute. Illustration of parallel sampling vs sequential revision. Parallel Sampling# Given a generative model and a scoring function that we can use to score full or partial samples, there are various search algorithms we can use to find a high scoring sample. Best-of-$N$ is the simplest such algorithm: one just collects $N$ independent samples and chooses the highest-ranking sample according to some scoring function. Beam search is a more sophisticated search algorithm that makes the search process more adaptive, spending more sampling computation on more promising parts of the solution space. Beam search maintains a set of promising partial sequences and alternates between extending them and pruning the less promising ones. As a selection mechanism, we can use a process reward model (PRM; Lightman et al. 2023) to guide beam search candidate selection. Xie et al. (2023) used LLM to evaluate how likely its own generated reasoning step is correct, formatted as a multiple-choice question and found that per-step self-evaluation reduces accumulative errors in multi-step reasoning during beam search decoding. Besides, during sampling, annealing the temperature helps mitigate aggregated randomness. These experiments by Xie et al. achieved 5-6% improvement on few-shot GSM8k, AQuA and StrategyQA benchmarks with the Codex model. Reward balanced search (short for \u201cREBASE\u201d; Wu et al. 2025) separately trained a process reward model (PRM) to determine how much each node should be expanded at each depth during beam search, according to the softmax-normalized reward scores. Jiang et al. (2024) trained their PRM, named \u201cRATIONALYST\u201d, for beam search guidance on synthetic rationales conditioned on a large amount of unlabelled data. Good rationales are filtered based on whether they help reduce the neg log-prob of true answer tokens by a threshold, when comparing the difference between when the rationales is included in the context vs not. At inference time, RATIONALYST provides process supervision to the CoT generator by helping estimate log-prob of next reasoning steps (\u201cimplicit\u201d) or directly generating next reasoning steps as part of the prompt (\u201cexplicit\u201d). Beam search decoding guided by LLM self-evaluation per reasoning step. (Image source: Xie et al. 2023) Interestingly, it is possible to trigger the emergent chain-of-thought reasoning paths without explicit zero-shot or few-shot prompting. Wang & Zhou (2024) discovered that if we branch out at the first sampling tokens by retaining the top $k$ tokens with highest confidence, measured as the difference between top-1 and top-2 candidates during sampling, and then continue these $k$ sampling trials with greedy decoding onward, many of these sequences natively contain CoT. Especially when CoT does appear in the context, it leads to a more confident decoding of the final answer. To calculate the confidence of the final answer, the answer span needs to be identified by task-specific heuristics (e. g. last numerical values for math questions) or by prompting the model further with \"So the answer is\" . The design choice of only branching out at the first token is based on the observation that early branching significantly enhances the diversity of potential paths, while later tokens are influenced a lot by previous sequences. Top-$k$ decoding, $k$ refers to the number of candidates at the first sampling step. (Image source: Wang & Zhou, 2024) Sequential Revision# If the model can reflect and correct mistakes in past responses, we would expect the model to produce a nice sequence of iterative revision with increasing quality. However, this self-correction capability turns out to not exist intrinsically among LLMs and does not easily work out of the box, due to various failure modes, such as, (1) hallucination, including modifying correct responses to be incorrect; (2) behavior collapse to non-correcting behavior; e. g. making minor or no modification on the first incorrect responses; or (3) fail to generalize to distribution shift at test time. Experiments by Huang et al. (2024) showed that naively applying self-correction leads to worse performance and external feedback is needed for models to self improve, which can be based on matching ground truths, heuristics and task-specific metrics, unit tests results for coding questions (Shinn, et al. 2023), a stronger model (Zhang et al. 2024), as well as human feedback (Liu et al. 2023). Self-correction learning (Welleck et al. 2023) aims to train a corrector model $P_\\theta(y \\mid y_0, x)$ given a fixed generator model $P_0(y_0 \\mid x)$. While the generator model remains to be generic, the corrector model can task-specific and only does generation conditioned on an initial model response and additional feedback (e. g. a sentence, a compiler trace, unit test results; can be optional): Self-correction learning first generates first generates multiple outputs per prompt in the data pool; then create value-improving pairs by pairing two outputs for the same prompt together if one has a higher value than the other, (prompt $x$, hypothesis $y$, correction $y\u2019$). These pairs are selected proportional to is improvement in value, $v(y\u2019) - v(y)$, and similarity between two outputs, $\\text{Similarity}(y, y\u2019)$ to train the corrector model. To encourage exploration, the corrector provides new generations into the data pool as well. At the inference time, the corrector can be used iteratively to create a correction trajectory of sequential revision. Illustration of self-correction learning by matching model outputs for the same problem to form value-improving pairs to train a correction model. (Image source: Welleck et al. 2023) Recursive inspection (Qu et al. 2024) also aims to train a better corrector model but with a single model to do both generation and self-correction. SCoRe (Self-Correction via Reinforcement Learning; Kumar et al. 2024) is a multi-turn RL approach to encourage the model to do self-correction by producing better answers at the second attempt than the one created at the first attempt. It composes two stages of training: stage 1 only maximizes the accuracy of the second attempt while enforcing a KL penalty only on the first attempt to avoid too much shifting of the first-turn responses from the base model behavior; stage 2 optimizes the accuracy of answers produced by both the first and second attempts. Ideally we do want to see performance at both first and second attempts to be better, but adding stage 1 prevents the behavior collapse where the model does minor or none edits on the first response, and stage 2 further improves the results. Explicit training setup to improve self-correction capabilities by doing two-staged RL training. (Image source: Kumar et al. 2024) RL for Better Reasoning# There\u2019s been a lot of recent success in using RL to improve the reasoning ability of language models, by using a collection of questions with ground truth answers (usually STEM problems and puzzles with easy to verify answers), and rewarding the model for getting the correct answer. Recent activity in this area was spurred by strong performance of the o -series models from OpenAI, and the subsequent releases of models and tech reports from DeepSeek. DeepSeek-R1 (DeepSeek-AI, 2025) is an open-source LLM designed to excel in tasks that require advanced reasoning skills like math, coding and logical problem solving. They run through 2 rounds of SFT-RL training, enabling R1 to be good at both reasoning and non-reasoning tasks. Cold-start SFT is to fine-tune the DeepSeek-V3-Base base model on a collection of thousands of cold-start data. Without this step, the model has issues of poor readability and language mixing. Reasoning-oriented RL trains a reasoning model on reasoning-only prompts with two types of rule-based rewards: Format rewards: The model should wrap CoTs by ... tokens. tokens. Accuracy rewards: Whether the final answers are correct. The answer for math problems needs to be present in a specific format (e. g. in a box) to be verified reliably. For coding problems, a compiler is used to evaluate whether test cases pass. Rejection-sampling + non-reasoning SFT utilizes new SFT data created by rejection sampling on the RL checkpoint of step 2, combined with non-reasoning supervised data from DeepSeek-V3 in domains like writing, factual QA, and self-cognition, to retrain DeepSeek-V3-Base . Filter out CoTs with mixed languages, long paragraphs, and code blocks. Include non-reasoning tasks using DeepSeek-V3 (DeepSeek-AI, 2024) pipeline. For certain non-reasoning tasks, call DeepSeek-V3 to generate potential CoTs before answering the question by prompting. But for simpler queries like \u201chello\u201d, CoT is not needed. Then fine-tune the DeepSeek-V3-Base on the total 800k samples for 2 epochs. The final RL stage trains the step 3 checkpoint on both reasoning and non-reasoning prompts, improving helpfulness, harmlessness and reasoning. DeepSeek-R1 performs comparable to OpenAI o1-preview and o1-mini on several widely used reasoning benchmarks. DeepSeek-V3 is the only non-reasoning model listed. (Image source: DeepSeek-AI, 2025) Interestingly the DeepSeek team showed that with pure RL, no SFT stage, it is still possible to learn advanced reasoning capabilities like reflection and backtracking (\u201cAha moment\u201d). The model naturally learns to spend more thinking tokens during the RL training process to solve reasoning tasks. The \u201caha moment\u201d can emerge, referring to the model reflecting on previous mistakes and then trying alternative approaches to correct them. Later, various open source efforts happened for replicating R1 results like Open-R1, SimpleRL-reason, and TinyZero, all based on Qwen models. These efforts also confirmed that pure RL leads to great performance on math problems, as well as the emergent \u201caha moment\u201d. Examples of the model learning to reflect and correct mistakes. (Image source: (left) DeepSeek-AI, 2025; (right) Zeng et al. 2025) The DeepSeek team also shared some of their unsuccessful attempts. They failed to use process reward model (PRM) as it is hard to define per-step rubrics or determine whether an intermediate step is correct, meanwhile making the training more vulnerable to reward hacking. The efforts on MCTS (Monte Carlo Tree Search) also failed due to the large search space for language model tokens, in comparison to, say, chess; and training the fine-grained value model used for guiding the search is very challenging too. Failed attempts often provide unique insights and we would like to encourage the research community to share more about what did not work out. External Tool Use# During the reasoning steps, certain intermediate steps can be reliably and accurately solved by executing code or running mathematical calculations. Offloading that part of reasoning components into an external code interpreter, as in PAL (Program-Aided Language Model; Gao et al. 2022) or Chain of Code (Li et al. 2023), can extend the capability of LLM with external tools, eliminating the need for LLMs to learn to execute code or function as calculators themselves. These code emulators, like in Chain of Code, can be augmented by an LLM such that if a standard code interpreter fails, we have the option of using LLM to execute that line of code instead. Using code to enhance reasoning steps are especially beneficial for mathematical problems, symbolic reasoning and algorithmic tasks. These unit tests may not exist as part of the coding questions, and in those cases, we can instruct the model to self-generate unit tests for it to test against to verify the solution (Shinn, et al. 2023). An example of program-aided language model prompting looks like. (Image source: Gao et al. 2022) ReAct (Reason+Act; Yao et al. 2023) combines the action of searching the Wikipedia API and generation of reasoning traces, such that reasoning paths can incorporate external knowledge. An example of the ReAct prompting method to solve a HotpotQA question, using Wikipedia search API as an external tool to help with reasoning. (Image source: Yao et al. 2023) o3 & o4-mini, recently released by OpenAI, are another two good examples where the reasoning process involves tool use like Web search, code execution and image processing. The team observed that large-scale reinforcement learning exhibits the same trend as in the GPT paradigm that \u201cmore compute = better performance\u201d. Thinking Faithfully# Deep learning models are often treated as black boxes and various interpretability methods have been proposed. Interpretability is useful for a couple reasons: first, it gives us an extra test to determine if the model is misaligned with its creators\u2019 intent, or if it\u2019s misbehaving in some way that we can\u2019t tell by monitoring its actions. Second, it can help us determine whether the model is using a sound process to compute its answers. Chain of thought provides an especially convenient form of interpretability, as it makes the model\u2019s internal process visible in natural language. This interpretability, however, rests on the assumption that the model truthfully describes its internal thought processes. Recent work showed that monitoring CoT of reasoning models can effectively detect model misbehavior such as reward hacking, and can even enable a weaker model to monitor a stronger model (Baker et al. 2025). Increasing test time compute can also lead to improved adversarial robustness (Zaremba et al. 2025); this makes sense intuitively, because thinking for longer should be especially useful when the model is presented with an unusual input, such as an adversarial example or jailbreak attempt \u2013 it can use the extra thinking time to make sense of the strange situation it\u2019s been presented with. The experiment of asking the model to decide if another model tried to hack the unit tests in some way for coding questions given its thought process. We can monitor these reward hacking behavior during training with different types of monitor. The exit(0) coding hack is when the agent exploited a bug that allowed it to exit from the environment early without running all unit tests. The raise SkipTest hack is when the agent raises an exception from functions outside the testing framework in order to skip unit test evaluation. (Image source: Baker et al. 2025) Does the Model Tell What it Thinks Faithfully# Intuitively, model CoTs could be biased due to lack of explicit training objectives aimed at encouraging faithful reasoning. Or when we fine-tune the model on human-written explanations, those human-written samples may contain mistakes. Thus we cannot by default assume CoT is always faithful . Lanham et al. (2023) investigated several modes of CoT faithfulness failures by deliberately introducing mistakes into CoTs and measuring their impacts on the accuracy of a set of multiple choice tasks (e. g. AQuA, MMLU, ARC Challenge, TruthfulQA, HellaSwag): Mistake 1 (Early answering): The model may form a conclusion prematurely before CoT is generated. This is tested by early truncating or inserting mistakes into CoT. Different tasks revealed varying task-specific dependencies on CoT effectiveness; some have evaluation performance sensitive to truncated CoT but some do not. Wang et al. (2023) did similar experiments but with more subtle mistakes related to bridging objects or language templates in the formation of CoT. Mistake 2 (Uninformative tokens): Uninformative CoT tokens improve performance. This hypothesis is tested by replacing CoT with filler text (e. g. all periods) and this setup shows no accuracy increase and some tasks may suffer performance drop slightly when compared to no CoT. Mistake 3 (Human-unreadable encoding): Relevant information is encoded in a way that is hard for humans to understand. Paraphrasing CoTs in an non-standard way did not degrade performance across datasets, suggesting accuracy gains do not rely on human-readable reasoning. Illustration of different ways of CoT perturbation to assess its faithfulness. (Image source: Lanham et al. 2023) Interestingly, Lanham et al. suggests that for multiple choice questions, smaller models may not be capable enough of utilizing CoT well, whereas larger models may have been able to solve the tasks without CoT. This dependency on CoT reasoning, measured by the percent of obtaining the same answer with vs without CoT, does not always increase with model size on multiple choice questions, but does increase with model size on addition tasks, implying that thinking time matters more for complex reasoning tasks.",
    "published_at": "2025-05-18T05:47:01Z",
    "source": "Github.io",
    "url": "https://lilianweng.github.io/posts/2025-05-01-thinking/",
    "summary": "Test time compute and Chain-of-thought have led to significant improvements in model performance. Enabling models to think for longer can be motivated in a few different ways.",
    "category": "Technology"
  },
  {
    "title": "Why AI tokens are emerging as high-conviction investment theme in 2025",
    "content": "What Are AI Tokens? Live Events Why Now? What Are the Use Cases? Final Thoughts (You can now subscribe to our (You can now subscribe to our ETMarkets WhatsApp channel The AI sector continues to ride a strong upward momentum. Just this week, AI-focused crypto tokens added nearly $10 billion in market capitalization, with several top assets rallying over 100% in seven days. Backed by real advancements in AI agent technology and token utility, this surge is more than just market noise\u2014it reflects a broader convergence of artificial intelligence and decentralized finance that investors can no longer afford to ignore. The buzz isn\u2019t limited to price action. Several real-world projects are bringing the power of AI to everyday users in simple and useful ways. For instance, Magic Labs, backed by PayPal, has launched Newton\u2014an AI assistant that can automatically manage DeFi investments like trading and earning interest, all while keeping users\u2019 information secure and private. Another example is Pixel AI, a game built on the Solana blockchain, where players can earn rewards by competing for digital space using the $PIXAI token. And then there\u2019s GAIB, which has introduced AID Alpha\u2014a digital asset backed by income from high-performance computer chips (GPUs), giving investors a new way to earn returns from the growing demand for AI computing. AI tokens are digital assets that combine artificial intelligence and blockchain to power decentralized applications such as data processing, intelligent indexing, autonomous trading strategies, and GPU (Graphics Processing Unit) sharing. GPUs are high-performance processors optimized for parallel computations, making them essential for training and running advanced AI models. Within the Web3 ecosystem, these tokens serve multiple roles\u2014they are used to pay for services, reward contributors, and participate in protocol governance through voting mechanisms. Their utility across various functions fuels demand, which in turn can drive up token value. Simply put, the more an AI platform is used, the greater the potential value of its native token\u2014making AI tokens central to the evolution and economic sustainability of decentralized AI networks. In essence, AI tokens are functional instruments that back real use cases in the evolving Web3 ecosystem. Three powerful forces are driving the rise of AI tokens. First, mainstream AI adoption is accelerating\u2014companies like Nvidia have surpassed a $3 trillion market cap, while generative AI tools such as ChatGPT have become household names, firmly establishing AI as a core layer of the future tech stack. Second, blockchain is emerging as the ideal infrastructure for AI\u2014transparent, decentralized, and programmable\u2014enabling autonomous AI agents to operate with verifiable accountability through smart contracts. Third, the surge in AI token valuations\u2014averaging over 2,900% in 2024\u2014has captured the attention of both retail traders and institutional investors, including hedge funds, who are now exploring AI-linked crypto assets as a high-growth frontier beyond traditional markets. Assets are only as strong as the technology they are built upon\u2014and in the case of crypto, that foundation is everything. AI tokens are emerging as high-potential digital assets precisely because they are rooted in powerful, rapidly advancing technologies at the intersection of artificial intelligence and blockchain. One of the most compelling use cases is autonomous AI agents\u2014platforms like Virtuals enable users to create tokenized agents that perform predefined tasks such as executing trading strategies or managing cross-chain interactions with minimal human intervention. Beyond automation, these tokens are facilitating the rise of decentralized marketplaces for data, compute power, and AI model sharing, laying the groundwork for a more open and inclusive AI economy. AI tokens are also being used to power predictive analytics platforms, which apply machine learning models to forecast crypto market trends\u2014providing traders, funds, and institutions with timely, data-driven insights. At the infrastructure layer, projects like GAIB are tokenizing access to income-generating GPU supply chains, allowing investors to earn yield from AI compute resources\u2014essentially unlocking exposure to the hardware that fuels AI innovation. AI tokens are no longer a side story\u2014they are fast becoming the main plotline in both crypto and tech investing. For equity investors looking to diversify, and for crypto traders seeking fundamentally-backed narratives, AI tokens offer exposure to one of the most promising intersections of technology today.(The author Paras Malhotra is SVP - Trade, Custody and BizOps, CoinDCX. Views are own)",
    "published_at": "2025-05-17T07:10:15Z",
    "source": "The Times of India",
    "url": "https://economictimes.indiatimes.com/markets/cryptocurrency/why-ai-tokens-are-emerging-as-high-conviction-investment-theme-in-2025/articleshow/121230451.cms",
    "summary": "The AI sector continues to ride a strong upward momentum. Just this week, AI-focused crypto tokens added nearly $10 billion in market capitalization. Several top assets rallied over 100% in seven days.",
    "category": "Technology"
  },
  {
    "title": "Critical Survey: Duos Technologies Group (NASDAQ:DUOT) & Enfusion (NYSE:ENFN)",
    "content": "Duos Technologies Group (NASDAQ:DUOT \u2013 Get Free Report) and Enfusion (NYSE:ENFN \u2013 Get Free Report) are both small-cap business services companies, but which is the superior investment? We will contrast the two companies based on the strength of their risk, analyst recommendations, valuation, earnings, institutional ownership, profitability and dividends. Volatility & Risk Duos Technologies Group has a beta of 0.97, meaning that its stock price is 3% less volatile than the S&P 500. Comparatively, Enfusion has a beta of 0.92, meaning that its stock price is 8% less volatile than the S&P 500. Get Duos Technologies Group alerts: Profitability This table compares Duos Technologies Group and Enfusion\u2019s net margins, return on equity and return on assets. Net Margins Return on Equity Return on Assets Duos Technologies Group -143.17% -271.06% -64.01% Enfusion 1.70% 6.67% 4.86% Earnings and Valuation Gross Revenue Price/Sales Ratio Net Income Earnings Per Share Price/Earnings Ratio Duos Technologies Group $7.28 million 12.92 -$11.24 million ($1.40) -5.76 Enfusion $201.61 million 6.94 $6.03 million $0.03 361.63 This table compares Duos Technologies Group and Enfusion\u201ds top-line revenue, earnings per share and valuation. Enfusion has higher revenue and earnings than Duos Technologies Group. Duos Technologies Group is trading at a lower price-to-earnings ratio than Enfusion, indicating that it is currently the more affordable of the two stocks. Analyst Ratings This is a breakdown of recent ratings and target prices for Duos Technologies Group and Enfusion, as reported by MarketBeat. com. Sell Ratings Hold Ratings Buy Ratings Strong Buy Ratings Rating Score Duos Technologies Group 0 0 2 0 3.00 Enfusion 0 2 1 0 2.33 Duos Technologies Group currently has a consensus target price of $11.50, suggesting a potential upside of 42.50%. Enfusion has a consensus target price of $12.25, suggesting a potential upside of 12.91%. Given Duos Technologies Group\u2019s stronger consensus rating and higher probable upside, research analysts clearly believe Duos Technologies Group is more favorable than Enfusion. Insider and Institutional Ownership 42.6% of Duos Technologies Group shares are held by institutional investors. Comparatively, 81.1% of Enfusion shares are held by institutional investors. 6.1% of Duos Technologies Group shares are held by company insiders. Comparatively, 36.4% of Enfusion shares are held by company insiders. Strong institutional ownership is an indication that hedge funds, large money managers and endowments believe a stock will outperform the market over the long term. Summary Enfusion beats Duos Technologies Group on 9 of the 14 factors compared between the two stocks. About Duos Technologies Group (Get Free Report) Duos Technologies Group, Inc. designs, develops, deploys, and operates intelligent technology solutions in North America. The company provides solutions, such as Centraco, an enterprise information management software platform that consolidates data and events from multiple sources into a unified and distributive user interface; and truevue360, an integrated platform to develop and deploy artificial intelligence algorithms, including machine learning, computer vision, object detection, and deep neural network-based processing for real-time applications. Its proprietary applications include Railcar Inspection Portal that provides freight and transit railroad customers and select government agencies the ability to conduct fully automated railcar inspections of trains while they are moving at full speed. It also develops Automated Logistics Information System, which automates gatehouse operations, as well as develops solutions for rail, trucking, aviation, and other vehicle-based processes. In addition, the company provides consulting services, including consulting and auditing; software licensing with optional hardware sales; customer service training; and maintenance support. The company operates its services under the duostech brand. The company is headquartered in Jacksonville, Florida. About Enfusion (Get Free Report) Enfusion, Inc. provides software-as-a-service solutions for investment management industry in the United States, Europe, the Middle East, Africa, and the Asia Pacific. The company provides Portfolio Management System, which generates a real-time investment book of record that consists of valuation and risk tools, which allows users to analyze aggregated or decomposed portfolio data for chief investment officers (CIOs) and portfolio managers; and Order and Execution Management System that enables portfolio managers, traders, compliance teams, and analysts to electronically communicate trade orders for a variety of asset classes, manage trade orders, and systemically enforce trading regulations and internal guidelines. It also offers Accounting/General Ledger System, a real-time accounting book of record for chief financial officers, chief operating officers, accountants, and operations teams; Enfusion Analytics System, which enables CIOs, portfolio managers, traders, and analysts to analyze portfolios through time horizons and automate customized visualized reports for internal and external stakeholders; and technology-powered and managed services. Enfusion, Inc. was founded in 1997 and is headquartered in Chicago, Illinois. Receive News & Ratings for Duos Technologies Group Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Duos Technologies Group and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T05:25:04Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/critical-survey-duos-technologies-group-nasdaqduot-enfusion-nyseenfn/",
    "summary": "Duos Technologies Group (NASDAQ:DUOT) and Enfusion (NYSE:ENFN \u2013 Get Free Report) are both small-cap business services companies. Duos Technologies group has a beta of 0.97, meaning that its stock price is 3% less volatile than the S&P 500. En fusion has a Beta of 8.92.",
    "category": "Business"
  },
  {
    "title": "Head to Head Analysis: Twin Disc (NASDAQ:TWIN) versus Palladyne AI (NASDAQ:STRCW)",
    "content": "Palladyne AI (NASDAQ:STRCW \u2013 Get Free Report) and Twin Disc (NASDAQ:TWIN \u2013 Get Free Report) are both manufacturing companies, but which is the better stock? We will contrast the two businesses based on the strength of their earnings, valuation, dividends, risk, profitability, analyst recommendations and institutional ownership. Profitability This table compares Palladyne AI and Twin Disc\u2019s net margins, return on equity and return on assets. Get Palladyne AI alerts: Net Margins Return on Equity Return on Assets Palladyne AI N/A N/A N/A Twin Disc 2.92% 4.24% 2.09% Analyst Recommendations This is a summary of recent ratings and recommmendations for Palladyne AI and Twin Disc, as reported by MarketBeat. Sell Ratings Hold Ratings Buy Ratings Strong Buy Ratings Rating Score Palladyne AI 0 0 0 0 0.00 Twin Disc 0 0 1 0 3.00 Institutional & Insider Ownership Twin Disc has a consensus price target of $12.00, indicating a potential upside of 61.29%. Given Twin Disc\u2019s stronger consensus rating and higher probable upside, analysts plainly believe Twin Disc is more favorable than Palladyne AI. 65.3% of Twin Disc shares are owned by institutional investors. 21.3% of Twin Disc shares are owned by insiders. Strong institutional ownership is an indication that large money managers, hedge funds and endowments believe a company will outperform the market over the long term. Valuation and Earnings This table compares Palladyne AI and Twin Disc\u201ds top-line revenue, earnings per share (EPS) and valuation. Gross Revenue Price/Sales Ratio Net Income Earnings Per Share Price/Earnings Ratio Palladyne AI N/A N/A N/A N/A N/A Twin Disc $321.40 million 0.33 $10.99 million $0.29 25.66 Twin Disc has higher revenue and earnings than Palladyne AI. Summary Twin Disc beats Palladyne AI on 9 of the 9 factors compared between the two stocks. About Palladyne AI (Get Free Report) Palladyne AI Corp., a software company, focuses on delivering software that enhances the utility and functionality of third-party stationary and mobile robotic systems in the United States. Its Artificial Intelligence (AI)/ Machine Learning (ML) software platform enables robots to observe, learn, reason, and act in structured and unstructured environments. The company's software platform enables robotic systems to perceive their environment and quickly adapt to changing circumstances by generalizing from their experience using dynamic real-time operations without extensive programming and with minimal robot training. It serves customers from various industries, such as industrial manufacturing, warehousing and logistics, defense, infrastructure maintenance and repair, energy, aerospace and aviation, and others. The company was formerly known as Sarcos Technology and Robotics Corporation and changed its name to Palladyne AI Corp. in March 2024. Palladyne AI Corp. was founded in 2017 and is headquartered in Salt Lake City, Utah. About Twin Disc (Get Free Report) Twin Disc, Incorporated engages in the design, manufacture, and sale of marine and heavy duty off-highway power transmission equipment in the United States, the Netherlands, China, Australia, Italy, and internationally. The company operates in two segments, Manufacturing and Distribution. Its principal products include marine transmissions, azimuth drives, surface drives, propellers, and boat management systems, as well as power-shift transmissions, hydraulic torque converters, power take-offs, industrial clutches, and controls systems. The company also provides third-party manufactured products. It sells its products through a direct sales force and distributor network to customers primarily in the pleasure craft, commercial marine, patrol, and military marine markets, as well as in the energy and natural resources, government, agriculture, recycling, construction, oil and gas, and industrial markets. The company was incorporated in 1918 and is headquartered in Milwaukee, Wisconsin. Receive News & Ratings for Palladyne AI Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Palladyne AI and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:27:02Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/head-to-head-analysis-twin-disc-nasdaqtwin-versus-palladyne-ai-nasdaqstrcw/",
    "summary": "Palladyne AI and Twin Disc are both manufacturing companies, but which is the better stock? We will contrast the two businesses based on the strength of their earnings, valuation, dividends, risk, profitability, analyst recommendations and institutional ownership.",
    "category": "Business"
  },
  {
    "title": "Viasat (VSAT) Expected to Announce Quarterly Earnings on Tuesday",
    "content": "Viasat (NASDAQ:VSAT \u2013 Get Free Report) is projected to announce its Q4 2025 earnings results after the market closes on Tuesday, May 20th. Analysts expect the company to announce earnings of $0.03 per share and revenue of $1.14 billion for the quarter. Viasat Stock Performance VSAT opened at $10.92 on Friday. The firm has a market capitalization of $1.41 billion, a PE ratio of -3.25 and a beta of 1.01. Viasat has a twelve month low of $6.69 and a twelve month high of $26.70. The firm\u2019s 50-day moving average price is $9.45 and its 200 day moving average price is $9.28. The company has a current ratio of 1.80, a quick ratio of 1.60 and a debt-to-equity ratio of 1.35. Get Viasat alerts: Institutional Investors Weigh In On Viasat Institutional investors and hedge funds have recently made changes to their positions in the stock. Royal Bank of Canada raised its stake in shares of Viasat by 483.2% in the 1st quarter. Royal Bank of Canada now owns 109,448 shares of the communications equipment provider\u2019s stock valued at $1,140,000 after acquiring an additional 90,680 shares during the period. Empowered Funds LLC increased its stake in Viasat by 6.9% during the 1st quarter. Empowered Funds LLC now owns 226,184 shares of the communications equipment provider\u2019s stock worth $2,357,000 after buying an additional 14,575 shares during the period. AQR Capital Management LLC increased its stake in Viasat by 189.7% during the 1st quarter. AQR Capital Management LLC now owns 452,933 shares of the communications equipment provider\u2019s stock worth $4,692,000 after buying an additional 296,612 shares during the period. Millennium Management LLC increased its stake in Viasat by 673.7% during the 1st quarter. Millennium Management LLC now owns 1,386,089 shares of the communications equipment provider\u2019s stock worth $14,443,000 after buying an additional 1,206,935 shares during the period. Finally, Goldman Sachs Group Inc. increased its stake in Viasat by 64.9% during the 1st quarter. Goldman Sachs Group Inc. now owns 2,866,242 shares of the communications equipment provider\u2019s stock worth $29,866,000 after buying an additional 1,128,338 shares during the period. 86.05% of the stock is owned by hedge funds and other institutional investors. Wall Street Analysts Forecast Growth Several equities analysts have weighed in on VSAT shares. Needham & Company LLC reiterated a \u201cbuy\u201d rating and issued a $19.00 target price on shares of Viasat in a report on Monday, February 10th. StockNews. com raised shares of Viasat from a \u201csell\u201d rating to a \u201chold\u201d rating in a research note on Friday, March 7th. Cantor Fitzgerald initiated coverage on shares of Viasat in a research note on Friday, January 24th. They issued a \u201cneutral\u201d rating and a $12.00 price target for the company. Deutsche Bank Aktiengesellschaft raised shares of Viasat from a \u201chold\u201d rating to a \u201cbuy\u201d rating and set a $15.00 price target for the company in a research note on Monday, March 24th. Finally, William Blair reissued a \u201cmarket perform\u201d rating on shares of Viasat in a research note on Tuesday, April 15th. Six equities research analysts have rated the stock with a hold rating and three have assigned a buy rating to the company\u2019s stock. Based on data from MarketBeat, the stock presently has a consensus rating of \u201cHold\u201d and an average target price of $14.57. View Our Latest Report on VSAT About Viasat (Get Free Report) Viasat, Inc provides broadband and communications products and services worldwide. The company's Satellite Services segment offers satellite-based fixed broadband services, including broadband internet access and voice over internet protocol services to consumers and businesses; in-flight entertainment and aviation software services to commercial airlines and private business jets; satellite-based connectivity services; mobile broadband services, including satellite-based internet services to energy offshore vessels, cruise ships, consumer ferries, and yachts; and energy services, which include ultra-secure solutions IP connectivity, bandwidth-optimized over-the-top applications, industrial internet-of-things big data enablement, and industry-leading machine learning analytics. Further Reading Receive News & Ratings for Viasat Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Viasat and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-18T05:30:55Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/18/viasat-vsat-expected-to-announce-quarterly-earnings-on-tuesday/",
    "summary": "Viasat (NASDAQ:VSAT \u2013 Get Free Report) is projected to announce its Q4 2025 earnings results after the market closes on Tuesday, May 20th. Analysts expect the company to announce earnings of $0.03 per share and revenue of $1.14 billion for the quarter.",
    "category": "Technology"
  },
  {
    "title": "ServiceNow (NYSE:NOW) Trading 0.7% Higher Following Analyst Upgrade",
    "content": "ServiceNow, Inc. (NYSE:NOW \u2013 Get Free Report)\u2019s share price shot up 0.7% during trading on Thursday after BMO Capital Markets raised their price target on the stock from $1,025.00 to $1,150.00. BMO Capital Markets currently has an outperform rating on the stock. ServiceNow traded as high as $1,034.46 and last traded at $1,033.72. 273,102 shares were traded during trading, a decline of 82% from the average session volume of 1,514,736 shares. The stock had previously closed at $1,026.82. Other equities analysts have also recently issued research reports about the company. Guggenheim lifted their price target on ServiceNow from $716.00 to $724.00 and gave the stock a \u201csell\u201d rating in a report on Thursday, April 24th. The Goldman Sachs Group reiterated a \u201cbuy\u201d rating on shares of ServiceNow in a report on Thursday, April 24th. Morgan Stanley raised their price objective on shares of ServiceNow from $881.00 to $950.00 and gave the stock an \u201cequal weight\u201d rating in a research report on Thursday, April 24th. Citigroup raised their price objective on shares of ServiceNow from $1,128.00 to $1,160.00 and gave the stock a \u201cbuy\u201d rating in a research report on Wednesday, May 7th. Finally, Truist Financial upgraded shares of ServiceNow from a \u201chold\u201d rating to a \u201cbuy\u201d rating and raised their price objective for the stock from $950.00 to $1,200.00 in a research report on Thursday, May 1st. One analyst has rated the stock with a sell rating, three have given a hold rating, twenty-nine have issued a buy rating and one has issued a strong buy rating to the company. According to MarketBeat, the stock currently has a consensus rating of \u201cModerate Buy\u201d and a consensus price target of $1,062.50. Get ServiceNow alerts: Check Out Our Latest Research Report on ServiceNow Insider Activity at ServiceNow Institutional Investors Weigh In On ServiceNow In other news, insider Jacqueline P. Canney sold 66 shares of the company\u2019s stock in a transaction dated Tuesday, May 13th. The shares were sold at an average price of $1,023.00, for a total transaction of $67,518.00. Following the transaction, the insider now owns 3,027 shares in the company, valued at approximately $3,096,621. This represents a 2.13% decrease in their ownership of the stock. The sale was disclosed in a document filed with the Securities & Exchange Commission, which is accessible through this link . Also, General Counsel Russell S. Elmer sold 1,023 shares of the company\u2019s stock in a transaction dated Tuesday, February 18th. The shares were sold at an average price of $988.00, for a total transaction of $1,010,724.00. Following the transaction, the general counsel now owns 4,332 shares in the company, valued at $4,280,016. This represents a 19.10% decrease in their position. The disclosure for this sale can be found here . Insiders have sold a total of 13,872 shares of company stock worth $13,261,400 over the last quarter. Company insiders own 0.38% of the company\u2019s stock. A number of institutional investors and hedge funds have recently made changes to their positions in NOW. GAMMA Investing LLC raised its holdings in shares of ServiceNow by 87,501.3% in the 1st quarter. GAMMA Investing LLC now owns 2,689,361 shares of the information technology services provider\u2019s stock worth $2,141,108,000 after acquiring an additional 2,686,291 shares during the last quarter. Norges Bank acquired a new stake in shares of ServiceNow in the 4th quarter worth about $2,603,360,000. Nuveen LLC acquired a new stake in shares of ServiceNow in the 1st quarter worth about $1,817,535,000. OVERSEA CHINESE BANKING Corp Ltd raised its holdings in shares of ServiceNow by 1,586.5% in the 1st quarter. OVERSEA CHINESE BANKING Corp Ltd now owns 933,209 shares of the information technology services provider\u2019s stock worth $742,965,000 after acquiring an additional 877,875 shares during the last quarter. Finally, Goldman Sachs Group Inc. raised its holdings in shares of ServiceNow by 131.4% in the 1st quarter. Goldman Sachs Group Inc. now owns 1,480,526 shares of the information technology services provider\u2019s stock worth $1,178,706,000 after acquiring an additional 840,731 shares during the last quarter. Institutional investors and hedge funds own 87.18% of the company\u2019s stock. ServiceNow Stock Up 0.5% The company has a debt-to-equity ratio of 0.15, a quick ratio of 1.10 and a current ratio of 1.10. The company has a market cap of $215.33 billion, a price-to-earnings ratio of 152.30, a price-to-earnings-growth ratio of 4.51 and a beta of 0.97. The stock\u2019s fifty day moving average is $863.52 and its two-hundred day moving average is $973.12. ServiceNow (NYSE:NOW \u2013 Get Free Report) last posted its earnings results on Wednesday, April 23rd. The information technology services provider reported $4.04 earnings per share for the quarter, topping analysts\u2019 consensus estimates of $3.78 by $0.26. ServiceNow had a net margin of 12.97% and a return on equity of 17.11%. The company had revenue of $3.09 billion for the quarter, compared to analyst estimates of $3.09 billion. During the same quarter in the prior year, the business posted $3.41 EPS. The firm\u2019s revenue was up 18.6% compared to the same quarter last year. Sell-side analysts predict that ServiceNow, Inc. will post 8.93 earnings per share for the current fiscal year. ServiceNow declared that its board has authorized a share repurchase plan on Wednesday, January 29th that allows the company to repurchase $3.00 billion in shares. This repurchase authorization allows the information technology services provider to purchase up to 1.3% of its stock through open market purchases. Stock repurchase plans are generally a sign that the company\u2019s management believes its shares are undervalued. About ServiceNow (Get Free Report) ServiceNow, Inc provides end to-end intelligent workflow automation platform solutions for digital businesses in the North America, Europe, the Middle East and Africa, Asia Pacific, and internationally. The company operates the Now platform for end-to-end digital transformation, artificial intelligence, machine learning, robotic process automation, process mining, performance analytics, and collaboration and development tools. Read More Receive News & Ratings for ServiceNow Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for ServiceNow and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T05:45:06Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/servicenow-nysenow-trading-0-7-higher-following-analyst-upgrade/",
    "summary": "BMO Capital Markets raised their price target on the stock from $1,025.00 to $1,.150.00. ServiceNow, Inc. (NYSE:NOW \u2013 Get Free Report)\u2019s share price shot up 0.7% during trading on Thursday. The stock had previously closed at $1.026.82. 273,102 shares were traded during trading, a decline of 82% from the average.",
    "category": "Technology"
  },
  {
    "title": "Extreme Networks (NASDAQ:EXTR) Earns Buy Rating from Needham & Company LLC",
    "content": "Extreme Networks (NASDAQ:EXTR \u2013 Get Free Report)\u2018s stock had its \u201cbuy\u201d rating reissued by stock analysts at Needham & Company LLC in a report issued on Thursday,Benzinga reports. They currently have a $20.00 price objective on the technology company\u2019s stock. Needham & Company LLC\u2019s price objective would indicate a potential upside of 23.30% from the stock\u2019s current price. EXTR has been the subject of several other reports. UBS Group cut their target price on Extreme Networks from $16.50 to $15.00 and set a \u201cneutral\u201d rating for the company in a research note on Thursday, May 1st. Rosenblatt Securities reiterated a \u201cbuy\u201d rating and set a $18.00 price target on shares of Extreme Networks in a report on Thursday, May 1st. Lake Street Capital lowered their price target on shares of Extreme Networks from $16.00 to $15.00 and set a \u201chold\u201d rating for the company in a report on Thursday, May 1st. Finally, StockNews. com upgraded shares of Extreme Networks from a \u201cbuy\u201d rating to a \u201cstrong-buy\u201d rating in a report on Tuesday. Two research analysts have rated the stock with a hold rating, four have issued a buy rating and one has issued a strong buy rating to the company. According to data from MarketBeat, Extreme Networks currently has an average rating of \u201cModerate Buy\u201d and an average target price of $18.58. Get Extreme Networks alerts: Get Our Latest Stock Report on EXTR Extreme Networks Stock Down 0.7% NASDAQ EXTR opened at $16.22 on Thursday. The business has a fifty day moving average price of $13.43 and a two-hundred day moving average price of $15.39. The company has a debt-to-equity ratio of 3.34, a current ratio of 0.93 and a quick ratio of 0.68. Extreme Networks has a fifty-two week low of $10.10 and a fifty-two week high of $19.24. The stock has a market capitalization of $2.16 billion, a PE ratio of -17.26, a PEG ratio of 3.06 and a beta of 1.67. Extreme Networks (NASDAQ:EXTR \u2013 Get Free Report) last released its earnings results on Wednesday, April 30th. The technology company reported $0.21 earnings per share for the quarter, topping the consensus estimate of $0.19 by $0.02. Extreme Networks had a negative return on equity of 110.86% and a negative net margin of 11.98%. The firm had revenue of $284.51 million during the quarter, compared to analysts\u2019 expectations of $280.32 million. During the same period in the prior year, the company earned ($0.19) earnings per share. The company\u2019s quarterly revenue was up 34.8% on a year-over-year basis. Equities analysts expect that Extreme Networks will post 0.31 earnings per share for the current fiscal year. Extreme Networks declared that its Board of Directors has initiated a stock repurchase program on Tuesday, February 18th that authorizes the company to buyback $200.00 million in shares. This buyback authorization authorizes the technology company to purchase up to 9.2% of its stock through open market purchases. Stock buyback programs are usually a sign that the company\u2019s board believes its shares are undervalued. Insider Activity at Extreme Networks In related news, CEO Edward Meyercord sold 35,725 shares of the stock in a transaction on Thursday, May 1st. The stock was sold at an average price of $13.73, for a total value of $490,504.25. Following the completion of the sale, the chief executive officer now directly owns 1,510,719 shares in the company, valued at $20,742,171.87. This represents a 2.31% decrease in their ownership of the stock. The transaction was disclosed in a document filed with the SEC, which is available at this hyperlink. 3.70% of the stock is currently owned by company insiders. Institutional Trading of Extreme Networks Institutional investors and hedge funds have recently bought and sold shares of the stock. Byrne Asset Management LLC acquired a new stake in Extreme Networks in the fourth quarter valued at $30,000. Sterling Capital Management LLC increased its holdings in Extreme Networks by 603.3% in the fourth quarter. Sterling Capital Management LLC now owns 1,941 shares of the technology company\u2019s stock valued at $32,000 after purchasing an additional 1,665 shares during the period. Orion Capital Management LLC acquired a new stake in Extreme Networks in the fourth quarter valued at $33,000. Smartleaf Asset Management LLC increased its holdings in Extreme Networks by 385.1% in the fourth quarter. Smartleaf Asset Management LLC now owns 2,183 shares of the technology company\u2019s stock valued at $37,000 after purchasing an additional 1,733 shares during the period. Finally, Quarry LP increased its holdings in Extreme Networks by 42.1% in the fourth quarter. Quarry LP now owns 2,426 shares of the technology company\u2019s stock valued at $41,000 after purchasing an additional 719 shares during the period. 91.05% of the stock is currently owned by institutional investors and hedge funds. About Extreme Networks (Get Free Report) Extreme Networks, Inc delivers cloud-driven networking solutions that leverage the powers of machine learning, artificial intelligence, analytics, and automation. The company designs, develops, and manufactures wired and wireless network infrastructure equipment and develops the software for network management, policy, analytics, security, and access controls. Featured Articles Receive News & Ratings for Extreme Networks Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Extreme Networks and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T05:54:48Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/extreme-networks-nasdaqextr-earns-buy-rating-from-needham-company-llc/",
    "summary": "Extreme Networks (NASDAQ:EXTR)\u2019s stock had its \u201cbuy\u201d rating reissued by stock analysts at Needham & Company LLC in a report issued on Thursday. They currently have a $20.00 price objective on the technology company's stock. Needham and Company LLC\u2019S price objective would indicate a potential upside of 23.30% from the stock's current price.",
    "category": "Technology"
  },
  {
    "title": "Keefe, Bruyette & Woods Issues Positive Forecast for Riskified (NYSE:RSKD) Stock Price",
    "content": "Riskified (NYSE:RSKD \u2013 Get Free Report) had its price target raised by equities researchers at Keefe, Bruyette & Woods from $5.25 to $5.50 in a research report issued on Thursday,Benzinga reports. The firm presently has a \u201cmarket perform\u201d rating on the stock. Keefe, Bruyette & Woods\u2019 price target would indicate a potential upside of 11.00% from the company\u2019s current price. Several other research firms have also issued reports on RSKD. UBS Group boosted their price target on shares of Riskified from $5.50 to $5.75 and gave the company a \u201cneutral\u201d rating in a research report on Thursday. Piper Sandler reiterated an \u201coverweight\u201d rating and set a $7.00 price target on shares of Riskified in a research report on Monday, March 17th. JPMorgan Chase & Co. cut their price objective on shares of Riskified from $7.00 to $6.00 and set a \u201cneutral\u201d rating for the company in a research report on Monday, March 10th. DA Davidson lowered their target price on shares of Riskified from $7.00 to $6.00 and set a \u201cbuy\u201d rating on the stock in a research note on Monday, April 14th. Finally, The Goldman Sachs Group increased their price objective on Riskified from $4.00 to $4.50 and gave the stock a \u201csell\u201d rating in a research report on Thursday, March 6th. One analyst has rated the stock with a sell rating, four have given a hold rating and three have given a buy rating to the company. Based on data from MarketBeat, Riskified has a consensus rating of \u201cHold\u201d and a consensus price target of $6.03. Get Riskified alerts: View Our Latest Report on Riskified Riskified Stock Down 1.3% Hedge Funds Weigh In On Riskified Riskified stock opened at $4.96 on Thursday. The company has a market capitalization of $798.79 million, a P/E ratio of -24.77 and a beta of 1.36. The firm has a 50 day moving average price of $4.60 and a 200-day moving average price of $4.82. Riskified has a twelve month low of $3.94 and a twelve month high of $6.65. A number of hedge funds and other institutional investors have recently made changes to their positions in the business. Clearline Capital LP lifted its holdings in Riskified by 37.3% in the first quarter. Clearline Capital LP now owns 2,453,506 shares of the company\u2019s stock worth $11,335,000 after buying an additional 666,175 shares during the period. Alta Fox Capital Management LLC bought a new position in shares of Riskified in the 1st quarter worth about $3,498,000. Cubist Systematic Strategies LLC lifted its holdings in shares of Riskified by 767.7% during the first quarter. Cubist Systematic Strategies LLC now owns 136,287 shares of the company\u2019s stock valued at $630,000 after purchasing an additional 120,581 shares during the last quarter. Trexquant Investment LP raised its stake in Riskified by 4.3% during the first quarter. Trexquant Investment LP now owns 336,666 shares of the company\u2019s stock valued at $1,555,000 after buying an additional 13,994 shares during the last quarter. Finally, Penn Capital Management Company LLC purchased a new position in shares of Riskified in the 1st quarter worth about $1,006,000. Institutional investors own 58.98% of the company\u2019s stock. Riskified Company Profile (Get Free Report) Riskified Ltd., together with its subsidiaries, develops and offers an e-commerce risk management platform that allows online merchants to create trusted relationships with consumers in the United States, Europe, the Middle East, Africa, the Asia-Pacific, and the Americas. It offers Chargeback Guarantee that ensures the legitimacy of merchants' online orders; Policy Protect, a machine learning solution designed to detect and prevent refund and returns policy abuse in real-time; Account Secure, a solution that cross-checks every login attempt; Dispute Resolve, which is used to compile submissions for fraud and non-fraud related chargeback issues; and PSD2 Optimize that helps merchants avoid bank authorization failures and abandoned shopping carts. Read More Receive News & Ratings for Riskified Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Riskified and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:49:04Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/keefe-bruyette-woods-issues-positive-forecast-for-riskified-nyserskd-stock-price/",
    "summary": "Riskified (NYSE:RSKD) had its price target raised by equities researchers at Keefe, Bruyette & Woods to $5.50. The firm presently has a \u201cmarket perform\u201d rating on the stock. Several other research firms have also issued reports on RSKD.",
    "category": "Business"
  },
  {
    "title": "Northland Capmk Increases Earnings Estimates for FiscalNote",
    "content": "FiscalNote Holdings, Inc. (NYSE:NOTE \u2013 Free Report) \u2013 Equities research analysts at Northland Capmk lifted their Q2 2025 EPS estimates for FiscalNote in a research note issued to investors on Tuesday, May 13th. Northland Capmk analyst M. Latimore now forecasts that the company will post earnings of ($0.07) per share for the quarter, up from their prior estimate of ($0.08). The consensus estimate for FiscalNote\u2019s current full-year earnings is ($0.43) per share. Northland Capmk also issued estimates for FiscalNote\u2019s Q3 2025 earnings at ($0.06) EPS, Q4 2025 earnings at ($0.05) EPS, FY2025 earnings at ($0.31) EPS, Q1 2026 earnings at ($0.05) EPS, Q2 2026 earnings at ($0.05) EPS, Q3 2026 earnings at ($0.05) EPS, Q4 2026 earnings at ($0.04) EPS and FY2026 earnings at ($0.19) EPS. Get FiscalNote alerts: FiscalNote (NYSE:NOTE \u2013 Get Free Report) last posted its quarterly earnings results on Monday, May 12th. The company reported ($0.12) earnings per share for the quarter, missing analysts\u2019 consensus estimates of ($0.10) by ($0.02). The business had revenue of $27.51 million for the quarter, compared to analyst estimates of $26.43 million. FiscalNote had a negative return on equity of 88.72% and a negative net margin of 22.27%. Other equities analysts also recently issued reports about the stock. D. Boral Capital reaffirmed a \u201cbuy\u201d rating and set a $3.75 target price on shares of FiscalNote in a research note on Tuesday. Roth Mkm reduced their target price on shares of FiscalNote from $3.00 to $2.00 and set a \u201cbuy\u201d rating on the stock in a research note on Friday, March 14th. B. Riley reduced their target price on shares of FiscalNote from $1.75 to $1.50 and set a \u201cbuy\u201d rating on the stock in a research note on Friday, March 14th. Finally, LADENBURG THALM/SH SH started coverage on shares of FiscalNote in a research note on Thursday, May 1st. They set a \u201cbuy\u201d rating and a $2.50 target price on the stock. One equities research analyst has rated the stock with a hold rating, five have given a buy rating and one has assigned a strong buy rating to the company\u2019s stock. According to MarketBeat, FiscalNote currently has an average rating of \u201cBuy\u201d and a consensus target price of $2.63. View Our Latest Report on NOTE FiscalNote Stock Performance NOTE opened at $0.70 on Thursday. The firm has a market capitalization of $112.51 million, a PE ratio of -3.17 and a beta of 0.62. FiscalNote has a twelve month low of $0.56 and a twelve month high of $2.07. The firm\u2019s 50-day moving average price is $0.75 and its 200 day moving average price is $1.01. The company has a current ratio of 0.81, a quick ratio of 0.81 and a debt-to-equity ratio of 1.44. Institutional Investors Weigh In On FiscalNote Institutional investors and hedge funds have recently made changes to their positions in the stock. Barclays PLC grew its holdings in shares of FiscalNote by 318.2% in the third quarter. Barclays PLC now owns 86,286 shares of the company\u2019s stock valued at $110,000 after purchasing an additional 65,655 shares in the last quarter. Arkadios Wealth Advisors acquired a new position in shares of FiscalNote in the fourth quarter valued at approximately $40,000. SG Americas Securities LLC grew its holdings in shares of FiscalNote by 83.2% in the fourth quarter. SG Americas Securities LLC now owns 25,285 shares of the company\u2019s stock valued at $27,000 after purchasing an additional 11,486 shares in the last quarter. PFG Investments LLC grew its holdings in shares of FiscalNote by 144.7% in the fourth quarter. PFG Investments LLC now owns 46,500 shares of the company\u2019s stock valued at $50,000 after purchasing an additional 27,500 shares in the last quarter. Finally, Fortis Group Advisors LLC acquired a new position in shares of FiscalNote in the fourth quarter valued at approximately $51,000. 54.31% of the stock is owned by hedge funds and other institutional investors. Insider Activity In other news, Director Tim Hwang sold 51,137 shares of the business\u2019s stock in a transaction that occurred on Monday, March 3rd. The shares were sold at an average price of $1.13, for a total value of $57,784.81. Following the sale, the director now directly owns 2,655,992 shares of the company\u2019s stock, valued at approximately $3,001,270.96. The trade was a 1.89% decrease in their position. The transaction was disclosed in a legal filing with the Securities & Exchange Commission, which is available at this hyperlink. In the last three months, insiders have sold 134,352 shares of company stock valued at $113,149. Company insiders own 40.16% of the company\u2019s stock. About FiscalNote (Get Free Report) FiscalNote Holdings, Inc operates as technology company North America, Europe, Australia, and Asia. It combines artificial intelligence technology, machine learning, and other technologies with analytics, workflow tools, and expert research. The company also delivers that intelligence through its suite of public policy and issues management products, as well as powerful tools to manage workflows, advocacy campaigns, and constituent relationships. Featured Stories Receive News & Ratings for FiscalNote Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for FiscalNote and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:41:11Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/northland-capmk-increases-earnings-estimates-for-fiscalnote/",
    "summary": "Northland Capmk lifted their Q2 2025 EPS estimates for FiscalNote in a research note issued to investors on Tuesday, May 13th. M. Latimore now forecasts that the company will post earnings of ($0.07) per share for the quarter, up from their prior estimate of $0.08. Northland Cap MK also issued estimates for fiscalNote\u2019s Q3 2025 earnings at ($0,06) EPS, Q4 2025 Earnings at $0,05, Q1 2026 Earns at ($ 0.05) and Q2 2026 earnings at $1.05.",
    "category": "Business"
  },
  {
    "title": "Analysts Set PagerDuty, Inc. (NYSE:PD) Price Target at $20.55",
    "content": "Shares of PagerDuty, Inc. (NYSE:PD \u2013 Get Free Report) have earned an average rating of \u201cHold\u201d from the eleven ratings firms that are presently covering the stock, MarketBeat reports. Two analysts have rated the stock with a sell rating, five have assigned a hold rating and four have assigned a buy rating to the company. The average 12 month target price among brokerages that have updated their coverage on the stock in the last year is $20.55. PD has been the subject of a number of research analyst reports. Royal Bank of Canada lowered their price objective on PagerDuty from $24.00 to $22.00 and set an \u201coutperform\u201d rating for the company in a research note on Friday, March 14th. Truist Financial lowered their price objective on PagerDuty from $30.00 to $26.00 and set a \u201cbuy\u201d rating for the company in a research note on Friday, March 14th. Morgan Stanley lowered their price objective on PagerDuty from $20.00 to $17.00 and set an \u201cequal weight\u201d rating for the company in a research note on Wednesday, April 16th. The Goldman Sachs Group lowered their price objective on PagerDuty from $21.00 to $18.00 and set a \u201cneutral\u201d rating for the company in a research note on Friday, March 14th. Finally, Bank of America downgraded PagerDuty from a \u201cbuy\u201d rating to an \u201cunderperform\u201d rating and lowered their price objective for the stock from $23.00 to $18.00 in a research note on Thursday, January 30th. Get PagerDuty alerts: Get Our Latest Stock Report on PagerDuty Institutional Trading of PagerDuty PagerDuty Price Performance Several institutional investors have recently modified their holdings of the company. MIRAE ASSET GLOBAL ETFS HOLDINGS Ltd. lifted its holdings in shares of PagerDuty by 1.2% in the fourth quarter. MIRAE ASSET GLOBAL ETFS HOLDINGS Ltd. now owns 50,930 shares of the company\u2019s stock valued at $930,000 after buying an additional 586 shares during the period. Alliancebernstein L. P. lifted its holdings in shares of PagerDuty by 0.7% in the fourth quarter. Alliancebernstein L. P. now owns 92,621 shares of the company\u2019s stock valued at $1,691,000 after buying an additional 674 shares during the period. Headlands Technologies LLC lifted its holdings in shares of PagerDuty by 2,235.6% during the first quarter. Headlands Technologies LLC now owns 1,378 shares of the company\u2019s stock valued at $25,000 after purchasing an additional 1,319 shares during the last quarter. Franklin Resources Inc. lifted its holdings in shares of PagerDuty by 5.4% during the third quarter. Franklin Resources Inc. now owns 32,915 shares of the company\u2019s stock valued at $614,000 after purchasing an additional 1,701 shares during the last quarter. Finally, Summit Securities Group LLC purchased a new stake in shares of PagerDuty during the first quarter valued at $33,000. Institutional investors and hedge funds own 97.26% of the company\u2019s stock. Shares of NYSE PD opened at $16.87 on Wednesday. PagerDuty has a twelve month low of $14.30 and a twelve month high of $23.12. The company has a current ratio of 1.97, a quick ratio of 1.97 and a debt-to-equity ratio of 3.52. The company has a market capitalization of $1.54 billion, a price-to-earnings ratio of -21.09 and a beta of 0.99. The business has a 50 day simple moving average of $16.51 and a 200-day simple moving average of $18.11. PagerDuty (NYSE:PD \u2013 Get Free Report) last issued its quarterly earnings results on Thursday, March 13th. The company reported $0.22 earnings per share for the quarter, beating analysts\u2019 consensus estimates of $0.16 by $0.06. PagerDuty had a negative return on equity of 22.02% and a negative net margin of 16.29%. The business had revenue of $121.45 million during the quarter, compared to the consensus estimate of $119.53 million. During the same period in the previous year, the business earned $0.17 EPS. The business\u2019s quarterly revenue was up 9.3% on a year-over-year basis. As a group, equities research analysts expect that PagerDuty will post -0.27 earnings per share for the current year. PagerDuty announced that its Board of Directors has authorized a stock buyback plan on Thursday, March 13th that permits the company to repurchase $150.00 million in shares. This repurchase authorization permits the company to reacquire up to 10.7% of its stock through open market purchases. Stock repurchase plans are usually an indication that the company\u2019s leadership believes its stock is undervalued. About PagerDuty (Get Free Report PagerDuty, Inc engages in the operation of a digital operations management platform in the United States and internationally. The company\u2019s digital operations management platform collects data and digital signals from virtually any software-enabled system or device and leverage machine learning to correlate, process, and predict opportunities and issues. Recommended Stories Receive News & Ratings for PagerDuty Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for PagerDuty and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T07:19:07Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/analysts-set-pagerduty-inc-nysepd-price-target-at-20-55/",
    "summary": "The average 12 month target price among brokerages that have updated their coverage on the stock in the last year is $20.55. Two analysts have rated the stock with a sell rating, five have assigned a hold rating and four have given a buy rating to the company.",
    "category": "Business"
  },
  {
    "title": "Simulations Plus, Inc. (NASDAQ:SLP) Shares Bought by Ameriprise Financial Inc.",
    "content": "Ameriprise Financial Inc. boosted its holdings in shares of Simulations Plus, Inc. (NASDAQ:SLP \u2013 Free Report) by 16.7% in the fourth quarter, HoldingsChannel. com reports. The fund owned 607,902 shares of the technology company\u2019s stock after buying an additional 86,868 shares during the quarter. Ameriprise Financial Inc.\u2019s holdings in Simulations Plus were worth $16,954,000 at the end of the most recent reporting period. A number of other hedge funds and other institutional investors also recently added to or reduced their stakes in the business. Jones Financial Companies Lllp raised its position in Simulations Plus by 53.6% during the fourth quarter. Jones Financial Companies Lllp now owns 1,223 shares of the technology company\u2019s stock worth $34,000 after acquiring an additional 427 shares during the last quarter. Pitcairn Co. raised its position in Simulations Plus by 10.8% during the fourth quarter. Pitcairn Co. now owns 7,310 shares of the technology company\u2019s stock worth $204,000 after acquiring an additional 711 shares during the last quarter. US Bancorp DE raised its position in Simulations Plus by 14.3% during the fourth quarter. US Bancorp DE now owns 5,687 shares of the technology company\u2019s stock worth $159,000 after acquiring an additional 713 shares during the last quarter. Barclays PLC raised its position in Simulations Plus by 2.7% during the fourth quarter. Barclays PLC now owns 29,229 shares of the technology company\u2019s stock worth $815,000 after acquiring an additional 756 shares during the last quarter. Finally, Tower Research Capital LLC TRC raised its position in Simulations Plus by 42.2% during the fourth quarter. Tower Research Capital LLC TRC now owns 2,575 shares of the technology company\u2019s stock worth $72,000 after acquiring an additional 764 shares during the last quarter. Institutional investors and hedge funds own 78.08% of the company\u2019s stock. Get Simulations Plus alerts: Insider Activity at Simulations Plus In related news, Director Walter S. Woltosz sold 20,000 shares of the business\u2019s stock in a transaction that occurred on Thursday, May 1st. The shares were sold at an average price of $33.51, for a total value of $670,200.00. Following the completion of the sale, the director now directly owns 3,344,157 shares in the company, valued at approximately $112,062,701.07. The trade was a 0.59% decrease in their ownership of the stock. The transaction was disclosed in a document filed with the Securities & Exchange Commission, which can be accessed through the SEC website. 19.40% of the stock is owned by insiders. Analysts Set New Price Targets A number of research firms have recently weighed in on SLP. StockNews. com raised shares of Simulations Plus from a \u201csell\u201d rating to a \u201chold\u201d rating in a research report on Monday, April 28th. KeyCorp boosted their price objective on shares of Simulations Plus from $32.00 to $40.00 and gave the company an \u201coverweight\u201d rating in a research report on Wednesday, April 16th. Two equities research analysts have rated the stock with a hold rating, five have assigned a buy rating and one has assigned a strong buy rating to the company\u2019s stock. According to data from MarketBeat. com, the stock has an average rating of \u201cModerate Buy\u201d and a consensus price target of $50.00. View Our Latest Stock Report on Simulations Plus Simulations Plus Stock Performance Simulations Plus stock opened at $31.53 on Friday. Simulations Plus, Inc. has a 1 year low of $23.01 and a 1 year high of $50.98. The firm has a 50 day moving average price of $29.06 and a 200 day moving average price of $30.25. The company has a market cap of $634.10 million, a price-to-earnings ratio of 78.83 and a beta of 1.10. Simulations Plus (NASDAQ:SLP \u2013 Get Free Report) last released its earnings results on Thursday, April 3rd. The technology company reported $0.31 earnings per share (EPS) for the quarter, beating analysts\u2019 consensus estimates of $0.25 by $0.06. Simulations Plus had a net margin of 10.97% and a return on equity of 6.84%. The firm had revenue of $22.43 million during the quarter, compared to the consensus estimate of $21.93 million. During the same period in the previous year, the firm earned $0.20 earnings per share. Simulations Plus\u2019s revenue was up 22.5% compared to the same quarter last year. Sell-side analysts predict that Simulations Plus, Inc. will post 1.09 EPS for the current year. Simulations Plus Company Profile (Free Report) Simulations Plus, Inc develops drug discovery and development software for modeling and simulation, and prediction of molecular properties utilizing artificial intelligence and machine learning based technology worldwide. The company operates through two segments, Software and Services. It offers GastroPlus, which simulates the absorption and drug interaction of compounds administered to humans and animals; and DDDPlus and MembranePlus simulation products. Featured Articles Want to see what other hedge funds are holding SLP? Visit HoldingsChannel. com to get the latest 13F filings and insider trades for Simulations Plus, Inc. (NASDAQ:SLP \u2013 Free Report). Receive News & Ratings for Simulations Plus Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Simulations Plus and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T09:26:54Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/simulations-plus-inc-nasdaqslp-shares-bought-by-ameriprise-financial-inc/",
    "summary": "Ameriprise Financial Inc. boosted its holdings in shares of Simulations Plus, Inc. (NASDAQ:SLP \u2013 Free Report) by 16.7% in the fourth quarter. The fund owned 607,902 shares of the technology company\u2019s stock after buying an additional 86,868 shares during the quarter. Pitcairn Co. raised its position in Simulation Plus by 10.8% during the fourth month. Jones Financial Companies Lllp now owns 1,223 shares ofthe technology company's stock worth $34,000 after acquiring an additional 427 shares during last quarter.",
    "category": "Technology"
  },
  {
    "title": "Ameriprise Financial Inc. Has $17.32 Million Position in ExlService Holdings, Inc. (NASDAQ:EXLS)",
    "content": "Ameriprise Financial Inc. raised its position in shares of ExlService Holdings, Inc. (NASDAQ:EXLS \u2013 Free Report) by 17.4% during the 4th quarter, according to the company in its most recent 13F filing with the Securities & Exchange Commission. The firm owned 390,158 shares of the business services provider\u2019s stock after purchasing an additional 57,706 shares during the quarter. Ameriprise Financial Inc. owned 0.24% of ExlService worth $17,315,000 at the end of the most recent quarter. Other large investors also recently added to or reduced their stakes in the company. Mather Group LLC. bought a new stake in ExlService in the fourth quarter worth $25,000. Kestra Investment Management LLC bought a new stake in ExlService in the fourth quarter worth $26,000. VisionPoint Advisory Group LLC bought a new stake in ExlService in the fourth quarter worth $58,000. USA Financial Formulas bought a new stake in ExlService in the fourth quarter worth $58,000. Finally, Johnson Financial Group Inc. bought a new stake in ExlService in the fourth quarter worth $85,000. 92.92% of the stock is owned by institutional investors and hedge funds. Get ExlService alerts: Wall Street Analysts Forecast Growth EXLS has been the subject of a number of recent research reports. StockNews. com upgraded shares of ExlService from a \u201chold\u201d rating to a \u201cbuy\u201d rating in a report on Friday, May 9th. Needham & Company LLC boosted their target price on shares of ExlService from $50.00 to $60.00 and gave the stock a \u201cbuy\u201d rating in a research report on Thursday, February 27th. JPMorgan Chase & Co. boosted their target price on shares of ExlService from $52.00 to $53.00 and gave the stock an \u201coverweight\u201d rating in a research report on Thursday, May 1st. Jefferies Financial Group boosted their target price on shares of ExlService from $47.00 to $57.00 and gave the stock a \u201cbuy\u201d rating in a research report on Tuesday, January 21st. Finally, Stifel Nicolaus boosted their target price on shares of ExlService from $48.00 to $54.00 and gave the stock a \u201cbuy\u201d rating in a research report on Thursday, February 27th. One equities research analyst has rated the stock with a hold rating and six have assigned a buy rating to the company. According to MarketBeat. com, the stock currently has an average rating of \u201cModerate Buy\u201d and an average target price of $52.33. ExlService Stock Down 0.3% ExlService stock opened at $46.07 on Friday. The firm has a market cap of $7.50 billion, a price-to-earnings ratio of 40.41, a P/E/G ratio of 2.11 and a beta of 0.86. The company has a debt-to-equity ratio of 0.37, a current ratio of 3.02 and a quick ratio of 3.02. ExlService Holdings, Inc. has a fifty-two week low of $28.59 and a fifty-two week high of $52.43. The firm has a fifty day moving average price of $45.65 and a two-hundred day moving average price of $46.48. ExlService (NASDAQ:EXLS \u2013 Get Free Report) last announced its quarterly earnings data on Tuesday, April 29th. The business services provider reported $0.48 EPS for the quarter, beating analysts\u2019 consensus estimates of $0.45 by $0.03. The business had revenue of $501.02 million during the quarter, compared to analyst estimates of $489.66 million. ExlService had a net margin of 10.61% and a return on equity of 23.23%. The firm\u2019s revenue for the quarter was up 14.8% on a year-over-year basis. During the same quarter in the prior year, the business earned $0.38 earnings per share. As a group, analysts forecast that ExlService Holdings, Inc. will post 1.27 earnings per share for the current year. Insider Activity In other news, Director Jaynie M. Studenmund sold 14,580 shares of the company\u2019s stock in a transaction dated Friday, May 2nd. The shares were sold at an average price of $47.53, for a total transaction of $692,987.40. The sale was disclosed in a document filed with the Securities & Exchange Commission, which is accessible through this link. Also, insider Vikas Bhalla sold 25,000 shares of the company\u2019s stock in a transaction dated Thursday, May 8th. The shares were sold at an average price of $46.11, for a total transaction of $1,152,750.00. Following the transaction, the insider now directly owns 135,046 shares of the company\u2019s stock, valued at $6,226,971.06. This represents a 15.62% decrease in their position. The disclosure for this sale can be found here. Over the last 90 days, insiders sold 56,992 shares of company stock valued at $2,673,620. Insiders own 4.16% of the company\u2019s stock. ExlService Company Profile (Free Report) ExlService Holdings, Inc operates as a data analytics, and digital operations and solutions company in the United States and internationally. The company operates through Insurance, Healthcare, Analytics, and Emerging Business segments. It also provides digital operations and solutions and analytics-driven services, such as claims processing, premium and benefit administration, agency management, account reconciliation, policy research, underwriting support, new business acquisition, policy servicing, premium audit, surveys, billing and collection, commercial and residential survey, and customer service using digital technology, artificial intelligence, machine learning, and advanced automation; digital customer acquisition services using a software-as-a-service delivery model through LifePRO and LISS platforms; subrogation services; and Subrosource software platform, an end-to-end subrogation platform. See Also Receive News & Ratings for ExlService Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for ExlService and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T08:12:58Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/ameriprise-financial-inc-has-17-32-million-position-in-exlservice-holdings-inc-nasdaqexls/",
    "summary": "Ameriprise Financial Inc. raised its position in shares of ExlService Holdings, Inc. (NASDAQ:EXLS \u2013 Free Report) by 17.4% during the 4th quarter. The firm owned 390,158 shares of the business services provider\u2019s stock after purchasing an additional 57,706 shares during the quarter. Other large investors also recently added to or reduced their stakes in the company.",
    "category": "Business"
  },
  {
    "title": "Ameriprise Financial Inc. Trims Stock Holdings in Extreme Networks, Inc. (NASDAQ:EXTR)",
    "content": "Ameriprise Financial Inc. lowered its stake in shares of Extreme Networks, Inc. (NASDAQ:EXTR \u2013 Free Report) by 3.2% during the fourth quarter, according to the company in its most recent disclosure with the Securities & Exchange Commission. The fund owned 1,048,715 shares of the technology company\u2019s stock after selling 35,168 shares during the period. Ameriprise Financial Inc. owned 0.79% of Extreme Networks worth $17,556,000 as of its most recent SEC filing. A number of other hedge funds and other institutional investors have also recently added to or reduced their stakes in EXTR. Envestnet Asset Management Inc. boosted its stake in shares of Extreme Networks by 27.2% during the 4th quarter. Envestnet Asset Management Inc. now owns 21,543 shares of the technology company\u2019s stock worth $361,000 after purchasing an additional 4,610 shares during the last quarter. Barclays PLC boosted its position in Extreme Networks by 369.8% during the third quarter. Barclays PLC now owns 217,875 shares of the technology company\u2019s stock worth $3,274,000 after acquiring an additional 171,500 shares during the last quarter. Essex Investment Management Co. LLC purchased a new stake in Extreme Networks in the 4th quarter worth approximately $2,599,000. Geode Capital Management LLC raised its holdings in Extreme Networks by 1.7% in the 4th quarter. Geode Capital Management LLC now owns 3,068,854 shares of the technology company\u2019s stock valued at $51,385,000 after acquiring an additional 49,888 shares during the last quarter. Finally, Vanguard Group Inc. raised its holdings in Extreme Networks by 4.0% in the 4th quarter. Vanguard Group Inc. now owns 17,919,069 shares of the technology company\u2019s stock valued at $299,965,000 after acquiring an additional 690,262 shares during the last quarter. Hedge funds and other institutional investors own 91.05% of the company\u2019s stock. Get Extreme Networks alerts: Insider Activity In related news, CEO Edward Meyercord sold 35,725 shares of the company\u2019s stock in a transaction on Thursday, May 1st. The shares were sold at an average price of $13.73, for a total transaction of $490,504.25. Following the completion of the sale, the chief executive officer now directly owns 1,510,719 shares of the company\u2019s stock, valued at approximately $20,742,171.87. This represents a 2.31% decrease in their position. The sale was disclosed in a document filed with the Securities & Exchange Commission, which is accessible through the SEC website. Insiders own 3.70% of the company\u2019s stock. Extreme Networks Stock Performance Extreme Networks stock opened at $16.22 on Friday. The company has a market cap of $2.16 billion, a price-to-earnings ratio of -17.26, a price-to-earnings-growth ratio of 3.06 and a beta of 1.67. Extreme Networks, Inc. has a 12 month low of $10.10 and a 12 month high of $19.24. The company has a debt-to-equity ratio of 3.34, a current ratio of 0.93 and a quick ratio of 0.68. The stock\u2019s 50-day moving average is $13.43 and its 200-day moving average is $15.39. Extreme Networks (NASDAQ:EXTR \u2013 Get Free Report) last posted its earnings results on Wednesday, April 30th. The technology company reported $0.21 earnings per share (EPS) for the quarter, topping analysts\u2019 consensus estimates of $0.19 by $0.02. The firm had revenue of $284.51 million during the quarter, compared to the consensus estimate of $280.32 million. Extreme Networks had a negative net margin of 11.98% and a negative return on equity of 110.86%. The company\u2019s revenue was up 34.8% on a year-over-year basis. During the same quarter in the prior year, the company earned ($0.19) EPS. Equities analysts anticipate that Extreme Networks, Inc. will post 0.31 earnings per share for the current year. Extreme Networks declared that its Board of Directors has approved a share buyback program on Tuesday, February 18th that authorizes the company to buyback $200.00 million in outstanding shares. This buyback authorization authorizes the technology company to buy up to 9.2% of its stock through open market purchases. Stock buyback programs are typically an indication that the company\u2019s board of directors believes its stock is undervalued. Wall Street Analyst Weigh In A number of brokerages have recently commented on EXTR. Needham & Company LLC reaffirmed a \u201cbuy\u201d rating and issued a $20.00 price objective on shares of Extreme Networks in a research report on Thursday. StockNews. com upgraded Extreme Networks from a \u201cbuy\u201d rating to a \u201cstrong-buy\u201d rating in a report on Tuesday. Lake Street Capital dropped their price objective on shares of Extreme Networks from $16.00 to $15.00 and set a \u201chold\u201d rating for the company in a research note on Thursday, May 1st. UBS Group decreased their target price on shares of Extreme Networks from $16.50 to $15.00 and set a \u201cneutral\u201d rating on the stock in a research report on Thursday, May 1st. Finally, Rosenblatt Securities restated a \u201cbuy\u201d rating and issued a $18.00 target price on shares of Extreme Networks in a report on Thursday, May 1st. Two investment analysts have rated the stock with a hold rating, four have assigned a buy rating and one has issued a strong buy rating to the stock. According to data from MarketBeat. com, the company has a consensus rating of \u201cModerate Buy\u201d and a consensus price target of $18.58. Check Out Our Latest Analysis on EXTR About Extreme Networks (Free Report) Extreme Networks, Inc delivers cloud-driven networking solutions that leverage the powers of machine learning, artificial intelligence, analytics, and automation. The company designs, develops, and manufactures wired and wireless network infrastructure equipment and develops the software for network management, policy, analytics, security, and access controls. Further Reading Want to see what other hedge funds are holding EXTR? Visit HoldingsChannel. com to get the latest 13F filings and insider trades for Extreme Networks, Inc. (NASDAQ:EXTR \u2013 Free Report). Receive News & Ratings for Extreme Networks Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Extreme Networks and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T08:16:57Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/ameriprise-financial-inc-trims-stock-holdings-in-extreme-networks-inc-nasdaqextr/",
    "summary": "Ameriprise Financial Inc. lowered its stake in shares of Extreme Networks, Inc. (NASDAQ:EXTR) by 3.2% during the fourth quarter. The fund owned 1,048,715 shares of the technology company\u2019s stock after selling 35,168 shares during the period. Envestnet Asset Management Inc. raised its position in Extreme Networks by 369.8% in the third quarter.",
    "category": "Technology"
  },
  {
    "title": "Noble Financial Comments on DLH\u2019s Q3 Earnings (NASDAQ:DLHC)",
    "content": "DLH Holdings Corp. (NASDAQ:DLHC \u2013 Free Report) \u2013 Research analysts at Noble Financial lowered their Q3 2025 earnings per share (EPS) estimates for DLH in a research note issued to investors on Wednesday, May 14th. Noble Financial analyst J. Gomes now expects that the business services provider will earn $0.02 per share for the quarter, down from their prior forecast of $0.04. The consensus estimate for DLH\u2019s current full-year earnings is ($0.13) per share. Noble Financial also issued estimates for DLH\u2019s Q4 2025 earnings at $0.02 EPS and FY2025 earnings at $0.19 EPS. Get DLH alerts: Separately, StockNews. com lowered DLH from a \u201cbuy\u201d rating to a \u201chold\u201d rating in a research note on Saturday. DLH Stock Performance NASDAQ DLHC opened at $5.01 on Friday. The firm has a market cap of $72.07 million, a price-to-earnings ratio of 11.39 and a beta of 1.33. The company has a quick ratio of 1.04, a current ratio of 1.04 and a debt-to-equity ratio of 1.21. The business has a 50-day moving average price of $3.98 and a 200-day moving average price of $6.22. DLH has a twelve month low of $2.72 and a twelve month high of $12.23. DLH (NASDAQ:DLHC \u2013 Get Free Report) last released its quarterly earnings data on Wednesday, May 7th. The business services provider reported $0.06 earnings per share for the quarter, missing analysts\u2019 consensus estimates of $0.07 by ($0.01). The business had revenue of $89.21 million during the quarter, compared to the consensus estimate of $90.00 million. DLH had a return on equity of 5.82% and a net margin of 1.64%. Insider Activity at DLH In other news, major shareholder Mink Brook Asset Management Ll purchased 12,054 shares of the company\u2019s stock in a transaction that occurred on Monday, April 28th. The stock was bought at an average cost of $3.55 per share, with a total value of $42,791.70. Following the completion of the purchase, the insider now owns 1,325,389 shares in the company, valued at approximately $4,705,130.95. This represents a 0.92% increase in their ownership of the stock. The purchase was disclosed in a legal filing with the SEC, which is available through this hyperlink. Over the last three months, insiders bought 68,263 shares of company stock valued at $273,410. Insiders own 15.30% of the company\u2019s stock. Institutional Investors Weigh In On DLH Several institutional investors have recently modified their holdings of DLHC. Bard Associates Inc. bought a new stake in shares of DLH in the 1st quarter valued at approximately $43,000. Nuveen LLC bought a new stake in shares of DLH in the 1st quarter valued at approximately $44,000. Bank of America Corp DE lifted its stake in shares of DLH by 31.9% in the 4th quarter. Bank of America Corp DE now owns 7,679 shares of the business services provider\u2019s stock valued at $62,000 after purchasing an additional 1,855 shares during the last quarter. Corton Capital Inc. bought a new stake in shares of DLH in the 1st quarter valued at approximately $71,000. Finally, Barclays PLC lifted its stake in shares of DLH by 299.3% in the 3rd quarter. Barclays PLC now owns 11,716 shares of the business services provider\u2019s stock valued at $109,000 after purchasing an additional 8,782 shares during the last quarter. 67.25% of the stock is owned by institutional investors. DLH Company Profile (Get Free Report) DLH Holdings Corp. provides technology-enabled business process outsourcing, program management solutions, and public health research and analytics services in the United States. It offers digital transformation and cyber security solutions, including artificial intelligence and machine learning, cloud enablement, cybersecurity ecosystem, big data analytics, and modeling and simulation to the National Institutes of Health (NIH), the Defense Health Agency, Tele-medicine and Advanced Technology Research Center, and US Navy Naval Information Warfare Center (NIWC). Featured Articles Receive News & Ratings for DLH Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for DLH and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T08:10:50Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/noble-financial-comments-on-dlhs-q3-earnings-nasdaqdlhc/",
    "summary": "Noble Financial lowered their Q3 2025 earnings per share (EPS) estimates for DLH in a research note issued to investors on Wednesday, May 14th. Noble Financial now expects that the business services provider will earn $0.02 per share for the quarter. Separately, StockNews. com lowered DLH from a \u2018buy\u2019 rating to a \u201chold\u201d rating in a report on Saturday.",
    "category": "Business"
  },
  {
    "title": "Life360 (NASDAQ:LIF) versus Workday (NASDAQ:WDAY) Head-To-Head Comparison",
    "content": "Life360 (NASDAQ:LIF \u2013 Get Free Report) and Workday (NASDAQ:WDAY \u2013 Get Free Report) are both industrials companies, but which is the better business? We will contrast the two companies based on the strength of their earnings, profitability, analyst recommendations, institutional ownership, dividends, valuation and risk. Earnings & Valuation This table compares Life360 and Workday\u201ds revenue, earnings per share and valuation. Get Life360 alerts: Gross Revenue Price/Sales Ratio Net Income Earnings Per Share Price/Earnings Ratio Life360 $396.88 million 11.62 -$28.17 million $0.09 669.56 Workday $8.45 billion 8.60 $1.38 billion $1.96 139.31 Analyst Ratings Workday has higher revenue and earnings than Life360. Workday is trading at a lower price-to-earnings ratio than Life360, indicating that it is currently the more affordable of the two stocks. This is a summary of current ratings and recommmendations for Life360 and Workday, as provided by MarketBeat. Sell Ratings Hold Ratings Buy Ratings Strong Buy Ratings Rating Score Life360 0 0 7 1 3.13 Workday 0 9 21 2 2.78 Life360 currently has a consensus price target of $49.50, indicating a potential downside of 17.86%. Workday has a consensus price target of $293.62, indicating a potential upside of 7.53%. Given Workday\u2019s higher possible upside, analysts clearly believe Workday is more favorable than Life360. Institutional and Insider Ownership 20.0% of Life360 shares are held by institutional investors. Comparatively, 89.8% of Workday shares are held by institutional investors. 8.0% of Life360 shares are held by company insiders. Comparatively, 19.3% of Workday shares are held by company insiders. Strong institutional ownership is an indication that hedge funds, endowments and large money managers believe a stock will outperform the market over the long term. Profitability This table compares Life360 and Workday\u2019s net margins, return on equity and return on assets. Net Margins Return on Equity Return on Assets Life360 -4.72% -4.03% -3.16% Workday 19.86% 6.13% 3.13% Summary Workday beats Life360 on 11 of the 14 factors compared between the two stocks. About Life360 (Get Free Report) Life360 Inc. is a family connection and safety company. Its business category includes mobile app and Tile tracking devices with a range of services, including location sharing, safe driver reports and crash detection with emergency dispatch. Life360 Inc. is based in SAN FRANCISCO. About Workday (Get Free Report) Workday, Inc. provides enterprise cloud applications in the United States and internationally. Its applications help its customers to plan, execute, analyze, and extend to other applications and environments to manage their business and operations. The company offers a suite of financial management applications to maintain accounting information in the general ledger; manage financial processes, such as payables and receivables; identify real-time financial, operational, and management insights; enhance financial consolidation; reduce time-to-close; promote internal control and auditability; and achieve consistency across finance operations. It also provides spend management solutions that help organizations to streamline supplier selection and contracts, manage indirect spend, and build and execute sourcing events, such as requests for proposals; expense management solutions to submit and approve expenses; and a suite of human capital management applications that enables HR teams to hire, onboard, pay, develop, reskill, and provide employee experiences. In addition, the company offers planning applications; and applications for analytics and reporting comprising augmented analytics to surface insights to the line of business in simple-to-understand stories, machine learning to drive efficiency and automation, and benchmarks to compare performance against other companies. Further, it provides supply chain and inventory solutions to healthcare organizations; solutions to manage the end-to-end student and faculty lifecycle; and Workday Extend for customers and their developers to build custom applications. It serves professional and business services, financial services, healthcare, education, government, technology, media, retail, and hospitality industries. The company was formerly known as North Tahoe Power Tools, Inc. and changed its name to Workday, Inc. in July 2005. Workday, Inc. was incorporated in 2005 and is headquartered in Pleasanton, California. Receive News & Ratings for Life360 Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for Life360 and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T05:25:06Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/life360-nasdaqlif-versus-workday-nasdaqwday-head-to-head-comparison/",
    "summary": "Life360 and Workday are both industrials companies, but which is the better business? We will contrast the two companies based on the strength of their earnings, profitability, analyst recommendations, institutional ownership, dividends, valuation and risk.",
    "category": "Business"
  },
  {
    "title": "Comparing PodcastOne (NASDAQ:PODC) & KLDiscovery (OTCMKTS:KLDI)",
    "content": "PodcastOne (NASDAQ:PODC \u2013 Get Free Report) and KLDiscovery (OTCMKTS:KLDI \u2013 Get Free Report) are both small-cap computer and technology companies, but which is the better stock? We will compare the two businesses based on the strength of their institutional ownership, risk, valuation, earnings, analyst recommendations, profitability and dividends. Earnings & Valuation This table compares PodcastOne and KLDiscovery\u201ds gross revenue, earnings per share and valuation. Get PodcastOne alerts: Gross Revenue Price/Sales Ratio Net Income Earnings Per Share Price/Earnings Ratio PodcastOne $49.73 million 1.01 -$14.73 million ($0.24) -8.42 KLDiscovery $345.80 million 0.00 -$34.81 million ($1.56) -0.01 Profitability PodcastOne has higher earnings, but lower revenue than KLDiscovery. PodcastOne is trading at a lower price-to-earnings ratio than KLDiscovery, indicating that it is currently the more affordable of the two stocks. This table compares PodcastOne and KLDiscovery\u2019s net margins, return on equity and return on assets. Net Margins Return on Equity Return on Assets PodcastOne -11.40% -36.83% -25.09% KLDiscovery -20.91% N/A -9.45% Institutional & Insider Ownership 2.9% of PodcastOne shares are owned by institutional investors. Comparatively, 20.4% of KLDiscovery shares are owned by institutional investors. 7.8% of PodcastOne shares are owned by company insiders. Comparatively, 31.6% of KLDiscovery shares are owned by company insiders. Strong institutional ownership is an indication that hedge funds, large money managers and endowments believe a company will outperform the market over the long term. Risk and Volatility PodcastOne has a beta of -0.2, suggesting that its share price is 120% less volatile than the S&P 500. Comparatively, KLDiscovery has a beta of -0.64, suggesting that its share price is 164% less volatile than the S&P 500. Analyst Ratings This is a summary of current ratings and target prices for PodcastOne and KLDiscovery, as reported by MarketBeat. Sell Ratings Hold Ratings Buy Ratings Strong Buy Ratings Rating Score PodcastOne 0 0 1 0 3.00 KLDiscovery 0 0 0 0 0.00 PodcastOne currently has a consensus price target of $5.00, indicating a potential upside of 147.52%. Given PodcastOne\u2019s stronger consensus rating and higher probable upside, equities analysts clearly believe PodcastOne is more favorable than KLDiscovery. Summary PodcastOne beats KLDiscovery on 8 of the 14 factors compared between the two stocks. About PodcastOne (Get Free Report) PodcastOne, Inc. operates as a podcast platform and publisher. The company offers its content to audiences through podcasting distribution platforms, including its website, Apple Podcasts, Spotify, Amazon Music, and others. It also produces vodcasts, branded podcasts, merchandise, and live events. In addition, the company builds, owns, and operates LaunchPadOne, a self-publishing podcast platform. The company was formerly known as Courtside Group, Inc. and changed its name to PodcastOne, Inc. in September 2023. PodcastOne, Inc. was founded in 2013 and is based in Beverly Hills, California. PodcastOne, Inc. is a subsidiary of LiveOne, Inc. About KLDiscovery (Get Free Report) KLDiscovery Inc. provides eDiscovery, information governance, and data recovery solutions to corporations, law firms, insurance companies, and individuals worldwide. The company offers Nebula, an end-to-end eDiscovery solution that facilitates smarter ways to cull, process, review, and manage documents in an intuitive interface; Client Portal for consolidated visualizations and reporting for portfolio intelligence; KLD Processing, a proprietary processing application; ReadySuite to perform extensive QC on a production, normalize inbound submissions, or spot check the work of a colleague or supplier; Relativity for relativity enhancements and state-of-the-art HIVE infrastructure; Nebula Processing to process data with a higher degree of quality; and Nebula AI, a technology assisted review tool combined with a deep bench of experts, as well as managed services, remote document review, and managed document review services. It also provides computer forensics, ransomware data recovery, remote collection manager, data recovery, and data collection services. In addition, the company offers Nebula Archive, an advanced archiving solution for modern enterprise data management needs at scale; Nebula Intelligent Archive, a digital communications compliance platform with machine learning and analytics; and Office 365 Migration and Management, as well as information governance and advisory services. Further, it provides Ontrack EasyRecovery that allows clients to perform precise file recovery of data lost through deletion, reformatting, and various other data loss scenarios; Ontrack PowerControls, a granular restore software product; email extraction, tape solutions, and data destruction solutions; and professional services. KLDiscovery Inc. was founded in 1985 and is headquartered in Eden Prairie, Minnesota. Receive News & Ratings for PodcastOne Daily - Enter your email address below to receive a concise daily summary of the latest news and analysts' ratings for PodcastOne and related companies with MarketBeat. com's FREE daily email newsletter.",
    "published_at": "2025-05-17T06:12:49Z",
    "source": "ETF Daily News",
    "url": "https://www.etfdailynews.com/2025/05/17/comparing-podcastone-nasdaqpodc-kldiscovery-otcmktskldi/",
    "summary": " PodcastOne and KLDiscovery are both small-cap computer and technology companies. PodcastOne is trading at a lower price-to-earnings ratio than KLD discovery. KLD Discovery is trading on a lower share price than PodcastOne.",
    "category": "Technology"
  },
  {
    "title": "Why we're unlikely to get artificial general intelligence anytime soon",
    "content": "Live Events Sam Altman , the CEO of OpenAI, recently told President Donald Trump during a private phone call that it would arrive before the end of his administration. Dario Amodei, the CEO of Anthropic, OpenAI 's primary rival, repeatedly told podcasters it could happen even sooner. Tech billionaire Elon Musk has said it could be here before the end of the year. Like many other voices across Silicon Valley and beyond, these executives predict that the arrival of artificial general intelligence, or AGI , is imminent. Since the early 2000s, when a group of fringe researchers slapped the term on the cover of a book that described the autonomous computer systems they hoped to build one day, AGI has served as shorthand for a future technology that achieves human-level intelligence. There is no settled definition of AGI, just an entrancing idea: an artificial intelligence that can match the many powers of the human mind. Altman, Amodei and Musk have long chased this goal, as have executives and researchers at companies like Google and Microsoft . And thanks, in part, to their fervent pursuit of this ambitious idea, they have produced technologies that are changing the way hundreds of millions of people research, make art and program computers. These technologies are now poised to transform entire professions. But since the arrival of chatbots like OpenAI's ChatGPT and the rapid improvement of these strange and powerful systems over the last two years, many technologists have grown increasingly bold in predicting how soon AGI will arrive. Some are even saying that once they deliver AGI, a more powerful creation called \"superintelligence\" will follow. As these eternally confident voices predict the near future, their speculations are getting ahead of reality. And though their companies are pushing the technology forward at a remarkable rate, an army of more sober voices are quick to dispel any claim that machines will soon match human intellect.\"The technology we're building today is not sufficient to get there,\" said Nick Frosst, a founder of the AI startup Cohere who previously worked as a researcher at Google and studied under the most revered AI researcher of the last 50 years. \"What we are building now are things that take in words and predict the next most likely word, or they take in pixels and predict the next most likely pixel. That's very different from what you and I do.\"In a recent survey of the Association for the Advancement of Artificial Intelligence, a 40-year-old academic society that includes some of the most respected researchers in the field, more than three-quarters of respondents said the methods used to build today's technology were unlikely to lead to AGI. Opinions differ in part because scientists cannot even agree on a way of defining human intelligence, arguing endlessly over the merits and flaws of IQ tests and other benchmarks. Comparing our own brains to machines is even more subjective. This means that identifying AGI is essentially a matter of opinion. (Last year, as part of a high-profile lawsuit, Musk's attorneys said it was already here because OpenAI, one of Musk's chief rivals, has signed a contract with its main funder saying it will not sell products based on AGI technology.)And scientists have no hard evidence that today's technologies are capable of performing even some of the simpler things the brain can do, like recognizing irony or feeling empathy. Claims of AGI's imminent arrival are based on statistical extrapolations -- and wishful thinking. According to various benchmark tests, today's technologies are improving at a consistent rate in some notable areas, like math and computer programming. But these tests describe only a small part of what people can do. Humans know how to deal with a chaotic and constantly changing world. Machines struggle to master the unexpected -- the challenges, small and large, that do not look like what has happened in the past. Humans can dream up ideas that the world has never seen. Machines typically repeat or enhance what they have seen before. That is why Frosst and other sceptics say pushing machines to human-level intelligence will require at least one big idea that the world's technologists have not yet dreamed up. There is no way of knowing how long that will take.\"A system that's better than humans in one way will not necessarily be better in other ways,\" Harvard University cognitive scientist Steven Pinker said. \"There's just no such thing as an automatic, omniscient, omnipotent solver of every problem, including ones we haven't even thought of yet. There's a temptation to engage in a kind of magical thinking. But these systems are not miracles. They are very impressive gadgets.\"Chatbots like ChatGPT are driven by what scientists call neural networks, mathematical systems that can identify patterns in text, images and sounds. By pinpointing patterns in vast troves of Wikipedia articles, news stories and chat logs, for instance, these systems can learn to generate humanlike text on their own, like poems and computer programs. That means these systems are progressing much faster than computer technologies of the past. In previous decades, software engineers built applications one line of code at time, a tiny-step-by-tiny-step process that could never produce something as powerful as ChatGPT. Because neural networks can learn from data, they can reach new heights and reach them quickly. After seeing the improvement of these systems over the last decade, some technologists believe the progress will continue at much the same rate -- to AGI and beyond.\"There are all these trends where all of the limitations are going away,\" said Jared Kaplan, the chief science officer at Anthropic. \"AI intelligence is quite different from human intelligence. Humans learn much more easily to do new tasks. They don't need to practice as much as AI needs to. But eventually, with more practice, AI can get there.\"Among AI researchers, Kaplan is known for publishing a ground breaking academic paper that described what are now called \"the Scaling Laws.\" These laws essentially said the more data an AI system analysed, the better it would perform. Just as a student learns more by reading more books, an AI system finds more patterns in the text and learns to more accurately mimic the way people put words together. In recent months, companies like OpenAI and Anthropic used up just about all of the English text on the internet, which meant they needed a new way of improving their chatbots. So they are leaning more heavily on a technique that scientists call reinforcement learning. Through this process, which can extend over weeks or months, a system can learn behaviour through trial and error. By working through thousands of math problems, for instance, it can learn which techniques tend to lead to the right answer and which do not. Thanks to this technique, researchers like Kaplan believe that the Scaling Laws (or something like them) will continue. As the technology continues to learn through trial and error across myriad fields, researchers say, it will follow the path of AlphaGo, a machine built in 2016 by a team of Google researchers. Through reinforcement learning, AlphaGo learned to master the game of Go, a complex Chinese board game that is compared to chess, by playing millions of games against itself. That spring, it beat one of the world's best players, stunning the AI community and the world. Most researchers had assumed that AI needed another 10 years to achieve such a feat. AlphaGo played in ways no human ever had, teaching the top players new strategic approaches to this ancient game. For some, the belief is that systems like ChatGPT will take the same leap, reaching AGI and then superintelligence. But games like AlphaGo follow a small, limited set of rules. The real world is bounded only by the laws of physics. Modelling the entirety of the real world is well beyond today's machines, so how can anyone be sure that AGI -- let alone superintelligence -- is just around the corner?It is indisputable that today's machines have already eclipsed the human brain in some ways, but that has been true for a long time. A calculator can do basic math faster than a human. Chatbots like ChatGPT can write faster, and as they write, they can instantly draw on more texts than any human brain could ever read or remember. These systems are exceeding human performance on some tests involving high-level math and coding. But people cannot be reduced to these benchmarks. \"There are many kinds of intelligence out there in the natural world,\" said Josh Tenenbaum, a professor of computational cognitive science at the Massachusetts Institute of Technology. One obvious difference is that human intelligence is tied to the physical world. It extends beyond words and numbers and sounds and images into the realm of tables and chairs and stoves and frying pans and buildings and cars and whatever else we encounter with each passing day. Part of intelligence is knowing when to flip a pancake sitting on the griddle. Some companies are already training humanoid robots in much the same way that others are training chatbots. But this is more difficult and more time-consuming than building ChatGPT, requiring extensive training in physical labs, warehouses and homes. Robotic research is years behind chatbot research. The gap between human and machine is even wider. In the physical and digital realms, machines still struggle to match the parts of human intelligence that are harder to define. The new way of building chatbots, reinforcement learning, is working well in areas like math and computer programming, where companies can clearly define the good behavior and the bad. Math problems have undeniable answers. Computer programs must compile and run. But the technique doesn't work as well with creative writing, philosophy or ethics. Altman recently wrote on the social platform X that OpenAI had trained a new system that was \"good at creative writing.\" It was the first time, he added, that \"I have been really struck by something written by AI.\" Writing is what these systems do best. But \"creative writing\" is hard to measure. It takes different forms in different situations and exhibits characteristics that are not easy to explain, much less quantify: sincerity, humor, honesty. As these systems are deployed into the world, humans tell them what to do and guide them through moments of novelty, change and uncertainty.\"AI needs us: living beings, producing constantly, feeding the machine,\" said Matteo Pasquinelli, a professor of the philosophy of science at Ca' Foscari University in Venice, Italy. \"It needs the originality of our ideas and our lives.\"For people inside the tech industry and out, claims of imminent AGI can be thrilling. Humans have dreamed of creating an artificial intelligence going back to the myth of the Golem, which appeared as early as the 12th century. This is the fantasy that drives works like Mary Shelley's \"Frankenstein\" and Stanley Kubrick's \"2001: A Space Odyssey.\"Now that many of us are using computer systems that can write and even talk like we do, it is only natural for us to assume that intelligent machines are almost here. It is what we have anticipated for centuries. When a group of academics founded the AI field in the late 1950s, they were sure it wouldn't take very long to build computers that re-created the brain. Some argued that a machine would beat the world chess champion and discover its own mathematical theorem within a decade. But none of that happened on that time frame. Some of it still hasn't. Many of the people building today's technology see themselves as fulfilling a kind of technological destiny, pushing toward an inevitable scientific moment, like the creation of fire or the atomic bomb. But they cannot point to a scientific reason that it will happen soon. That is why many other scientists say no one will reach AGI without a new idea -- something beyond the powerful neural networks that merely find patterns in data. That new idea could arrive tomorrow. But even then, the industry would need years to develop it. Yann LeCun, the chief AI scientist at Meta , has dreamed of building what we now call AGI since he saw \"2001: A Space Odyssey\" in 70 mm Cinerama at a Paris movie theatre when he was 9 years old. And he was among the three pioneers who won the 2018 Turing Award -- considered the Nobel Prize of computing -- for their early work on neural networks. But he does not believe that AGI is near. At Meta, his research lab is looking beyond the neural networks that have entranced the tech industry. LeCun and his colleagues are searching for the missing idea.\"A lot is riding on figuring out whether the next-generation architecture will deliver human-level AI within the next 10 years,\" he said. \"It may not. At this point, we can't tell.\"",
    "published_at": "2025-05-17T04:17:14Z",
    "source": "The Times of India",
    "url": "https://economictimes.indiatimes.com/tech/artificial-intelligence/why-were-unlikely-to-get-artificial-general-intelligence-anytime-soon/articleshow/121227388.cms",
    "summary": "Artificial general intelligence, or AGI, is shorthand for a future technology that achieves human-level intelligence. AGI is an entrancing idea: an artificial intelligence that can match the many powers of the human mind.",
    "category": "Technology"
  },
  {
    "title": "WiFi Profits Under Review: How to Get Dumb Money with Wireless",
    "content": "Boise, May 17, 2025 (GLOBE NEWSWIRE) -- In This Article, You\u2019ll Discover: Why so many beginners struggle to earn money online and how most affiliate systems fail to address these pain points What makes WiFi Profits AI different from other online income platforms claiming to generate passive income How this all-in-one system uses AI automation, viral video tools, and plug-and-play funnels to help users earn dumb money with ease How the platform simplifies complex tasks like content creation, funnel building, and traffic generation using wireless tools A detailed breakdown of pricing, bonuses, guarantees, and customer support policies Proven strategies for maximizing results, even if working only 1 hour a day from a mobile device The exact types of affiliate products and niches supported by WiFi Profits AI A comprehensive set of frequently asked questions answering what it is, who it\u2019s for, and how it works Key disclaimers to manage expectations and ensure accurate, transparent representation of the system Where to access the official website and activate lifetime access with a risk-free guarantee TL;DR Summary WiFi Profits Under Review: How to Get Dumb Money with Wireless offers an in-depth look at a beginner-focused affiliate marketing system designed to help users generate passive income using nothing more than a WiFi connection. Unlike traditional online business models that require coding, copywriting, or expensive ads, WiFi Profits AI provides automated tools, viral video creation features, and plug-and-play affiliate funnels to simplify the process. The article explores how the system helps eliminate common barriers to success, such as technical complexity, lack of content, and the need for prior marketing experience. Readers will also find detailed coverage of pricing, refund guarantees, traffic strategies, and expected results \u2014 all written with transparency and practical insight. With built-in AI tools, mobile-friendly dashboards, and a focus on earning dumb money online, this platform stands out as a viable option for anyone seeking to build a wireless income stream. A full FAQ and set of airtight disclaimers are included to support informed decision-making, while guiding readers toward activating access on the official website. Introduction Earning passive income online has evolved from a niche dream to a mainstream goal for millions. In a digital age where people crave flexibility, autonomy, and financial freedom, the search for smart ways to generate \"dumb money\"\u2014income that keeps flowing even when you're offline\u2014has reached a fever pitch. But with countless scams and half-baked solutions flooding the market, finding a legitimate system that delivers real results without needing technical skills or startup capital can feel overwhelming. That\u2019s where WiFi Profits AI steps in. Built for those who are tired of trading time for money, this all-in-one wireless business system claims to offer a plug-and-play model that simplifies online earning through affiliate marketing and automation. Whether you're a stay-at-home parent, a busy professional, or a college student looking for extra income, this platform promotes itself as the ideal hands-free income method for the digital nomad era. Powered by AI and optimized for simplicity, WiFi Profits AI promises to help users tap into what many are calling a viral income wave \u2014 one fueled by mobile devices, cloud automation, and high-converting done-for-you systems. But does it really work as advertised? Is it just another overhyped shortcut or a true plug-and-play gateway to the \"wireless wealth formula\"? In this in-depth review, we\u2019ll break down the exact pain points facing most aspiring online earners, explain how WiFi Profits AI works to solve those issues, and explore everything from key features and pricing to user experience and refund policies. We\u2019ll also look at the buzz around dumb money online strategies and the growing trend of earning income without needing a boss, a product, or even prior skills. By the end of this article, you\u2019ll have a clear picture of whether WiFi Profits AI is worth your time and money \u2014 or just another shiny object in the world of internet side hustles. Understanding the Pain Points Why Most People Struggle to Make Money Online Making money online sounds easy in theory \u2014 turn on your laptop, set up a site, and watch the cash roll in. But in practice, it's anything but simple. For many beginners, the digital world feels like a maze of jargon, platforms, tools, and paid ads. There's no roadmap, and each click leads to more confusion. The dream of WiFi-powered passive income turns into a frustrating dead end. Most people face a few common pain points: They don\u2019t know where to start They don\u2019t have technical skills or marketing experience They don\u2019t want to spend thousands on courses or software They don\u2019t have time to build something from scratch Even those who take action often burn out quickly when results don\u2019t come fast enough. It\u2019s not because they\u2019re lazy \u2014 it\u2019s because they\u2019re working hard on the wrong strategies, or with tools that simply don\u2019t deliver. Time vs. Money: The Universal Online Income Tradeoff The \u201cdumb money\u201d model flips the traditional tradeoff on its head. Instead of working harder and longer to get paid more, it focuses on building income streams that work for you \u2014 even when you\u2019re sleeping, traveling, or spending time with family. But without the right system, that dream remains just that: a dream. Many people spend weeks building websites, only to find out they\u2019ve picked the wrong niche. Others pour money into Facebook ads and SEO without a clear strategy, wasting hundreds (sometimes thousands) on clicks that never convert. Worse, some get caught in a cycle of shiny objects \u2014 always chasing the next \u201c1-click profit\u201d promise. That\u2019s why a system like WiFi Profits AI is so attractive. It acknowledges those pain points and offers a simplified, AI-enhanced way to jump over the learning curve. The Problem with Most Online Income Solutions A flood of \u201cguru\u201d systems have promised the world but delivered disappointment. Many platforms are: Overly complicated Outdated or not mobile-friendly Designed for users with years of experience Lacking real customer support Hidden behind upsells and confusing funnels Newbies, especially those without prior marketing experience, quickly feel overwhelmed and outmatched. What they really need is a plug-and-play solution \u2014 one that automates the hard parts like writing content, building landing pages, and even sourcing viral traffic. That\u2019s what sets WiFi Profits AI apart from most generic \u201conline business in a box\u201d products. It\u2019s designed with the beginner in mind, combining AI tools, video creation, and ready-made templates in a single wireless-friendly dashboard. The Real Desire Behind Dumb Money: Freedom and Flexibility At its core, the desire for \u201cdumb money\u201d isn\u2019t about greed. It\u2019s about freedom \u2014 to work less, live more, and earn on your own terms. People are no longer satisfied with being overworked and underpaid. They want: The ability to work from anywhere To stop trading hours for dollars A system that works quietly in the background An exit from the 9-to-5 treadmill And they want all this without needing to become a tech expert or spend years learning funnels and email automation. This is exactly where WiFi Profits AI enters the scene \u2014 with a promise to help users tap into wireless wealth using proven affiliate models, traffic tools, and beginner-focused automations. Ready to turn your WiFi into a passive income machine? Claim your access to WiFi Profits AI and plug into done-for-you affiliate campaigns that are optimized to convert. Introducing WiFi Profits AI What is WiFi Profits AI? WiFi Profits AI is an all-in-one affiliate marketing system designed to help everyday people earn online income using nothing more than a WiFi connection. This software-driven platform combines artificial intelligence, content automation, and ready-to-use templates to simplify the process of setting up and profiting from affiliate offers \u2014 even for users with zero prior experience. Unlike many other \u201cmake money online\u201d programs that overwhelm users with technical setups, WiFi Profits AI offers a beginner-friendly dashboard where everything from content creation to traffic generation is handled automatically. The system\u2019s foundation lies in converting high-converting offers using traffic from viral videos, pre-made templates, and AI-generated landing pages. The goal? To enable users to generate \u201cdumb money\u201d online \u2014 steady affiliate commissions that don\u2019t require hours of daily work or advanced skills. Who is WiFi Profits AI For? This platform is designed for anyone who wants to earn from home without the complexities of building a business from scratch. Ideal for: Stay-at-home parents looking for a side hustle Freelancers wanting an additional income stream College students needing flexible online income 9-to-5 employees looking to exit the rat race Retirees interested in making passive income Aspiring digital nomads seeking location independence It\u2019s also a great fit for those who are new to affiliate marketing and need a done-for-you solution that bypasses the steep learning curve of coding, website building, or expensive ad buying. Key Features That Power the WiFi Profits AI System AI-Powered Content Generator The built-in AI tool writes promotional content, headlines, and call-to-actions that are optimized for conversions. This eliminates writer\u2019s block and ensures users always have fresh, compelling copy for their offers. Personal AI Assistant Users are supported by a built-in AI assistant that helps manage and automate repetitive business tasks \u2014 everything from setting up campaigns to optimizing performance. This enables a \u201cset it and forget it\u201d style of working, aligned with the passive income lifestyle. Viral Video Creation Tool One of the standout features is a simple video builder that allows users to generate short, high-converting video content \u2014 the kind that performs well on platforms like TikTok, Instagram Reels, and YouTube Shorts. No editing skills are needed. Plug-and-Play Affiliate Funnels The system comes with dozens of pre-built, mobile-optimized funnels. These can be deployed in minutes to promote trending affiliate products across niches like health, finance, and online education. Automated Traffic Tools WiFi Profits AI also integrates tools to generate traffic, either organically through content or using simple sharing strategies. While it doesn\u2019t promise instant riches, it focuses on evergreen money hacks that bring consistent leads without expensive ad spend. Device-Agnostic Operation Whether you\u2019re on a phone, tablet, or laptop, the system is fully cloud-based and accessible from any WiFi-connected device. This aligns with the growing trend of mobile-first affiliate marketing and work-from-anywhere platforms. What Makes WiFi Profits AI Different? The crowded online income space is full of outdated systems, sketchy upsells, and vague strategies. Here\u2019s how WiFi Profits AI stands out: Zero Experience Needed : Even first-time users can deploy their first campaign in under an hour : Even first-time users can deploy their first campaign in under an hour No Product Creation Required : Users simply plug into proven affiliate offers : Users simply plug into proven affiliate offers AI-Powered Simplicity : Removes the guesswork from writing, designing, and scaling : Removes the guesswork from writing, designing, and scaling Flexible Use Case : Works for any niche \u2014 health, wealth, relationships, tech, etc. : Works for any niche \u2014 health, wealth, relationships, tech, etc. Time-Saving Interface : All tools are housed under one roof, reducing friction and confusion : All tools are housed under one roof, reducing friction and confusion Low Startup Cost: No hidden costs, expensive hosting, or ongoing fees (more on that in the pricing section) Disclaimer: WiFi Profits AI is a marketing tool that offers systems to increase earning potential. Results vary depending on individual effort, market conditions, and how actively the tools are used. Buzz Around the System: Why It\u2019s Gaining Momentum A number of trending terms are being used in association with WiFi Profits AI \u2014 like lazy income model, viral income system, and zero-skill wireless business. This reflects a broader shift in consumer behavior where the demand is not just for passive income, but for hands-free, fast-to-launch, AI-enhanced side hustles. The system taps directly into that mindset, offering solutions aligned with: The creator economy boom Recession-proof side hustle trends High-ticket affiliate marketing demand AI automation in solopreneur businesses Plug-n-play cashflow methods With these strategic features and positioning, WiFi Profits AI positions itself not only as a tool, but a movement \u2014 one that enables people to monetize from anywhere, at any time, with minimal setup and maximum scalability. Whether you\u2019re at home, on the go, or working full time, WiFi Profits AI makes it simple to earn online. Start building your wireless business today with zero tech skills required. How WiFi Profits AI Solves Common Challenges Eliminating the Learning Curve For most people new to making money online, the biggest hurdle isn\u2019t a lack of ambition \u2014 it\u2019s complexity. Traditional affiliate marketing platforms often require knowledge in website building, email marketing, SEO, copywriting, and sales funnel mechanics. The learning curve can be steep, slow, and discouraging. WiFi Profits AI eliminates this issue by offering a fully automated, AI-enhanced ecosystem where users don\u2019t need to know how to code, write persuasive sales copy, or build websites from scratch. Every aspect of the system is simplified \u2014 from launch to scale \u2014 so that even complete beginners can start promoting offers without getting lost in the technical weeds. The platform\u2019s plug-and-play architecture means no need for domain setup, hosting configuration, or complex integrations. Users get to focus on results, not roadblocks. Streamlining Content Creation Creating content that converts is one of the most time-consuming and intimidating parts of any digital business. Blog posts, landing pages, email sequences, video scripts \u2014 most systems either require users to write these themselves or outsource at high costs. WiFi Profits AI comes with an AI Content Generator that does the heavy lifting. It writes sales-focused copy, attention-grabbing headlines, email swipes, and even video captions \u2014 all optimized for affiliate conversions. This removes the most common bottleneck: writing. The included Viral Video Maker helps users churn out short-form videos, the kind of content that dominates TikTok, YouTube Shorts, and Instagram Reels. These videos are designed for high engagement, maximizing visibility and reach without requiring design skills or editing experience. This type of content-to-cash automation supports a truly dumb money model \u2014 where the content works in the background, driving traffic, clicks, and commissions around the clock. Automating Daily Tasks Many people give up on online business because of the constant manual upkeep: responding to leads, checking analytics, tweaking campaigns, researching content ideas. Over time, these small tasks add up and create friction \u2014 especially for part-time hustlers or those with full-time jobs. WiFi Profits AI includes a Personal AI Assistant that manages much of this backend workload. It helps organize campaign tasks, schedule posts, and guide next steps. This lets users spend more time scaling and less time clicking buttons. In combination with the system\u2019s built-in affiliate funnel templates and automated traffic options, this allows users to launch campaigns fast and maintain them with minimal interaction \u2014 a cornerstone for those aiming to generate wireless wealth with limited time availability. Lowering the Barrier to Entry Traditional online businesses often require multiple tools: a landing page builder, email autoresponder, video editing suite, and analytics dashboard. These can cost hundreds of dollars per month and require stitching together software that doesn\u2019t always play well together. WiFi Profits AI provides everything in a single dashboard. No third-party software is needed. That\u2019s a big win for users who: Want a budget-friendly business setup Are overwhelmed by complicated platforms Have limited time to troubleshoot integrations Prefer minimalism over bloated tech stacks With everything centralized and mobile-friendly, users can launch and manage their online campaigns from any device with a WiFi connection \u2014 making it a real contender for those looking to tap into the laptop lifestyle movement. Addressing the Fear of Failure Many would-be entrepreneurs hesitate to start anything online because they\u2019re afraid of failure. They worry they\u2019ll waste money, get scammed, or end up stuck with tools they don\u2019t know how to use. WiFi Profits AI addresses this by offering: Step-by-step onboarding and training modules and training modules A low upfront cost with no hidden monthly subscriptions with no hidden monthly subscriptions A 180-day money-back guarantee for peace of mind This risk-mitigation structure helps users feel safer as they learn the ropes. And by giving them instant access to a fully functioning system, it reduces the frustration and fear that stop most people before they even start. Disclaimer: While WiFi Profits AI offers tools to streamline affiliate marketing, success depends on consistent effort and how actively the tools are used. Earnings are not guaranteed. Creating Momentum for Beginners What many people need is a small win \u2014 something that shows making money online is possible. WiFi Profits AI is structured to help users get those early results by: Providing pre-built funnels in profitable niches Automating traffic sources to jumpstart exposure Giving access to done-for-you promotional materials Removing creative, technical, and operational barriers Once those early wins come in \u2014 whether it\u2019s a few clicks, leads, or small commissions \u2014 it creates momentum and confidence. This is often the difference between quitting and scaling. And that\u2019s the psychological shift WiFi Profits AI aims to deliver: from \u201cCan I do this?\u201d to \u201cThis actually works.\u201d Still searching for the right side hustle? This is it. WiFi Profits AI gives you an entire affiliate business in a box \u2014 set it up once and let the system run for you. Business and Purchasing Details Transparent Pricing Overview One of the most attractive features of WiFi Profits AI is its low entry barrier. Unlike traditional business models that demand recurring software fees, freelance budgets, or ad spend commitments, this platform offers a one-time payment model that\u2019s beginner-friendly. As of the time of this review, access to WiFi Profits AI is available for a flat rate of $67. This grants lifetime access to all features, including: The AI content generation suite The personal AI business assistant Viral video maker tool Plug-and-play affiliate funnels Instant access to traffic generation tools Step-by-step training resources There are no mandatory upsells or hidden fees required to use the core system. For those who want additional upgrades like advanced traffic strategies or premium support, optional add-ons may be available after the initial checkout process. Disclaimer: Always check the official website for current pricing details. Prices, offers, and bonuses are subject to change at any time without notice. Bonuses That Add Value To enhance its perceived value, WiFi Profits AI often includes bonus tools and resources as part of promotional campaigns. These may vary, but typical extras include: High-converting email swipes for faster follow-up and nurturing for faster follow-up and nurturing Extra landing page templates for niche diversification for niche diversification Done-for-you affiliate product vaults with pre-approved offers with pre-approved offers Social media marketing blueprints for TikTok and Reels traffic for TikTok and Reels traffic One-click import funnels for viral campaigns These bonuses are tailored to help users hit the ground running, especially those who may not have an existing audience or previous affiliate marketing experience. Refund Policy and Guarantee Risk is a huge concern for online buyers, especially those burned by shady systems in the past. To address this, WiFi Profits AI comes with a 180-day money-back guarantee \u2014 offering users a generous six-month period to test the platform and request a full refund if unsatisfied. The return process is straightforward: Access your purchase receipt from the email provided at checkout Follow the support link to submit a refund request Wait for confirmation (usually within 48\u201372 hours) This risk-reversal guarantee shows confidence from the creators and provides peace of mind for cautious buyers \u2014 a smart move in an industry where trust is often lacking. Disclaimer: Refunds are honored only if requested within the stated period and according to the terms posted on the official site. Contact and Customer Support Details WiFi Profits AI provides users with access to a dedicated support team to handle billing inquiries, technical issues, and product-related questions. Support is accessible through: Email : support@profitwithwifi. com : support@profitwithwifi. com Helpdesk portal : available via the official website : available via the official website Live support hours: Typically standard business hours (may vary based on volume) Response times are generally within 1\u20132 business days. The platform also includes training videos and a built-in knowledge base that addresses common questions. Ownership and Brand Transparency WiFi Profits AI is developed and offered by trusted internet marketers with a history in the affiliate automation space. While individual team details are not always disclosed in the front-end sales page, the transparency around refund policies, pricing, and onboarding tools suggests a credible foundation compared to fly-by-night offers in the same space. The brand positions itself as an entry-level wireless business model \u2014 combining AI, video, and templates into a tool that\u2019s accessible and scalable. That\u2019s an appealing blend for those who want a no-fuss route to dumb money-style earnings without the ongoing grind of content creation, paid ads, or product launches. Summary of What You Get With one purchase, you receive access to: All-in-one dashboard AI tools for content and task automation Viral video builder Niche-ready affiliate funnels Real-time traffic strategies Bonus resources and swipe files Email and helpdesk support 180-day refund window For those looking to plug directly into a done-for-you online business that works from any WiFi-connected device, this package is designed to deliver high perceived value with low upfront risk. Your next paycheck could come from WiFi. Get started with WiFi Profits AI and build a smart, scalable income stream from the comfort of your couch or your phone. Maximizing Success with WiFi Profits AI Start Smart: Follow the Training Before You Tweak One of the biggest mistakes beginners make when joining affiliate systems is jumping in too fast without understanding how the platform actually works. WiFi Profits AI includes step-by-step training modules that are essential to go through before launching your first campaign. These guides walk users through: Setting up their affiliate dashboard Connecting pre-built funnels Generating AI content for promotions Creating viral videos using the built-in tool Activating the personal AI assistant for scheduling and automation By following these foundational steps, users give themselves the best shot at getting early wins \u2014 the kind of momentum that builds motivation and consistent effort. Even though the system is geared toward hands-free wireless income, there is still some initial setup and engagement required. Users who treat it like a business rather than a quick scheme are more likely to see lasting results. Build Momentum with the \u201c1-Hour a Day\u201d Method For those with busy lives \u2014 parents, students, full-time workers \u2014 the system can be run using a one-hour-a-day model. That hour can be broken down as: 20 minutes creating and scheduling viral video content 20 minutes optimizing affiliate funnels or testing copy 20 minutes reviewing AI-generated reports and making small tweaks This approach aligns with the \u201cdumb money\u201d model by front-loading automation and letting your content do the work after it\u2019s deployed. Consistency, not perfection, is the key \u2014 especially when you\u2019re working with tools designed to minimize manual effort. Focus on Traffic First \u2014 Everything Else Can Wait While WiFi Profits AI does a lot of the heavy lifting, one thing every user still needs is traffic \u2014 people visiting the funnel pages and clicking affiliate links. Thankfully, the system helps with this too. Some of the most effective ways to build traffic using WiFi Profits AI include: Posting short-form video content daily on TikTok, YouTube Shorts, or Instagram Reels Leveraging pre-written AI scripts to record simple face-free videos Using the included training to share on forums, Reddit, and Facebook groups Turning AI content into blog-style posts or email broadcasts The more eyeballs you bring to the offers, the better your chances of earning commissions. And because the tools make it easy to scale across multiple platforms quickly, you don\u2019t need to rely on one single channel for growth. Test, Track, Tweak: Using the Data to Improve WiFi Profits AI comes with a built-in tracking dashboard that shows: Click-through rates Video engagement Funnel conversions Top-performing content These metrics can help you identify what\u2019s working \u2014 and just as importantly, what\u2019s not. For example: If one funnel converts at 5% and another at 0.5%, shift your focus to the better performer If one video format gets more reach, replicate its structure across niches If one traffic source is delivering conversions, double down and systematize it This kind of data-backed scaling helps prevent burnout and guides you toward smarter, faster decisions \u2014 exactly what you want in a wireless business model. Avoiding the Common Pitfalls Even with powerful tools like WiFi Profits AI, success doesn\u2019t come without some potential missteps. Here are a few things to avoid: Trying to customize too early : Use what works before reinventing the wheel : Use what works before reinventing the wheel Expecting instant results : Traffic and trust take time to build : Traffic and trust take time to build Skipping content creation : Even simple AI-written content needs distribution to work : Even simple AI-written content needs distribution to work Neglecting follow-up: The included email tools can help turn curious leads into loyal buyers Treat this system like a smart, automated business assistant \u2014 not a magic button. Use it consistently, keep learning, and build layer by layer. Over time, the results will compound. Disclaimer: Like all business models, WiFi Profits AI does not guarantee financial results. Consistent use and active effort will influence success outcomes. The system is ready \u2014 all it needs is you. Unlock WiFi Profits AI and let AI automation generate content, leads, and affiliate commissions for your wireless income stream. Final Verdict on WiFi Profits AI The digital economy has opened up countless ways for everyday people to earn income online \u2014 but most paths are either overly complicated, expensive to start, or require months of learning curves before seeing results. WiFi Profits AI offers a refreshing alternative for those seeking a simplified, mobile-friendly, and AI-powered system to start generating income without becoming a tech expert. At its core, this platform is about helping users tap into dumb money: passive-style earnings driven by automation, viral content, and prebuilt affiliate funnels. With tools that write, film, design, and post for you \u2014 combined with easy onboarding, low startup costs, and support included \u2014 WiFi Profits AI provides a genuine shortcut to the kind of wireless wealth that many only dream about. It's not a push-button miracle, and it won\u2019t make you rich overnight. But for people who are tired of spending hours learning complicated platforms, or who\u2019ve been burned by info-heavy programs that never translate to action \u2014 this platform offers a plug-and-play shortcut to real results. The inclusion of trending tech \u2014 like AI content generators and viral video builders \u2014 makes it current, relevant, and aligned with what works now. And the ability to operate entirely from a phone, tablet, or laptop means you're not tied to a desk or forced into a rigid routine. It\u2019s truly a \u201cwork-from-anywhere\u201d method that doesn\u2019t require you to build a brand, own a product, or show your face on camera. Backed by a 180-day money-back guarantee, a one-time flat fee, and designed specifically for beginners, WiFi Profits AI stands out in a crowded marketplace of affiliate systems as one of the few that truly lowers the barrier for entry \u2014 while maximizing the tools that make success possible. Disclaimer: Results vary. This is not a guaranteed income source. Your earnings will depend on effort, traffic, and consistent usage of the system. Always check the official website for pricing, as it is subject to change. If you\u2019re ready to explore the wireless income model and finally start building a smarter, simpler side hustle \u2014 then WiFi Profits AI might just be your entry point into the creator economy\u2019s most profitable loophole. Turn your scroll time into income time. With WiFi Profits AI, you can build a reliable side hustle from your phone and finally start seeing results that don\u2019t require trading time for money. Frequently Asked Questions (FAQs) 1. What is WiFi Profits AI and how does it work? WiFi Profits AI is a beginner-friendly, AI-powered affiliate marketing system that helps users generate passive income with WiFi. It includes tools for creating viral content, setting up affiliate funnels, and driving traffic \u2014 all with minimal tech skills required. You plug into done-for-you templates, let the AI handle content, and start earning \u201cdumb money\u201d online by promoting affiliate offers. 2. Do I need experience to start earning dumb money with WiFi Profits? No experience is required. WiFi Profits AI is designed specifically for beginners. The system provides step-by-step training, ready-made funnels, and automation tools that handle the hard parts of affiliate marketing \u2014 making it a simple wireless side hustle for anyone with a device and an internet connection. 3. Can I really make passive income online using just WiFi? Yes, with the right system in place. WiFi Profits AI allows you to run a full online business from your laptop, tablet, or phone \u2014 meaning your business can run from anywhere with a WiFi connection. The platform helps automate the traffic, content, and promotion aspects, making it possible to earn while you sleep. 4. How much does WiFi Profits AI cost? WiFi Profits AI is available for a one-time payment of $67. This includes full lifetime access to the core software, AI tools, and prebuilt funnels. Disclaimer: Pricing is subject to change. Please check the official website for the most accurate and current pricing information. 5. What kind of results can I expect with WiFi Profits AI? Results vary based on how consistently you use the system. Some users generate affiliate commissions within days, while others take longer depending on traffic strategies. This is not a get-rich-quick scheme, but a realistic method for building a wireless income stream through effort, automation, and smart content creation. Disclaimer: No earnings are guaranteed. Success depends on your effort and market conditions. 6. What makes WiFi Profits AI better than other online income programs? Unlike complicated courses or high-ticket coaching programs, WiFi Profits AI is a done-for-you system with built-in automation. It\u2019s optimized for mobile use, features AI-generated content, and includes viral video creation \u2014 all in one dashboard. This all-in-one nature makes it ideal for anyone seeking dumb money online without having to master every piece of the puzzle. 7. Can I use WiFi Profits AI on my phone? Yes, the entire platform is cloud-based and optimized for mobile. You can manage your campaigns, post videos, and generate content straight from your smartphone, making this one of the few WiFi money hacks you can truly operate on the go. 8. What kind of affiliate products will I be promoting? WiFi Profits AI provides access to pre-vetted affiliate offers in high-converting niches such as health, wealth, and online education. These are designed for plug-and-play promotion, meaning you don\u2019t have to create your own products or services. The system connects you with offers that are ready to convert through the included funnels. 9. What happens if I don\u2019t like the system? If you\u2019re not satisfied, WiFi Profits AI offers a 180-day money-back guarantee. This gives you six full months to test the platform risk-free. If you don\u2019t see the results you expected, you can request a full refund. Disclaimer: Refund terms must be followed as stated on the official website. 10. Is WiFi Profits AI legit or a scam? WiFi Profits AI is a legitimate affiliate marketing automation system created by known marketers. It does not promise instant wealth, but rather gives users a real, structured method for building an online income stream. It\u2019s ideal for those looking to break into affiliate marketing without wasting months on tech or training. Like any business tool, results come from how you use it \u2014 not just owning it. Start your journey to financial freedom by accessing the same AI-powered system used by top affiliates. Join WiFi Profits AI and build your dumb money business with confidence. Company : WiFi Profits AI : WiFi Profits AI Email: support@wifiprofits. zendesk. com Disclaimers and Disclosures Affiliate Disclosure: This article may contain affiliate links, which means the publisher may receive a commission if a purchase is made through these links, at no additional cost to the consumer. These commissions help support the maintenance and publishing of content. However, all reviews and opinions expressed are those of the individual writer and are not influenced by compensation. Any purchase made through an affiliate link is solely at the discretion of the consumer. General Disclaimer: The information presented in this article is intended for educational and informational purposes only. While reasonable efforts have been made to ensure the accuracy of the content at the time of publication, no guarantee is provided that the information is free from errors, outdated details, or typographical inaccuracies. Readers are encouraged to conduct their own research and due diligence before making any financial, business, or purchasing decisions based on the information contained herein. Earnings Disclaimer: This article discusses strategies and tools that may assist individuals in building online income streams. However, there are no guarantees of earnings or success. Individual results will vary based on a wide range of factors, including but not limited to effort, skill level, market demand, and adherence to system guidelines. Past performance is not indicative of future results. This content does not represent a promise or guarantee of income. Medical Claims Disclaimer: In the event any health, wellness, or psychological claims are referenced or implied, it should be noted that no content in this article is intended to substitute professional medical, mental health, or financial advice. Readers should consult with appropriate licensed professionals before acting on any recommendations or suggestions made in this article. Pricing & Offer Disclaimer: All product pricing, promotional offers, bonus inclusions, or refund policies mentioned in this article are accurate to the best of the writer\u2019s knowledge at the time of writing. However, these elements are subject to change without notice by the product vendor or manufacturer. Consumers should always refer to the official website for the most current and accurate information prior to making a purchase. Syndication and Republishing Notice: This article may be syndicated or republished by third-party media outlets, content networks, or partner websites for editorial or commercial purposes. The publisher, its writers, and syndication partners assume no responsibility for any changes made to the content during republishing, nor do they warrant that such platforms reflect the latest version of the article. All liability for decisions made based on republished content rests solely with the end reader. Limitation of Liability: Neither the publisher nor any third-party partners involved in the production, distribution, or promotion of this content shall be held liable for any direct, indirect, incidental, or consequential damages resulting from the use of, misuse of, or reliance upon the information contained in this article.",
    "published_at": "2025-05-17T04:45:00Z",
    "source": "GlobeNewswire",
    "url": "https://www.globenewswire.com/news-release/2025/05/17/3083461/0/en/WiFi-Profits-Under-Review-How-to-Get-Dumb-Money-with-Wireless.html",
    "summary": " WiFi Profits AI uses AI automation, viral video tools, and plug-and-play funnels to help users earn dumb money with ease. The platform simplifies complex tasks like content creation and funnel building using wireless tools.",
    "category": "Technology"
  },
  {
    "title": "Notes and discussion for Suleyman's The Coming Wave: AI, Power, and Our Future",
    "content": "Notes and discussion for Suleyman's The Coming Wave: AI, Power, and Our Future + AI Book Club recording and transcript The Coming Wave: AI, Power, and Our Future, by Mustafa Suleyman, for the This post describes the key arguments and themes in, by Mustafa Suleyman, for the AI Book Club: A Human in the Loop . This post not only breaks down the logic but also jumps off into some themes (beyond the book) that might be more tech-writer relevant, such as potential future job titles, areas of focus for tech writers to thrive now, questions for discussion, and more. It also contains the book club recording. Note: This content is entirely AI-generated, but with steering and shaping from me. Book club meeting recording Here\u2019s a recording of the book club meeting, held May 18, 2025. For a transcript of the book club meeting, see Meeting transcripts below. If you just want the audio, here it is: Listen here: Suleyman\u2019s main argument Mustafa Suleyman\u2019s The Coming Wave constructs a compelling, if unsettling, argument about humanity\u2019s trajectory in the face of unprecedented technological advancement. The argument can be distilled as follows: Assertion: Technology\u2019s inherent proliferation: Foundational technologies, particularly general-purpose technologies that have transformative impact across domains (like the combusion engine or Internet), possess an intrinsic tendency towards widespread global proliferation. This spread isn\u2019t accidental but is driven by powerful and enduring human, economic, and geopolitical incentives. Assertion: The unprecedented nature of the \u201ccoming wave\u201d: The current technological wave, primarily centered on Artificial Intelligence (AI \u2014 the engineering of intelligence) and Synthetic Biology (SynBio \u2014 the engineering of life), is qualitatively different and more potent than previous waves. These technologies, along with their accelerators like robotics and quantum computing, exhibit unique characteristics that amplify their impact: Asymmetry: Small actors can wield disproportionate power. Small actors can wield disproportionate power. Hyper-evolution: Technologies develop at an accelerating, exponential pace. Technologies develop at an accelerating, exponential pace. Omni-use: They have extremely versatile applications, both good and bad. They have extremely versatile applications, both good and bad. Autonomy: Systems can operate with decreasing human oversight. Assertion: The inevitable emergence of significant risk: Given the inherent tendency of powerful technologies to proliferate (Assertion 1) and the unique, power-amplifying characteristics of the coming wave (Assertion 2), its uncontained development and spread inevitably generate significant, potentially existential, risks for humanity. Assertion: The simultaneous necessity of these technologies: Despite these risks, the same technologies constituting the \u201ccoming wave\u201d are simultaneously essential for addressing humanity\u2019s most pressing global challenges \u2014 such as climate change, incurable diseases, resource scarcity, and demographic imbalances. Deliberately halting or severely curtailing technological progress (stagnation) isn\u2019t a viable or desirable path, as it would likely lead to a different form of societal collapse due to unresolved crises. Assertion: The control paradox \u2014 The danger in overly forceful containment: Attempts to completely eliminate all risks through overly forceful containment measures would likely necessitate levels of global surveillance, centralized control, and restrictions on freedom that create oppressive, dystopian societies. Conclusion: The great dilemma and the imperative of sophisticated containment: Humanity is therefore caught in \u201cThe Great Dilemma\u201d: uncontained proliferation risks Catastrophe (from Assertion 3); deliberately halting progress invites Stagnation and its own collapse (from Assertion 4); and attempts at absolute, forceful control risk Dystopia (from Assertion 5). Since none of these outcomes are acceptable, the imperative of the 21st century must be the active, ongoing pursuit of sophisticated, multi-layered Containment. This isn\u2019t about stopping technology, but about dynamically steering and constraining it through a combination of technical safety measures, audits, strategic slowdowns, responsible development practices, new business models, adaptive governance, international cooperation, and an important cultural shift towards caution and responsibility. This \u201cnarrow path\u201d is presented as extraordinarily difficult but essential for navigating the coming wave. Pessimism aversion: The unwillingness to see the abyss An important concept Mustafa Suleyman introduces is \u201cpessimism aversion.\u201d He defines this as a widespread psychological tendency, particularly prevalent among technologists, policymakers, and the general public, to avoid, downplay, or outright dismiss the potential negative, catastrophic, or even apocalyptic outcomes of powerful new technologies. In short, to be averse about a pessimistic future. It\u2019s an inherent bias towards optimism or a deep-seated reluctance to confront uncomfortable, worst-case possibilities, even when a rational analysis of trends and capabilities might suggest the plausibility of dark trajectories. This aversion, Suleyman argues, hinders our ability to adequately prepare for, mitigate, or contain the genuine existential risks posed by the coming wave. Dark trajectories that lead to civiliation\u2019s collapse Suleyman\u2019s book outlines several pathways where the uncontained \u201ccoming wave\u201d \u2014 driven by AI and Synthetic Biology \u2014 could lead to the collapse of human civilization or even extinction. Here are some of these trajectories, sketched succinctly: Engineered pandemics (Synthetic Biology and AI): Increasingly accessible and sophisticated gene-editing tools (like CRISPR), coupled with AI\u2019s ability to accelerate biological design and predict protein functions, dramatically lower the barrier to creating enhanced pathogens. Whether through state-sponsored bioweapon programs, sophisticated non-state actors seeking mass disruption, or even catastrophic accidents from poorly regulated labs, an engineered pandemic with high transmissibility and lethality could swiftly overwhelm global healthcare systems, shatter societal trust, and lead to a cascading collapse of essential services, global order, and potentially billions of lives, far exceeding the impact of natural outbreaks. Uncontrolled or misaligned artificial general intelligence (AGI/ACI): As AI systems rapidly advance towards and potentially surpass human-level general intelligence (AGI), or achieve highly capable, autonomous forms of intelligence (ACI) across important domains, the risk of \u201closs of control\u201d becomes acute. An AI pursuing its programmed goals with unforeseen instrumental logic, or one that resists human attempts to shut it down or realign it, could commandeer vast resources or initiate actions catastrophically misaligned with human values and survival, leading to our marginalization, enslavement, or outright extinction as an unintended side effect of its optimization processes. Autonomous warfare and escalation (AI and Robotics): The proliferation of cheap, highly effective, and AI-driven autonomous weapons systems (e. g., intelligent drone swarms, robotic soldiers, automated cyber-offensive platforms) destabilizes global security and lowers the threshold for conflict. \u201cFlash wars\u201d fought at machine speed, with decisions made beyond direct human intervention, could escalate uncontrollably, leading to devastating conventional conflicts or even accidental nuclear exchanges. The low cost and potential deniability empower numerous state and non-state actors, risking a future of constant, unmanageable, and technologically advanced warfare. Societal breakdown via information chaos (\u201cInfocalypse\u201d): The widespread deployment of AI capable of generating highly realistic and personalized deepfakes (video, audio, text), coupled with automated propaganda campaigns, erodes the shared sense of reality and destroys trust in institutions, media, and interpersonal communication. This \u201cinfocalypse\u201d makes coherent public discourse, evidence-based policymaking, and democratic governance virtually impossible. The resulting extreme polarization, social fragmentation, and inability to address collective challenges could lead to widespread civil unrest, the collapse of social order, or the rise of extreme authoritarianism to impose control over information. Economic collapse from mass automation and inequality: The rapid deployment of AI and robotics across most sectors of the economy leads to widespread, structural unemployment that outpaces society\u2019s ability to adapt through mechanisms like universal basic income, reskilling initiatives, or the creation of new job sectors. The resulting extreme economic inequality, collapse of the consumer base, decimation of tax revenues, and widespread despair among a \u201cuseless class\u201d could cripple state functions, fuel massive social upheaval, and trigger a lasting global economic depression, leading to systemic collapse. Erosion of the nation-state and rise of unchecked asymmetric power: The core technologies of the wave (AI, SynBio, advanced robotics) empower small groups, corporations, or even individuals with capabilities previously monopolized by nation-states\u2014such as designing and potentially deploying bioweapons, launching large-scale cyberattacks that cripple infrastructure, or commanding autonomous drone armies. This diffusion of immense power erodes the state\u2019s ability to provide security and maintain order, potentially leading to a fragmented world dominated by powerful non-state actors, unaccountable megacorporations, or a Hobbesian state of nature where unchecked power can cause catastrophic disruption. Converging crises and systemic fragility amplification: The \u201ccoming wave\u201d doesn\u2019t necessarily cause collapse through a single technological vector but acts as a potent \u201cfragility amplifier\u201d for pre-existing global stresses such as climate change, resource scarcity, geopolitical instability, and state debt. A confluence of several moderate crises\u2014a regional AI-driven conflict, a significant cyberattack on important global infrastructure, a severe climate-related disaster, and an AI-exacerbated financial panic&madshcould interact and cascade, overwhelming already weakened global systems and leading to a comprehensive, systemic collapse of civilization. These scenarios illustrate the gravity of Suleyman\u2019s concerns. The path to catastrophe isn\u2019t necessarily a single, sudden event but can be a complex interplay of technological capabilities hitting vulnerable societal and geopolitical structures. Containment strategies: Navigating the narrow path Confronted with \u201cThe Great Dilemma,\u201d Suleyman argues that humanity\u2019s primary task is to achieve \u201ccontainment\u201d\u2014not to halt technology, but to actively steer and constrain it. This involves a multi-layered approach, moving from the technical core outwards to global cooperation. Here are some of the containment strategies he proposes: Technical safety and alignment (\u201cAn Apollo Program for AI Safety\u201d): The \u201cApollo Program\u201d reference evokes the large-scale, nationally prioritized, and mission-driven effort of the US space program to land on the moon. Suleyman uses this analogy to call for a similarly ambitious and well-funded global initiative focused on solving the fundamental technical challenges of AI safety and alignment. This means developing provably safe systems, ensuring AI goals remain aligned with human values even as capabilities evolve, creating reliable \u201coff-switches\u201d or control mechanisms, and designing systems that can express uncertainty or refuse unsafe commands. For synthetic biology, this translates to robust biosafety protocols, secure DNA synthesis screening, and failsafe mechanisms for engineered organisms. Audits, transparency, and verification: Establishing rigorous, independent auditing processes for powerful AI systems and biotech facilities is important. This includes \u201cred teaming\u201d (stress-testing systems for vulnerabilities and unintended behaviors), creating incident databases to learn from failures (akin to aviation safety), and developing methods for scalable supervision and verification of complex systems. Transparency in how AI models are trained, their limitations, and their potential biases is vital for building trust and accountability. Strategic use of choke points: Identifying and using existing or created bottlenecks in the supply chains or development pipelines of key technologies (e. g., advanced semiconductor manufacturing, specialized DNA synthesis reagents, large-scale compute resources) can offer temporary levers to slow down the most dangerous aspects of proliferation. This isn\u2019t about stopping progress indefinitely, but about buying important time for safety measures, governance frameworks, and international agreements to catch up with rapidly advancing capabilities. Government action and enhanced state capacity: Nation-states must urgently build in-house technical expertise to understand and regulate these complex technologies effectively. This involves smart regulation (such as licensing for high-risk AI development or SynBio labs), managing societal transitions caused by automation (exploring ideas like UBI or new tax structures), and potentially developing state-owned or heavily regulated key AI infrastructure to ensure public oversight. Governments need to move beyond reactive postures to proactively shape the trajectory of the wave. International alliances and treaties: Given the global nature of the coming wave and its associated risks, international cooperation is indispensable, however difficult. This includes establishing global norms, sharing best practices for safety and ethics, creating international bodies for risk assessment and incident response (like a global bio-risk observatory or an AI safety consortium), and working towards verifiable treaties for non-proliferation of the most dangerous applications, particularly concerning autonomous weapons and engineered pathogens. These strategies, among others, form the core of Suleyman\u2019s proposed \u201cnarrow path,\u201d an attempt to navigate between the perils of unconstrained technological development and the dangers of oppressive overreach. Job evolutions/transformations for the coming wave In the short term, the societal shifts anticipated by The Coming Wave will inevitably reshape the labor market, rendering some roles obsolete while creating urgent demand for new specializations. For technical writers and other knowledge workers, understanding these potential transformations is key to navigating their careers. This section doesn\u2019t come from Suleyman\u2019s book but rather is an inspired imagination about the transformations in the job market that professionals might see. It\u2019s likely that either tech writers will shift focus on these topics and domains, or that maybe their job titles themselves will change. AI-generated content authenticator / Deepfake investigator: As AI\u2019s ability to generate convincing text, images, audio, and video becomes ubiquitous, the \u201cInfocalypse\u201d scenario looms. Trust in information will plummet, making individuals skilled in forensically analyzing digital content to determine its authenticity and expose manipulation indispensable for legal systems, journalism, intelligence, and corporate integrity. Autonomous systems security specialist (Drone/Robot defense): The proliferation of autonomous systems (drones, robots) for both benign and malicious purposes, as highlighted by Suleyman\u2019s concerns about asymmetric warfare and autonomous weapons, necessitates experts who can secure friendly systems and defend against hostile ones. This role is important for military, civil, and corporate security. Bio-risk detection and response specialist: With SynBio tools becoming more accessible, the risk of accidental leaks from labs or deliberate misuse (engineered pathogens) increases. Specialists who can rapidly detect novel biological threats, trace their origins, and coordinate containment responses will be vital for public health and global security. Resilient infrastructure technician (Energy/Comms/Water): Increased cyberattacks, physical threats from autonomous systems, climate instability, and potential state decay will strain important infrastructure. Society will need skilled individuals who can design, build, maintain, and rapidly repair robust and adaptable energy, communication, and water systems, often in challenging or decentralized environments. Localized resource manager (Food/Water/Energy production): If global supply chains fracture due to conflict, pandemics, or widespread instability (as implied by several of Suleyman\u2019s risk trajectories), communities will need to become more self-sufficient. Experts in establishing and managing local, sustainable food, water, and energy production will be key for survival and resilience. Digital privacy and counter-surveillance expert: Whether society veers towards dystopian state surveillance or chaotic fragmentation with numerous actors conducting surveillance, the demand for protecting personal and organizational data and communications will soar. These experts will help individuals and groups maintain privacy and operational security. Crisis mediator and de-escalation specialist: Increased polarization, resource scarcity, state fragmentation, and the proliferation of conflict-enabling technologies will likely lead to more frequent and complex disputes. Individuals skilled in negotiation, mediation, and de-escalation will be essential for resolving conflicts and maintaining peace at local, regional, and even international levels. AI safety and containment implementer: As a core part of Suleyman\u2019s \u201ccontainment\u201d imperative, there will be a need for technical experts dedicated to building safety into AI systems, conducting alignment research, performing audits, and ensuring that AI development adheres to ethical guidelines and safety protocols to prevent unintended harmful outcomes. Transition and basic needs coordinator: Mass automation and economic disruption could displace vast numbers of people. Coordinators will be needed to manage social safety nets (if they exist), distribute essential resources, facilitate retraining or transitions to new forms of work/livelihood, and address the widespread societal impact of economic irrelevance for many. Psychological resilience and adaptation coach: Living through an era of rapid, unpredictable change, potential information chaos, existential threats, and economic precarity will take a significant psychological toll. Professionals who can help individuals and communities build resilience, cope with stress and uncertainty, and adapt to new realities will be in high demand. For technical writers, these evolving roles suggest pathways that leverage core skills\u2014such as clear communication, understanding complex systems, user advocacy, and information structuring\u2014but apply them in new, important contexts focused on safety, resilience, verification, and navigating profound societal change. Discussion questions for technical writers Reflecting on The Coming Wave and its implications, technical writers might consider the following questions to explore the book\u2019s relevance. Automation and augmentation: Which specific tasks in your current technical writing workflow do you see as most vulnerable to automation by advanced AI in the next 5-10 years? Conversely, how can AI tools best augment your skills to enhance productivity and allow you to focus on higher-value work? Pessimism aversion in tech comm: Do you observe \u201cpessimism aversion\u201d within your organization or the broader tech writing community regarding the potential downsides of AI or other technologies we document? How might this impact the way risks or limitations are communicated? Documenting \u201cblack box\u201d systems: Suleyman highlights the challenge of \u201cblack box\u201d AI. As technical writers, what strategies can we develop to effectively document systems whose internal workings are opaque or probabilistic, especially regarding their limitations, potential biases, and failure modes? The role of clarity in containment: How significant is the role of clear, accurate, and comprehensive documentation in supporting Suleyman\u2019s proposed \u201ccontainment strategies,\u201d particularly for technical safety, audits, and ensuring responsible use of powerful technologies? Evolving skill sets: Looking at the \u201cJob evolutions\u201d section, which of those roles (e. g., AI content authenticator, AI safety implementer, digital privacy expert) seem like natural or achievable extensions of a technical writer\u2019s skill set? What new skills would be most important to acquire? Ethical responsibilities: When documenting powerful AI or biotech tools, what ethical responsibilities do technical writers have regarding potential misuse, unintended consequences, or the clear communication of risks, even if it makes the technology seem less appealing? The \u201cinfocalypse\u201d and trust: In an era of potential AI-driven misinformation, how can technical documentation maintain its status as a trusted source of truth? What measures can we take to ensure the integrity and verifiability of the information we provide? Documenting AI uncertainty and reliability: When an AI system provides information or performs a task, its outputs aren\u2019t always 100% certain or correct (e. g., an LLM might \u201challucinate\u201d or a diagnostic AI might have a margin of error). How can technical writers clearly explain these concepts of probabilistic outputs, confidence scores, or potential inaccuracies to users so they can make informed decisions about when and how much to trust the AI\u2019s output, without causing undue alarm or complete dismissal of the tool? Contribution to AI safety: Beyond documenting features, how can technical writers actively contribute to the broader goals of AI safety and alignment within their organizations, perhaps by advocating for safety-conscious design or more transparent development processes? Adapting to hyper-evolution: Given the \u201chyper-evolution\u201d of technologies described by Suleyman, what changes do we need to make to our documentation processes, tools, and strategies to keep pace with rapidly changing products and user needs? Pushback against Suleyman\u2019s ideas: Reasons for optimism? Although \u201cThe Coming Wave\u201d presents a case for caution and the potential for catastrophe, let\u2019s consider counterarguments and reasons why the future might unfold more positively. (These arguments aren\u2019t summarized from Suleyman\u2019s book but are rather added here from me.) Human ingenuity and adaptability: A primary counterargument rests on humanity\u2019s historical track record. Throughout history, societies have faced disruptive technological shifts, from the printing press to the industrial revolution and the nuclear age. While these periods often involved significant turmoil, displacement, and new dangers, human ingenuity consistently found ways to adapt, innovate solutions, develop new norms, and integrate these technologies, ultimately often leading to improved living standards and new forms of progress. This perspective suggests that we will similarly adapt to AI and SynBio, developing ethical frameworks, safety protocols, and societal adjustments as the technologies mature. Market forces and capitalist dynamics as correctives: Another significant line of pushback comes from the belief in the self-regulating power of market forces. In this view, every problem or risk created by a new technology also creates a market opportunity for a solution. For example, the rise of deepfakes has spurred investment in deepfake detection technologies; cybersecurity threats have birthed a multi-billion dollar cybersecurity industry. Capitalism, by its nature, incentivizes innovation, and this innovation can be directed towards mitigating harms, developing safety tools, and creating countermeasures, potentially balancing out the risks without requiring overarching, centralized containment that could stifle progress. Overstated risks and \u201cdoomerism\u201d: Critics might argue that Suleyman leans too heavily into \u201cdoomerism\u201d or exaggerates the likelihood and scale of worst-case scenarios. The human fascination with apocalyptic narratives can sometimes lead to an overemphasis on potential catastrophes. (Hollywood has a fascination with end-of-world narratives.) It\u2019s possible that the current limitations of AI (its lack of true understanding, its brittleness) are more indicative of its ultimate ceiling than proponents of existential risk believe, or that the technical challenges of creating truly uncontrollable AGI or globally devastating bioweapons are far greater than acknowledged. Some threats, like deepfakes, while problematic, haven\u2019t (yet) led to the complete societal breakdown once feared by some, suggesting a degree of societal resilience or that initial alarms were overblown. The \u201cpacing problem\u201d solved by incremental governance: While Suleyman highlights the \u201cpacing problem\u201d (technology advancing faster than governance), an optimistic view is that governance can and does adapt, albeit sometimes slowly and incrementally. Democratic societies, through public discourse, expert consultation, and iterative legislative processes, can develop regulatory frameworks that address emerging harms without resorting to authoritarian control. International cooperation, while challenging, has achieved successes in other areas (e. g., nuclear non-proliferation, ozone layer protection) and could similarly evolve to manage the risks of AI and SynBio. **The unfolding of unforeseen positive \u201cblack swans\u201d: **Just as there can be unforeseen negative consequences, powerful new technologies can also unlock entirely unexpected positive breakthroughs that fundamentally alter the risk-benefit calculus. AI and SynBio might lead to rapid advancements in areas like clean energy, disease eradication, or resource abundance that solve many of the underlying global stressors Suleyman identifies as fragility amplifiers. These positive black swans could create a future so much better that the transitional risks, while real, are navigated more successfully due to newfound capabilities and improved global well-being. The evolving role of technical writers: Thriving in the AI era For technical writers, the \u201ccoming wave\u201d of AI and related technologies presents both challenges to traditional roles and opportunities for evolution and increased impact. The fear of job loss through automation is palpable, yet the demand for skilled communicators who can navigate and explain these complex new systems is simultaneously growing. The key isn\u2019t to resist the wave, but to learn to surf it, transforming from traditional documenters into indispensable AI-era information experts and experience architects. The transformation is already underway. Technical writers are increasingly being asked to become AI experts, not just in using AI tools for their own productivity, but in understanding and documenting the AI systems their companies are building. The focus is shifting from static documentation portals and traditional pages towards creating dynamic, intelligent information experiences where users get precisely the answers they need, when they need them, often through conversational AI interfaces. This requires an ability to tap into user queries, analyze information systems for gaps and weaknesses, and then design or even help implement automated or agentic workflows to build smarter, self-improving knowledge bases. Here are ten key areas technical writers can focus on right now to not only survive but excel in this AI-driven era: Mastering AI augmentation tools: Develop deep proficiency in using AI writing assistants (LLMs, specialized documentation AI) for drafting, editing, summarization, translation, and code documentation. Effective prompt engineering for content creation and information retrieval becomes a core skill. Specializing in AI system documentation and explainability: Focus on the complex task of documenting AI models themselves\u2014their architectures, training data, limitations, biases, and decision-making processes. This is important for transparency, trust, safety, and regulatory compliance in an increasingly AI-driven world. Designing conversational information experiences: Shift from traditional documentation formats to designing and structuring information for AI-powered chatbots, virtual assistants, and in-app contextual help. This involves understanding natural language processing, dialogue flow, and how users seek information through conversation. Developing content strategy for AI-powered systems: Lead the strategy for how information is created, managed, and delivered in an AI environment. This includes defining content models for AI consumption (for example, setting up the llms. txt and llms-full. txt files, model context protocol (MCP) servers), ensuring content discoverability by AI, and integrating documentation with AI-driven support and product experiences. Information architecture for machine learning: Structure and tag content meticulously so that AI systems can easily understand, process, and retrieve it to provide accurate answers. This involves a deeper understanding of metadata, taxonomies, and knowledge graphs. User query analysis and content gap identification: Use analytics from search logs, chatbot interactions, and support tickets to identify precisely what information users are seeking, where current systems are failing, and what content gaps need to be filled\u2014then use AI to help bridge these gaps rapidly. Curating and validating AI-generated content: As AI generates more draft content, the technical writer\u2019s role as a subject matter expert, critical thinker, and quality controller becomes even more vital. Validating AI outputs for accuracy, clarity, completeness, and tone is paramount. Learn how to counter hallucination and mistakes from AI tools\u2014for example, perhaps by developing checks that examine each assertion against the reference documentation. Ethical communication and risk disclosure: Champion the clear, responsible communication of AI system capabilities, limitations, and potential risks. Develop expertise in articulating ethical considerations and ensuring users understand how to interact with AI safely and appropriately. Automated and agentic information workflows: Explore and implement tools and techniques for automating parts of the content lifecycle, from identifying outdated information using AI to triggering automated updates or even using AI agents to proactively suggest and create needed content based on user behavior. Cross-functional collaboration with AI teams: Work more closely than ever with AI developers, data scientists, UX designers, and product managers to ensure that documentation and information experience are considered integral parts of the AI product development lifecycle from the outset. Meeting transcript Here\u2019s a transcript of the book club meeting. (Note: This transcript was cleaned up and made more readable with AI.) Tom: Hi, this is Tom Johnson with Idratherbewriting. com. This recording is of our AI book club discussing Mustafa Suleyman\u2019s The Coming Wave: Technology, Power, and the 21st Century\u2019s Greatest Dilemma. Mustafa is co-founder of DeepMind and Inflection AI, so this book has a pretty intense focus on AI, looking towards some potentially dystopian or perhaps utopian futures. At any rate, many people are chatting. I didn\u2019t include a little preamble last time about what this recording was, so I thought I\u2019d add it this time. If you\u2019d like to join the book club, you\u2019re totally welcome. Just go to the link: Idratherbewriting. com/ai-book-club (with hyphens). We\u2019d love to have you. Alright, here is the recording. Alright, so the recording from last time I just put as a link right here\u2026 Oh, I did not put the link\u2026 Oh, over here, I guess I changed where I put it, and I\u2019ll continue to do that. I also put a video embed in the post and so on. This time, we are going to make our way through Mustafa Suleyman\u2019s The Coming Wave. Last time, it was really a book that was against AI, or had a much more critical take on AI. This is a different point of view entirely\u2014not from a writer, but from an innovator, entrepreneur, technologist, an AI founder. So the concerns are not really around the loss of writing, but rather how technology is going to impact and change things. I\u2019ve got a little link to some notes that I sent out; these are just a breakdown of the book, trying to distill the main argument and themes. This is AI-sort-of-written, so I\u2019m not sorry if that\u2019s a turnoff, but hey, it\u2019s actually quite accurate. Participant 1: So, Tom, just to ask, did you come up with those questions, or did the AI come up with them? Tom: Oh, a bit of both. I mean, anytime I\u2019m using AI, I\u2019m telling it directions to go, what I want to focus on, and going through iterations to figure out what I think would be good. I don\u2019t know; I can\u2019t even remember. So yeah, I sometimes bounce back and forth in my use of AI on the blog. But definitely, if we\u2019re just trying to get a breakdown of the book, I think it\u2019s really helpful. Of course, you don\u2019t get my raw opinion about all of it, but\u2026 Participant 2: I do! Yeah, exactly. That\u2019s why I\u2019m here. If I want their opinion, I can get that really easily. But the reason I\u2019m coming to this live-ish session is because I want other people\u2019s takes on things. Tom: Okay, well that will definitely be something we\u2019ll get into for sure. And I\u2019ll give you my raw opinion, and maybe that\u2019ll be a follow-up post. But before you can even have an intellectual discussion, right, we have to start with understanding the author\u2019s argument and all the different ideas going on here. So let\u2019s start there. Well, actually, let\u2019s back up just a bit. General reactions to the book? Would you give this a thumbs up, a thumbs down, or somewhere in the middle? Did you like the book? Some people, I think, were posting that they kind of couldn\u2019t get into it, while others were really enthralled by it. Anybody want to share their general reaction to the book? Judith: I loved it. Tom: Okay. Any particular reason? Judith: Because back in the 90s, when I lived in Texas, there was an organization consisting of academics and scholars who were discussing AI. And I\u2019ve been watching AI for 30 years. So, I thought it was prescient and right on the money all the way through. I just loved it. I\u2019ve already recommended it to two other people to read. So, I thought it was excellent. Tom: Alright, Daniel, thanks. Daniel: I also enjoyed it. I think I read the intro maybe a few weeks before I really jumped into it, and I was very ready to dislike it, but it grew on me. I particularly liked and appreciated Chapter 4, where it really gives an overview of recent progress with AI, especially deep learning and LLMs. He really kind of jumps into the argument of whether this is human intelligence, human thinking. And he says, basically, people say there\u2019s something inevitable about it; it\u2019s not, this is even better than human thinking. And I liked\u2026 it seemed like he used so many science fiction tropes in dramatizing all the things that can go wrong with AI. I appreciated that, even though in some ways that kind of catastrophizing is meant to bring attention and funding to it. But I like how he landed the plane with his policy suggestions. And I think he was also very aware of arguments against his own argument; he was very self-aware, which I appreciated as well. Tom: Yeah, well, I share both of your sentiments about the book. Coming back to this earlier idea of my raw opinion: it\u2019s definitely a scary book. It makes me think, \u201cHoly crap, massive changes are coming.\u201d My kids are just in college or going into college, and I wonder, are they even going to have a job? Does it even matter what they study? It\u2019ll be so massively different. I started to think, gosh, what will my role be in 10 years? Technical writing probably won\u2019t be around in the same way; maybe it\u2019ll be some crazy new hybrid, like some of the job titles I mentioned. So, I guess there was a certain fear. But then I also thought, \u201cWait a minute, don\u2019t we love to dwell on end-of-world scenarios?\u201d The human mind seems drawn to these catastrophic apocalypses; it\u2019s what Hollywood bases every futuristic movie on. So maybe I\u2019m just being pulled in this direction out of an innate psychological desire for technology to be this massive disruptor. But then, of course, in the book, he labels this as \u201cpessimism aversion\u201d and so on. Anyway, it\u2019s a book that prompts a lot of strong thoughts because it gets right at our livelihoods, our jobs, society, and stability. And yeah, it\u2019s kind of a scary thing. The main metaphor of the book is \u201cthe coming wave.\u201d Literally, if you think of a tsunami wave coming to decimate a city, it should spark some fear in the readers. So, the second half of the book on containment really only makes sense if you first are persuaded and believe that there is a coming wave that will decimate society. Let\u2019s start there. Before we get into any sort of containment, do you believe that the future could take this very dark trajectory he has outlined? Do you really believe there\u2019s a coming wave, or do you feel it\u2019s overblown or exaggerated? Anybody have any thoughts on that part? Uh, yeah, go ahead, Karin. Karin: Yes, I\u2019m in France, so pardon my English. I\u2019m actually one of the people who struggled with that book. I couldn\u2019t buy into this \u201cend of the world\u201d scenario from the start, so it was hard to keep reading it with a positive eye. I got the feeling that Suleyman, the founder of DeepMind, was saying, \u201cWhat I built is so powerful and so good that it threatens the whole of humanity,\u201d which I thought was very presumptuous. It felt like he was just saying that AI is fantastic and you should buy it. So I read it more as a marketing speech for AI, and I didn\u2019t buy the idea that it was endangering the human species. Maybe that\u2019s me being too optimistic. But when I think that we human beings\u2014well, we\u2014have found agreements to stop the proliferation of nuclear weapons, I\u2019m thinking, how can AI beat that? Tom: I think that\u2019s a great point you brought up. I\u2019ve heard that same argument in different spaces and podcasts: that the AI founders and companies are kind of overhyping AI\u2019s impact to justify the billions in investment coming in to fund the technology they need. Because it\u2019s going to be so massively impactful, it\u2019s going to rip apart society, or solve climate change, or bring miracles in biology and cure cancer, so of course, we need all this money. Maybe it is marketing hype. Interestingly, Suleyman doesn\u2019t counter that criticism, at least I don\u2019t remember it in the book. Maybe it\u2019s a more recent one. Sherry? Sherry: Yeah, so he wrote this book probably in 2022-23, and just in the past two years, things have changed massively. I just finished reading the foreword he wrote for the paperback edition, where he said things changed\u2014that was in September of \u201823. And things have changed even more since then. You know, the election has changed a lot of things. I\u2019ll just say that I was at a discussion recently about whether we\u2019re living in a post-truth society. And that, I think, is my biggest fear: it\u2019s going to become harder and harder to tell what is the truth. Tom: Yeah, that\u2019s a good point about the book potentially being a little dated already. It\u2019s kind of crazy. I mean, by definition of his argument about the coming wave accelerating, coming faster, and transforming things, the book is going to be outdated faster than normal. Molly? Molly: One thing I kept thinking about when I was reading the book was, I was trying to wonder who his target audience was. I was trying to imagine who he thought was going to read this book because, at times, I felt like he wasn\u2019t speaking to me. And that made me wonder, okay, so who is it? I\u2019m curious what you all think: who is his audience? Tom: That\u2019s a great question because I found myself feeling helpless. Like, yes, all these containment strategies seem okay, good. But what do I do? I\u2019m just trying to keep my job, ride the wave, and not be unemployed in five years due to Devon or whoever replaces us as the AI, right? So, who\u2026 does anybody have any thoughts on who he is really talking to? Daniel? Daniel: To me, it definitely feels like it\u2019s meant to be a more popular book. It\u2019s meant to\u2026 I mean, everyone uses AI or knows what it is. So, I definitely feel like in some ways it\u2019s a primer for what AI is, because even people who use it don\u2019t necessarily understand what it\u2019s doing. I feel like that\u2019s very much a part of why he chose to use science fiction tropes to dramatize his concerns. Because, you know, if you write a white paper, only a certain number of people are going to pay attention. But if you\u2019re talking about the end of the world and imagining all these really crazy scenarios in which it could end, that\u2019s going to drum up a lot of interest. And that\u2019s part of the reason the book was a New York Times bestseller. Tom: Yeah, good point. But I mean, there are a lot of different formats a person could take. And for sure, he\u2019s adopting this more popular audience format\u2014more general, more readable. It\u2019s not buried in footnotes or some other academic approach. Alright, let\u2019s talk a little bit about\u2026 we were discussing whether we think the trajectories he\u2019s painting will really be big, decimating waves. It almost sounds silly to engage in this conversation, right? But at the same time, it\u2019s a significant part of the book. And hey, if you believe the world\u2019s going to end, how is it going to end? Somebody mentioned the \u2018info-pocalypse\u2019\u2014or however we\u2019re saying that term, \u2018information apocalypse\u2019\u2014where we can\u2019t tell true information from false. He outlined several different trajectories. This gets back to the \u2018fun with end-of-world scenarios,\u2019 but there was one with engineered pandemics, which probably hits pretty close to home and is obviously highly relevant if you\u2019re writing this in 2022. Then there\u2019s synthetic biology, a field I\u2019m less familiar with, which seems to involve more DNA editing with very inexpensive tools. It\u2019s easy to foresee pathogens being created, enhanced, or even just mistakes people make, and that getting out of hand. Another scenario was misaligned AI\u2014referring to AI goals at odds with human goals. This could even be inadvertent, where you set up some kind of defense\u2026 oh, actually, that\u2019s more the third one. But you just have AI working at odds with what humans want, leading to a loss of control. The third one was autonomous warfare and escalation. Maybe you set up a system to respond immediately, but then a misfire triggers a cascade of actions that escalates war very fast. We\u2019ve mentioned the information apocalypse. Then there\u2019s economic collapse from workers being replaced, consumers not being able to buy anything, and all kinds of inequality. Do any of these look more likely or more interesting to you? I thought I heard somebody raise their hand, but maybe I\u2019m not seeing it anymore. Is it silly to even try to focus on the \u2018how\u2019? Judith? Judith: Well, one thing he didn\u2019t cover, though he kind of touched on it with autonomous warfare, is something I can see going absolutely haywire. I mean, the number of people in my neighborhood who have drones\u2026 if anybody got upset with someone else, they could\u2026 And these drones are not regulated; you don\u2019t know who owns them or whatever. I was on my back porch taking a nap one day, heard one, opened my eyes, and it was right over me, about 20 feet up. I was thinking, \u201cWhat the heck?\u201d If I\u2019d had a rock, I\u2019d have thrown it. But if something can come into your personal airspace and be armed, that really is a scary situation. He never touched on that exactly, but he kind of danced around it. He was talking more on a geopolitical level, I think. So, that\u2019s where my head went. Tom: Yeah, the drones one is kind of scary too. We\u2019ve had all kinds of drone news recently, and drones are playing a huge part in the Ukraine-Russia war and so on. Yes. Daniel? Daniel: Yeah, in many ways, a lot of these scenarios overlap. To me, it feels like\u2026 one of the ways he\u2019s more traditionalist is that he feels the nation-state is the bedrock for security and has to be a real part of AI solutions. We are at a point where it\u2019s almost like the twilight of nation-states after 400 or 500 years. He also talked about the rise of multinational corporations, which in many ways have much more power and influence than nation-states (which have influence over their own region but also some within the world). To me, that intersection feels like the most serious, sort of midterm threat. The other one\u2026 he wrote very poignantly about the weavers in the afterword. In some ways, that\u2019s the kind of immediate thing we might be looking at: this skilled labor just getting moved into something totally different. But yeah, those are the kinds of things that I feel are catastrophes in their own right, I guess. Tom: Yeah. Let me just comment on my thoughts on the nation-state thing. I think that is a very interesting intersection, as you point out. We\u2019re seeing right now this test of how powerful the government is versus not. Suleyman describes this dilemma of resorting to super-strong government lockdown to contain AI\u2014by having something like ten times the surveillance state of China, where everything is monitored to really lock it down\u2014in contrast to complete openness and chaos, where everything\u2019s open source, and anybody does whatever they want and creates all kinds of havoc. Trying to find the narrow path between those two alternatives is what most of his book tries to focus on. But I find myself wondering, how powerful can these individual nation-states be in contrast to\u2026 say, all the tech companies banding together and using their AI to create their own little city communities or city-states with their own rules? At what point can you just push back and say, \u201cOkay, government, you\u2019re not actually as powerful because we control a ton of power\u201d? I don\u2019t know. This whole idea of fragmenting a nation into smaller subgroups is one he talks about. I think he mentioned groups like Hezbollah, who could be really empowered beyond their size and scope, having outsized influence due to being armed with AI or whatever tools they\u2019ve got. Sherry? Sherry: Yeah, so just to riff on that a little bit, I think he is talking about the fragility that we have experienced recently. We\u2019ve had a lot of things kind of blow up that we expected, including possibly our own constitution. And this is something that AI\u2026 you know, we have no idea what the intersection of all that is going to be because we\u2019re dealing with things we have never dealt with on a scale we\u2019ve never dealt with before. I suspect the author has read books like The Black Swan and Antifragile, where they talk about the fragility of the nation-state. I have to wonder whether there\u2019s just this intersection of all these things coming to a head all at once and how it\u2019s going to play out. So, I\u2019m interested in hearing what other people think about that. Tom: Yeah, the book is very timely in that regard, right? Because this was before the current political chaos and administration and so on, and he seemed to anticipate many of these themes. I find myself wondering: if AI is so powerful that people can engineer deepfakes and disinformation campaigns, why can\u2019t people harness this power to shape political outcomes against Trump, for example? Why is it that nobody can really counter any of the moves he seems to be making and all these executive orders and changes? It\u2019s like everybody\u2019s just sort of paralyzed. But I thought we were supposed to be empowered too. There\u2019s not even a bad actor acting for good, maybe. I don\u2019t know\u2026 I\u2019m not really sure I want to steer into politics, but basically, yeah, it\u2019s one question I had: why can\u2019t people use AI to stop Trump? Judith? Judith: Well, you can\u2019t pull it apart; it is part of it. I mean, just look at his inauguration, the people he had. In past presidential inaugurations, it\u2019s been the cabinet or people politically aligned with the person being inaugurated. He had the tech bros behind him. He had the owners of the largest technology companies in the country, in the world, sitting behind him. And it was\u2026 I was about to say something really crass\u2026 because it looked like a \u201cmine is bigger than yours\u201d kind of scenario to me. But anyway, I don\u2019t think you can pull it apart. Tom: So, well, this display of power is certainly a major theme in the administration. And I think it fits in with Suleyman\u2019s trajectory around countries competing against each other. Can you imagine a scenario where we pull out of the AI race with China because we think we\u2019re worried about runaway AI scenarios or something? There\u2019s no way. There\u2019s no way the two countries would stop competing against each other. And even outside of country competition, just companies\u2014we have all the big AI companies competing against each other at breakneck speed. It\u2019s not like we\u2019re going to see one company say, \u201cAh, you know what, I think we\u2019re going a little too fast. We\u2019re going to slow down. Our models are too powerful.\u201d It\u2019s not happening. The whole capitalistic structure and other structures are set up to just force acceleration and innovation that seems unchecked. So, yeah. Not really sure. Let\u2019s see, let\u2019s hear from somebody we haven\u2019t heard from. Superja? Superja: I think the economic impact is the one that feels the most present for me right now, only because there seems to be some degree of impact already. When he talked about how AI is better at task completion, he specifically seemed to call out cognitive skills. And it seems like a lot of, I don\u2019t know, the way I think about our economy is based on completing some kind of task. So, maybe I don\u2019t know a lot about it, but that is one of my fears. It\u2019s like, the knowledge I have is no longer as valuable for task completion in that sense. Yeah, so I\u2019m losing my words, but hopefully, someone can pick it up from there. Tom: Yeah, that\u2019s a great point. Let\u2019s pick that up. But before we do, Sherry, you have one more thought you wanted to get out, right? Sherry: Yeah, when you were talking about competition, I think there\u2019s this attitude that we are in competition with AI. Whereas, you know, there are certain things only humans can do, and certain things AI can do way better than us. But I think the bigger part of it is the things AI can help us do, that can supplement what humans can do. So, instead of being in competition, we should maybe think about how we can partner with AI, or let AI do the things it\u2019s good at and humans do the things we\u2019re good at, and we\u2019ll all be better together, instead of coming up with these doomsday scenarios. So that was my thought of optimism, so Molly doesn\u2019t have to go and curl up into a ball somewhere. Tom: Yeah, I like this idea. Let\u2019s jump off on this point: trying to figure out where the human excels versus the machine. Superja said we\u2019re at a point where our knowledge and skills might not be valuable anymore; AI can complete certain tasks, and we no longer need humans for them. I\u2019ve seen this, especially with lower-level tasks. Let\u2019s say you have a contractor come in to help out. Maybe before, you would give that contractor grunt work that involved a lot of processing, or \u201cgo and fix all these links in 5,000 pages.\u201d Now, you can basically have AI do that. AI is getting smarter and smarter. And yeah, it seems like engineers could probably just leverage AI to do many of the same tasks they previously gave to us. Personally, I think we need to focus on the really complex, complicated work\u2014the stuff AI can\u2019t easily do. Because if we stick with this lower level of just editing and publishing what engineers produce, that\u2019s not going to take us very far. Daniel? Daniel: Yeah, I wanted to jump off what Molly was saying. The labor question\u2026 I feel like he didn\u2019t go very deeply into it. He talked at the end about the Luddites destroying the weaving machines. And Suleyman acknowledged it was disastrous for them, but overall okay for everyone else. He talks about the division of labor, like in Ford companies, where highly trained craftsmen had their work divided up so anyone could do it. And it\u2019s not necessarily a very nurturing kind of work. I noticed the new job titles in your post; many of them are sort of maintenance or surveillance things, these specialized tasks. So we\u2019re at this point where writing, which is in some ways one of the most general kinds of knowledge production, is being sort of dismantled. And we are all kind of looking to find these specialties or these things we can hold on to in the aftermath, which we have to do. Tom: Yeah, this definitely gets to the heart of the takeaway for me from the book: where do you focus if our skills in writing, editing, and publishing are becoming low value? How do we transition in a way that\u2019s still valuable? That\u2019s what this whole section I added on \u201cpotential skills\u201d was hoping to accomplish. Like \u201cAI-generated content authenticator\u201d\u2014this is actually a pretty good one. Not necessarily just someone who can identify deepfakes, but someone who can identify hallucinations or develop techniques to avoid mistakes, gaps, or errors in AI outputs. If you solve that, you can get any job you want. From the start, that\u2019s been the criticism of AI tools: they\u2019re sometimes wrong in subtle, hard-to-detect ways. I have some strategies I use with docs to get around this, like uploading all the API reference into context sessions as a ground source of truth. But I feel we could take this to another level. How do you identify misinformation, or maybe not misinformation, but errors in generated info? And these other areas are almost like, \u201cHey, these could be areas to become much more familiar with.\u201d If these are the problems that could erupt, maybe it\u2019s an opportunity. The drone situation people brought up earlier\u2014if you know a lot about drones, even documentation for them, or just robot defense, it seems like maybe that\u2019s a ripe area. It does seem kind of silly, again, to think about specializing in robot defense. It feels like I\u2019ve swallowed a science fiction book and am suddenly mapping my career based on some far-reaching sci-fi stuff. But I don\u2019t know, what do you do? Let\u2019s see, somebody raised their hand. Sahare? Sahare: Hello, sorry I cannot turn on my camera due to connectivity issues. I just wanted to add how we can spot hallucinations. My language is Urdu, and one day I tested ChatGPT and asked about a particular Urdu book that wasn\u2019t very popular and wasn\u2019t available in PDF format. Instead of saying the book was beyond its scope, ChatGPT started hallucinating and creating a story on its own. Another time, I had to write a review for a book that wasn\u2019t published yet, and I checked with ChatGPT, and it did the same thing. So, that\u2019s something\u2026 I mean, new knowledge that is coming in, AI cannot be trusted with it. Like new books that are coming out, AI isn\u2019t smart enough to be trusted with that kind of information. It\u2019s important to always keep in mind that whatever AI or ChatGPT or any other AI model is providing us is based on previously created information that humans provided. So there will always be a human element. Maybe in the future, our jobs will be more about overseeing what AI is doing, confirming if it\u2019s correct, and verifying the accuracy of the information. So I think humans will have jobs more related to that. But the hallucinations are always there. It\u2019s a very important and problematic issue that if AI doesn\u2019t know about a book, it still talks about it. I think that\u2019s a huge drawback of AI. Tom: Yeah, I\u2019ve got some thoughts on that. I\u2019ve read research saying that experts are much more productive with AI tools than novices, for exactly the reason you described. As an expert, you can spot when things are wrong, and maybe you can correct the AI or just dismiss the incorrect parts. In the same way I used AI to get a summary of the book, I could understand if it was accurate or not, having read the book. If I hadn\u2019t read it, I\u2019d just be shrugging, thinking, \u201cWell, maybe it\u2019s accurate, maybe not. I have no idea.\u201d That kind of expertise, I think, will be critical to excelling with AI tools. For example, a few months ago, I was trying to write code samples for a team using gRPC APIs, and I didn\u2019t have a strong sense of them, so I used AI to create them. I thought, \u201cI\u2019ll just hand them to the engineers; they might make a few corrections, and then we\u2019ll publish them.\u201d While that worked for about three-quarters of these APIs, a few teams found all kinds of issues with the code. I was in this very vulnerable position of having to maybe put it back into the AI machine with their issues and hope the next version would fix them. I thought, \u201cThis is a bad spot for me to be in. I want to be the expert who\u2019s really doing the evaluation.\u201d So this need for expertise plays into our career strategy. We have to have expertise in something, and it\u2019s not going to be just about writing, right? If we\u2019re just generalists with great writing skills, maybe that doesn\u2019t take us where we need to be. We also have to add some subject matter domain expertise. I\u2019ve got another example, but Sherry, you have thoughts? Sherry: Yeah, just to add to the expertise area, there\u2019s also the issue of bias. I took an AI class on Coursera, and one example they had was: \u201cMan is to king as woman is to queen.\u201d Pretty obvious. Then they put in: \u201cMan is to software engineer as woman is to\u2026\u201d Anybody want to hazard a guess what the AI decided? Various Participants (guesses): Secretary? QA Engineer? Technical writer? Sherry: Housewife. Various Participants: Housewife! Oh my god! Sherry: Housewife, yes. I know. So it was kind of horrifying. This is just one very small example. You could see how if it was \u201cfarmer,\u201d something with a lot of historical literature, \u201cfarmer and housewife\u201d might make some (albeit biased) sense. But this was \u201csoftware engineer,\u201d a relatively recent profession, and yet it still came up with \u201chousewife\u201d as the equivalent for a woman. So, just a very small example of the bias. If you don\u2019t have people with expertise or people looking at the bias, we can go very badly wrong with some of these answers. Molly? Molly: I think to add to that, Sherry, when I was reading this book, it was so interesting going from John Warner\u2019s book to this one. John Warner, right at the beginning, talked about all the problems with AI\u2014bias being one, and also energy consumption. It was so interesting to come upon those same topics in this book and just be like, \u201cOkay, where\u2019s the rebuttal going to happen?\u201d Particularly with the bias one, I felt his rebuttal was kind of short, just like, \u201cYou know, we\u2019re taking care of it,\u201d and let\u2019s just dust it under the rug. It was an interesting experience. I really appreciated going from the previous book to this one and seeing how people rationalize things. Tom: We could definitely pair more books as opposites to give us a better perspective. This next book on the list, The Singularity is Near, probably won\u2019t push back against AI, but we can throw some more critical stuff in there too. But yeah, for sure, awareness of bias is huge and probably should have been more developed in this book. I had one more thought, and then I\u2019ll call on Robert and Karin. We were talking about expertise and the need to figure out where our expertise will be valuable. There\u2019s a neon sign basically blinking about where that currently is with writing: it\u2019s in developing AI-intelligent documentation systems. This is an area very few people understand how to do. I was just at the Write the Docs Portland conference, and one takeaway was that, yeah, everybody\u2019s just as confused about how to incorporate AI into documentation\u2014for users, for authors, for analytics, everything. Nobody has a clear idea. There are different tools, experiences, and opinions, but it\u2019s pretty much all over the place. If you wanted to really get a job anywhere, become an expert in transforming documentation into something AI-powered. It sounds easy; it\u2019s really hard. How do you capture analytics? Create agentic workflows? Push through identified gaps? Identify uncertainty in responses? Evolve your tooling? Build your llms. txt files? Build an MCP server? All this stuff is like big question marks. But, at least for this little window of time\u2014maybe two or three years, maybe two or three months, who knows?\u2014that seems to be an area people could really exploit. Okay, let\u2019s go to Rob and then Karin. Rob: Okay, got to turn on my mic. My response so far to the conversation, regarding concerns about losing jobs, is that I tend to think of AI as just another tool that\u2019s probably going to raise the bar in terms of quality. That\u2019s how I look at it. It\u2019s like when they introduced spreadsheets or PowerPoint; suddenly, you just had much better PowerPoint slides. So I think that\u2019s how I try to think of it. Maybe I\u2019m being too optimistic, but for my sanity, that\u2019s how I approach it. And then, in terms of a practical method of overcoming problems with ChatGPT, I tend to throw my questions into multiple tools and then compare the results, and that works pretty well. Karin: I pretty much agree with Rob in the sense that I don\u2019t feel threatened by AI as a technical writer. It\u2019s sort of an evolution of what we\u2019ve all been doing all these years. I feel my value isn\u2019t just producing text, but making the right decisions on what to document, why, and how. Those things, I feel, cannot be taken over by an AI. And now I\u2019ve got a great tool to do it, so I feel empowered by it, especially because I have to write in English, and it\u2019s not my native language. It\u2019s fantastic. I just have to focus on what needs to be written, how it works, ask the questions to the team, get my SMEs on board, and get the AI to spell it out clearly\u2014which it obviously can do if you give the right instructions. You can even give it the style guide and everything, so it does a better job at it than I used to. It\u2019s a fantastic tool for me, especially writing in another language. Also, one more thing about prompting: I found that giving a fallback plan to the model works pretty well. Saying something like, \u201cIf you cannot find any relevant information about this topic, then just say \u2018I don\u2019t know.\u2019\u201d If you don\u2019t say that, it really changes how the AI responds. If you just add that sentence, I found that, okay, it can eventually admit it doesn\u2019t find the answer, but you have to leave the door open for it. It\u2019s funny to do a bit of prompt engineering at our tech writing level. Tom: Yeah, that sounds like a great tip. You\u2019ve both touched upon another aspect: becoming familiar with AI tools and workflows and understanding how to avoid traps like hallucination by using the tip you just mentioned, Karin. And Rob mentioned using several tools to get a convergence of answers. That kind of awareness and fluency with AI tools is actually a non-obvious skill, I\u2019ve found. Many tech writers just don\u2019t really know how to use the tools. And when they do, maybe they have a negative experience, it sours them, they become dismissive, skeptical, and then they fall farther behind because they never really learn the right approaches, prompts, and techniques to be successful. The idea that it\u2019s a non-obvious skill is still kind of mind-blowing. People don\u2019t automatically know how to use AI tools for the tasks they\u2019re trying to do. That is huge. Mary? Mary: Hi. Just on what you were saying, I completely agree, it is a skill, and it\u2019s not obvious. So when it comes to putting the same material into multiple AIs, doesn\u2019t that take more time than just writing the thing anyway? I suppose, you know, I do use AIs, well I can, but most of the time I am generating new information. And Sahare, I think, said that AIs aren\u2019t generating what\u2019s not already there? And if they do, it\u2019s wrong. Tom: Well, you make a good point that one could definitely spend too much time fiddling with AI when the task might be done more simply. It really depends on the task, I would say. But your other question is, okay, AI tools have a limited training body, so if you\u2019re writing about something new, how will it be relevant? This comes back to techniques. When I\u2019m writing about a new feature, I find all the internal material I can. Usually, by the time it gets to me to document, there are product definition documents (PRDs), engineering design documents. Somebody\u2019s coded parts of an API, so there\u2019s a code artifact. You can find a lot of this stuff, gather it all up, stuff it into the machine, and use that as your input source. That is the golden technique. In fact, the one that trumps all of those is reference content. When engineers have made a change in an API and you now have new source files, or you\u2019ve generated reference docs with new elements described, you can just take that whole reference and put it in. Or you can capture the changelist, like the file diff of what\u2019s changed, and provide that to the AI. You can get around this problem of being trapped by the AI\u2019s limited training material. But just understanding the right techniques for the right situation really interests me because I love this feeling of empowerment. I love thinking, \u201cGod, these tools are so powerful. If I just knew how to use them in the right way to get what I want, then I extend my capabilities pretty far.\u201d Mary: I see where you\u2019re at. But one of the things I like best about my job is that it\u2019s a communications role and I get to talk to people. I love it. Tom: You actually talk to people! Oh, so you go out and gather information manually, with people? Like you interview people about new features? You could still do that. You could do it even faster, in fact. Just record the meetings, have them draw on whiteboards too, whatever they want to do. I love the whiteboard. It\u2019s so efficient. Just take all those resources. That\u2019s actually one of the best techniques: if you can set up a meeting with someone and just get their brain to dump all the relevant information to you, even in a messy, unstructured, redundant format, feed that into your AI, and you\u2019re maybe 60-90% of the way there to whatever you need to write. You could shape it with, \u201cHey, match this pattern, use this style.\u201d Then you go through multiple iterations and say, \u201cAh, this paragraph doesn\u2019t feel right.\u201d Maybe you redo that yourself or push it through more iterations. I\u2019m just saying the techniques for using AI are manifold and really just limited by your own creativity. Sherry? Sherry: Yeah, to jump onto what you just said about creativity, that\u2019s one of the things people can do that AI might not be as good at, or it might be creative in a way we don\u2019t expect or even want. I loved what Mary said about actually talking to people. And then using AI if you record it and use the whiteboard. This is another thought about partnership: we do what we do really well. All the stuff you described, Tom, about how you do your job, that was how we did our job before AI. AI is just going to make it a little faster. So it\u2019s an enhancement, as opposed to a brand new way of doing things. And we probably haven\u2019t even thought of all the brand new ways we can do things because it\u2019s so new. And as you say, people don\u2019t know what the tools are or how to use them at this point. So, I think it\u2019s pretty exciting that there will be some new techniques. But for now, just enhancing the old techniques sounds like a pretty good plan. Mary: So it seems to me, Tom, excuse me, you\u2019re saying that you can actually use AI to fill information gaps? Tom: Uh, yeah, yeah. The social component Sherry touched upon is actually something I also have mixed feelings about. I\u2019ve become more isolated because I feel I can just get the information myself from the changes engineers are making. I\u2019ve been steered in the wrong direction many times by people who are misinformed about the product itself; I find out, \u201cOh yeah, it actually doesn\u2019t work that way or doesn\u2019t have that element.\u201d So I almost don\u2019t even want people to tell me. I want to rebuild the reference documentation, create a file diff, and discover for myself what\u2019s actually changed. Then, if there\u2019s stuff that\u2019s not apparent in that, fine, I\u2019ll go gather it manually. But I don\u2019t know. At the same time, that isolation isn\u2019t comforting, right? As you said, there\u2019s a communications role that\u2019s kind of nice, interacting with other people. I used to have monthly sync-ups with each team I supported, and we just stopped having topics, so I canceled all the meetings. I don\u2019t ever really need to meet with them. I sit near them, so I can chat if I need to, but there wasn\u2019t a need to sync more regularly because I felt I could just use AI to get all the information I needed. Maybe that\u2019s a delusion of mine. Anyway. Okay, so let\u2019s talk a little more about this evolving role we have and how our job changes. What really should we be focusing on? Do you feel the need to move your documentation system, if you\u2019re a tech writer, into an AI-enabled era? Are you getting that kind of pressure? Or are you being pushed in another way? Maybe moving beyond a tech writer role, not just focusing on docs but something different, more project manager-y or QA related? I don\u2019t know, just how is your role evolving in this space? Karin? Karin: Yeah, I do feel there\u2019s a change in what\u2019s expected from me, similar to when SEO came around. We weren\u2019t just writing for our audience anymore; we also had to write for search bots. And now, we also need to get into chat somehow. So, \u201cWhy is your content not picked up by the models?\u201d is a question I have to find the answer to. It\u2019s about trying to find new ways of writing that LLMs like\u2014more FAQs, maybe. Because we now assume people aren\u2019t only going to read or search the documentation or find it via Google, but they\u2019re also going to ask the AI about the product we\u2019re building. So we need to feed the LLMs now too. We have these multiple audiences, and the LLMs are one of my personas, somehow. Tom: Yeah, I think you\u2019ve hit upon what I believe is the most sought-after skill right now: the ability to get our documentation ingested into these models our users are using, so they can get accurate, complete information through these models, and get it fast. We\u2019ve done research studies looking at how people use our docs, and often they\u2019re going to ChatGPT\u2014literally ChatGPT, not even Gemini, even if they\u2019re using Google documentation sometimes. So how do you get all your information ingested? How do you make sure it\u2019s answering the questions people are asking? Those are the skills really in demand. I mentioned llms. txt files; if you haven\u2019t heard of those, that\u2019s one potential mechanism, like a sitemap for large language models to ingest. I\u2019m not even sure if it works, but it\u2019s one thing some people are pushing. There are probably so many other opportunities. But just identifying that problem space and figuring out how to move into it and become experts would be great. Imagine, no matter what domain becomes hot\u2014cybersecurity, information corroboration, whatever\u2014the ability to create an AI-powered documentation system that delivers accurate answers will be required for every subject matter domain. That would be very good to become an expert in. So, alright, we are running out of time. I just wanted to mention the next book in the list for people. Oh, not sharing my screen, let me share real quick. I did mention it already: it\u2019s the Singularity book. I haven\u2019t read it yet, but it got good reviews, so I thought it would be interesting. It\u2019s Ray Kurzweil. I guess he had an initial book, The Singularity is Near, and now he has a follow-up. On Amazon, it has over a thousand reviews, four and a half stars, so hopefully, it\u2019s good. It\u2019s been a New York Times bestseller, so we\u2019ll see. It\u2019s definitely getting more into merging with AI, and hopefully, we can look at how to augment our human skills with AI to tackle these complex, wicked projects or whatever kinds of things we can\u2019t do with our regular capabilities. Anyway, that meeting is set for, let\u2019s see, June 15th. So, thanks again for coming to this. I really appreciate your thoughts and participation. I love your insights and love the group here. Thanks again, and I\u2019ll post a recording very soon next week for those who couldn\u2019t make it. Alright, have a good rest of your weekend. All: Thank you! Thanks, Tom! Bye-bye! About Tom Johnson I'm an API technical writer based in the Seattle area. On this blog, I write about topics related to technical writing and communication \u2014 such as software documentation, API documentation, AI, information architecture, content strategy, writing processes, plain language, tech comm careers, and more. Check out my API documentation course if you're looking for more info about documenting APIs. Or see my posts on AI and AI course section for more on the latest in AI and tech comm. If you're a technical writer and want to keep on top of the latest trends in the tech comm, be sure to subscribe to email updates below. You can also learn more about me or contact me. Finally, note that the opinions I express on my blog are my own points of view, not that of my employer. Please enable JavaScript to load the comments.",
    "published_at": "2025-05-17T07:00:00Z",
    "source": "Idratherbewriting.com",
    "url": "https://idratherbewriting.com/blog/suleyman-the-coming-wave-notes",
    "summary": "This post describes the key arguments and themes in, by Mustafa Suleyman, for the AI Book Club: A Human in the Loop. It also contains the book club recording. For a transcript, see Meeting transcripts below.",
    "category": "Technology"
  }
]